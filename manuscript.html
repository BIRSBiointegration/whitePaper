<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Kim-Anh Lê Cao" />
  <meta name="author" content="Aedin C Culhane" />
  <meta name="author" content="Elana Fertig" />
  <meta name="author" content="Vincent J. Carey" />
  <meta name="author" content="Jane Roe" />
  <meta name="author" content="Ricard Argelaguet" />
  <meta name="dcterms.date" content="2020-07-29" />
  <meta name="keywords" content="markdown, publishing, manubot" />
  <title>Community-wide hackathons establish foundations for emerging single cell data integration</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta name="citation_title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta property="og:title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta property="twitter:title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta name="dc.date" content="2020-07-29" />
  <meta name="citation_publication_date" content="2020-07-29" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="Kim-Anh Lê Cao" />
  <meta name="citation_author_institution" content="Melbourne Integrative Genomics, School of Mathematics and Statistics, University of Melbourne, Australia" />
  <meta name="citation_author_orcid" content="0000-0003-3923-1116" />
  <meta name="twitter:creator" content="@mixOmicsTeam" />
  <meta name="citation_author" content="Aedin C Culhane" />
  <meta name="citation_author_institution" content="Data Sciences, Dana-Farber Cancer Institute, Boston, MA, USA" />
  <meta name="citation_author_institution" content="Biostatsitics, Harvard TH Chan School of Public Health, Boston, MA, USA" />
  <meta name="citation_author_orcid" content="0000-0002-1395-9734" />
  <meta name="twitter:creator" content="@AedinCulhane" />
  <meta name="citation_author" content="Elana Fertig" />
  <meta name="citation_author_institution" content="Department of Oncology, Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University School of Medicine, Baltimore, MD, USA" />
  <meta name="citation_author_institution" content="Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, MD, USA" />
  <meta name="citation_author_institution" content="Department of Applied Mathematics and Statistics, Johns Hopkins University Whiting School of Engineering, Baltimore, MD, USA" />
  <meta name="citation_author_orcid" content="0000-0003-3204-342X" />
  <meta name="twitter:creator" content="@FertigLab" />
  <meta name="citation_author" content="Vincent J. Carey" />
  <meta name="citation_author_institution" content="Channing Division of Network Medicine, Brigham and Women&#39;s Hospital, Harvard Medical School" />
  <meta name="citation_author_orcid" content="0000-0003-4046-0063" />
  <meta name="citation_author" content="Jane Roe" />
  <meta name="citation_author_institution" content="Department of Something, University of Whatever" />
  <meta name="citation_author_institution" content="Department of Whatever, University of Something" />
  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />
  <meta name="twitter:creator" content="@XXX" />
  <meta name="citation_author" content="Ricard Argelaguet" />
  <meta name="citation_author_institution" content="European Bioinformatics Institute (EMBL-EBI)" />
  <meta name="citation_author_orcid" content="0000-0003-3199-3722" />
  <meta name="twitter:creator" content="@RArgelaguet" />
  <link rel="canonical" href="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta property="og:url" content="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta property="twitter:url" content="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta name="citation_fulltext_html_url" content="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta name="citation_pdf_url" content="https://BIRSBiointegration.github.io/whitePaper/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://BIRSBiointegration.github.io/whitePaper/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://BIRSBiointegration.github.io/whitePaper/v/39b6d200fc62de66ece3fcb67d05bb0c5795a2f1/" />
  <meta name="manubot_html_url_versioned" content="https://BIRSBiointegration.github.io/whitePaper/v/39b6d200fc62de66ece3fcb67d05bb0c5795a2f1/" />
  <meta name="manubot_pdf_url_versioned" content="https://BIRSBiointegration.github.io/whitePaper/v/39b6d200fc62de66ece3fcb67d05bb0c5795a2f1/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Community-wide hackathons establish foundations for emerging single cell data integration</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://BIRSBiointegration.github.io/whitePaper/v/39b6d200fc62de66ece3fcb67d05bb0c5795a2f1/">permalink</a>)
was automatically generated
from <a href="https://github.com/BIRSBiointegration/whitePaper/tree/39b6d200fc62de66ece3fcb67d05bb0c5795a2f1">BIRSBiointegration/whitePaper@39b6d20</a>
on July 29, 2020.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Kim-Anh Lê Cao</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3923-1116">0000-0003-3923-1116</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/mixOmicsTeam">mixOmicsTeam</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/mixOmicsTeam">mixOmicsTeam</a><br>
<small>
Melbourne Integrative Genomics, School of Mathematics and Statistics, University of Melbourne, Australia
· Funded by Grant National Health and Medical Research Council Career Development fellowship (GNT1159458)
</small></p></li>
<li><p><strong>Aedin C Culhane</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-1395-9734">0000-0002-1395-9734</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/aedin">aedin</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/AedinCulhane">AedinCulhane</a><br>
<small>
Data Sciences, Dana-Farber Cancer Institute, Boston, MA, USA; Biostatsitics, Harvard TH Chan School of Public Health, Boston, MA, USA
· Funded by Chan Zuckerberg Initative, NIH, DoD (need to get grant IDs)
</small></p></li>
<li><p><strong>Elana Fertig</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3204-342X">0000-0003-3204-342X</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/ejfertig">ejfertig</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/FertigLab">FertigLab</a><br>
<small>
Department of Oncology, Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University School of Medicine, Baltimore, MD, USA; Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, MD, USA; Department of Applied Mathematics and Statistics, Johns Hopkins University Whiting School of Engineering, Baltimore, MD, USA
· Funded by National Institute of Health, National Cancer Institute; National Institute of Health, National Institute of Dental and Craniofacial Research; Lustgarten Foundation; Emerson Foundation; Allegheny Health Network
</small></p></li>
<li><p><strong>Vincent J. Carey</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-4046-0063">0000-0003-4046-0063</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/vjcitn">vjcitn</a><br>
<small>
Channing Division of Network Medicine, Brigham and Women’s Hospital, Harvard Medical School
· Funded by National Institutes of Health, National Human Genome Research Institute; National Institutes of Health, National Cancer Institute; Chan-Zuckerberg Initiative
</small></p></li>
<li><p><strong>Jane Roe</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/XXXX-XXXX-XXXX-XXXX">XXXX-XXXX-XXXX-XXXX</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/janeroe%20(PLEASE%20COPY/PASTE%20DO%20NOT%20EDIT%20THIS%20ONE)">janeroe (PLEASE COPY/PASTE DO NOT EDIT THIS ONE)</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/XXX">XXX</a><br>
<small>
Department of Something, University of Whatever; Department of Whatever, University of Something
· Funded by XX
</small></p></li>
<li><p><strong>Ricard Argelaguet</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3199-3722">0000-0003-3199-3722</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/rargelaguet">rargelaguet</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/RArgelaguet">RArgelaguet</a><br>
<small>
European Bioinformatics Institute (EMBL-EBI)
· Funded by EMBL PhD programme
</small></p></li>
</ul>
<h1 id="draft-outline">Draft outline</h1>
<p>Full outline described in 01.outline.md as comment if you need to go back to the big picture.</p>
<!---
![Main challenges discussed during our brainstorming sessions from the hackathons.](images/Outline.png){#fig:outline}


## Introduction [Figure 1 outline]

### Comprehensive characterization of biological systems with multi-omics
 - Single cell community has advanced technologies to enable concurrent processing of biological systems at multiple molecular resolutions
 - The lack of prior knowledge and gold standard benchmark naturally leads to a data-driven approach

### New single cell multi omics initiatives:
 - Human Cell Atlas (HCA): assess variation in normal tissues
 - Brain initiative and Allen Brain
 - Human Tumor Atlas Network (HTAN): Single-cell, longitudinal, and clinical outcomes atlases of cancer transitions for diverse tumor types.

### What bulk multi-omics (e.g. TCGA, ENCODE) have taught us:
 - Type of omics that can answer a specific biological question
 - The value of open resources for methodological developments
 - New hypotheses

### Using hackathons to illustrate analysis standards and challenges for capturing biological information from multi-omics technologies
 - Brief overview of our three hackathon studies highlighting state of the art challenges (e.g., spatial transcriptomics, cross-study analysis, epigenetic regulation)
 - Challenges include issues with noise and experimental design, Time lag between regulatory levels not addressed and many open questions
remain (e.g methylation / gene expression), Direction of regulation not captured
 - We present our findings from hackathon case studies that helped us obtain benchmarks and define a common language for multi-omics



## Hackathon case studies

### scRNA-seq + seqFISH as a case study for spatial transcriptomics [Figure 2 results]
#### Overview and biological question
#### Main challenges and how it was overcome by the participants
- Challenge 1: overlay of scRNA-seq onto seqFISH for resolution enhancement
- Challenge 2: determine signatures of cellular co-localization or spatial coordinates in non-spatial scRNA-seq


### Spatial proteomics and cross-study analysis [Figure 3 results]
#### Overview and biological question
#### Main challenges and how it was overcome by the participants
- Challenge 1: address the lack of overlap between proteins across studies
- Challenge 2: spatial protein expression analysis

### scNMT-seq as a case-study for epigenetic regulation [Figure 4 results], lead: Ricard Argelaguet
#### Overview and biological question
#### Main challenges and how it was overcome by the participants
- Challenge 1: defining genomic features
- Challenge 2: DNA methylation imputation
- Challenge 3: Linking epigenetic features / chromatin accessibility to gene expression


## Analytical approaches for hackathons and commonalities for multi-omics analysis illustrated by the series of hackathons [Figure 5 + Table 1]

Short introduction explaining that we focus here on the common challenges across hackathons

### Summary of hackathon study-specific methods
 - Table describes method, foundation in the context of previous bulk and single cell literature, and technology dependence
    - Attempts to tweak existing methods and challenges associated in hackathons
    - List methods that are either technology dependent (e.g. spatial) vs universal and how to choose them


### Dependence on pre-processing method and/or variable selection
- These steps are key and affect downstream analyses
  - Normalization / data transformation (seqFish), pre-processing, gene summaries (scNMT-seq) to variable selection (seqFish)
  - reproducibility difficult / no consensus. e.g. Alexis selected 19 genes whereas Zhu original paper based on 47 genes (difference in methods / processed data)
- Hackathon data pre-processed enable better comparisons across methods
- No consensus reached as those are emerging data with no ground truth nor established biological results

### Approaches for partial overlap of information (cells / features) and how to predict (cell type, dataset) using another data set
- Overlap in each study
  - seqFish: same features but not cells; scProt: same proteins, not cells but similar patients; scNMT-seq: same cells but not features
  - How it was solved (Table)
- Anchoring information across datasets or studies is needed (Figure)
- Incorporation of existing biological knowledge
  - ‘From discovery to detection’ (Meuleman + debrief), time is ripe to include more knowledge in our data driven approaches
- Challenge: Partial cell overlap (but no features matching) and No overlap were not addressed

### Managing differences in scale and size for datasets that do not match cells or features
- Hackathons datasets did not match cells or features.
  - scNMTQ-seq: MOFA limitation when # features vary (and size of datasets).
  - seqFish: greedy approach to select the best gene subset (Alexis, size); consider batch effect removal method (Amrit, scale)

- Consensus on projection based methods, even if pre-processing was applied (Table)
- Additional weighting is needed (e.g. Arora, Abadi).


## Interpretation challenges [Table 2: Glossary of terms]

### Interpretation requires a good understanding of the methods
- Glossary needed for communication
- Incorporation of contiguous information to facilitate interpretation of analytical results
- Biological knowledge and incorporation of information from databases are important, including bridges to data bases (KEGG, Gene Ontology, HCA) to validate through complementary data.

### Visualization tools for interpretation and communication
- Example: tSNE/ UMAP.

### Explaining results to biologists through generative models and simulations
- Example: factor analysis.

### Issues of over-discretization (premature-summarization) and over-simplification
- Example: notion of cell-type is insufficient (rare cell types vs. more “continuous” view on cell types).
- Problem with loss of information in the desire to simplify.
- Over interpretation / over reliance of graphical outputs


## Benchmarking in gold standard datasets [Figure 6, Table 3]

### Definition of benchmarking
- Goal 1: recovery of known cell types (processing of raw data, quantification, and clustering)
- Goal 2: benchmark methods for their ability to discover known relationships between data modalities, e.g. gene regulatory relationships observed between chromatin accessibility and gene expression (relationships are not fully known at the single cell level).

### Strategies for benchmarking
- Simulation useful for known truth, but difficult to simulate realistic covariance structure across features and across data modalities.
- Benchmarking datasets for single cell studies (Table): limited focus on sequencing depth and diversity of cell types derived from a single assay:
ground truth for the intended effect of exposure in a proposed study design.
validation for a data integration task for which a new computational method may be proposed.
- Multi-modal assays benchmarking:
- Design to address biological question (co-embedding, mapping or correlation, and inferring causal relationships).
- Design for either data integration or further downstream analyses (e.g. differential analysis)
- Study design should take into account:
  - Biological and technical variability via replicates, block design, and randomization.
  - Power analysis for the intended effect or data integration task.
  - Dependencies between modalities.
- Challenge: No universal benchmark data scheme suits every combination of modality, benchmark datasets may be established for commonly used combinations of modalities or technologies, towards specific data integration tasks.

### Hackathons
- Cross-validation within study can be performed via Hackathons, e.g. cross-validation analysis of the scNMT-seq dataset using MOFA+
- Assess if relationships discovered in one dataset present in other datasets, potentially looking across single cell and bulk.
- Challenge: how to match dimensions of latent space across folds. (examples: permutation or cross-validation to assess model performance)

## Software infrastructure [Figure 7, Table 4]

### Key questions

- Q1: How should multimodal single cell data be managed for interactive and batch analyses?
- Q2: What methods will help software developers create scalable solutions for multimodal single cell analysis?
- Q3: How can we ensure that visualization methods that are central to multimodal single cell analysis are usable by researchers with visual impairments?

### Data management strategies

- Abstract data type with “multiassay experiment”:
  - each mode =  different collection of features on possibly non-overlapping collections of samples;  
  - metadata on features conventionally defined
  - metadata on samples include all relevant information on experimental conditions.
- Data container for a multi assay analysis:  
  - assays from the same cells, or measurements from distinct cells.
  - Assay slots containing variables or features from multiple modalities (e.g. gene expression units from scRNA-seq and protein units from sc-proteomics), feature may be multidimensional (e.g. spatial coordinates, locations of eQTLs).
- Map between the different assays to enable analysis

### Scalability strategies

- Reducing barriers to interpretable visualizations
- Color is a powerful data visualization tool to represent complex and rich scientific data.
- Color vision deficiencies affect a substantial portion of the population. Include colorblind friendly visualizations [1] as a default setting in our visualizations


## Future directions

### What do we need for the future computation of multi omics single cell

### Upcoming cell atlases technologies

- What is coming?
- how they provide contexts for experimental perturbations
- How they provide context for novel datasets

### Unifying analysis goals for new computational methods

### Moving towards spatiotemporal omics and integration with mathematical models.

--->
<h2 id="figures-tables-and-online-resources">Figures, Tables and online resources</h2>
<h3 id="figures">Figures</h3>
<ul>
<li>Figure 1: Outline of manuscript (Provided below)</li>
<li>Figure 2: scRNA-seq + seqFISH main results</li>
<li>Figure 3: scTargeted proteomics main results</li>
<li>Figure 4: scNMT-seq main results</li>
<li>Figure 5: Illustration of partial overlap between studies (at the cells and / or features level)</li>
<li>Figure 6: Within study cross-validation</li>
<li>Figure 7: Infrastructure of Giotto package as illustration</li>
</ul>
<h3 id="tables">Tables</h3>
<ul>
<li>Table 1: Summary of tasks and methods across all hackathons highlighting methods and common challenges (Provided below)</li>
<li>Table 2: Glossary of terms, consensus terms will be used throughout the manuscript</li>
<li>Table 3: Benchmarking single cell data sets</li>
<li>Table 4: List of single cell analysis software</li>
</ul>
<h3 id="online-resources">Online resources</h3>
<ul>
<li>Online resource 1: Three hackathon datasets (github)</li>
<li>Online resource 2: R packages with open source reproducible vignettes (12 vignettes)</li>
</ul>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<h2 id="introduction">Introduction</h2>
<h3 id="comprehensive-characterization-of-biological-systems-with-multi-omics">Comprehensive characterization of biological systems with multi-omics</h3>
<ul>
<li>Single cell community has advanced technologies to enable concurrent processing of biological systems at multiple molecular resolutions</li>
<li>The lack of prior knowledge and gold standard benchmark naturally leads to a data-driven approach</li>
</ul>
<h3 id="new-single-cell-multi-omics-initiatives">New single cell multi omics initiatives:</h3>
<ul>
<li>Human Cell Atlas (HCA): assess variation in normal tissues</li>
<li>Brain initiative and Allen Brain</li>
<li>Human Tumor Atlas Network (HTAN): Single-cell, longitudinal, and clinical outcomes atlases of cancer transitions for diverse tumor types.</li>
</ul>
<h3 id="what-bulk-multi-omics-e.g.-tcga-encode-have-taught-us">What bulk multi-omics (e.g. TCGA, ENCODE) have taught us:</h3>
<ul>
<li>Type of omics that can answer a specific biological question</li>
<li>The value of open resources for methodological developments</li>
<li>New hypotheses</li>
</ul>
<h3 id="using-hackathons-to-illustrate-analysis-standards-and-challenges-for-capturing-biological-information-from-multi-omics-technologies">Using hackathons to illustrate analysis standards and challenges for capturing biological information from multi-omics technologies</h3>
<ul>
<li><p>Brief overview of our three hackathon studies highlighting state of the art challenges (e.g., spatial transcriptomics, cross-study analysis, epigenetic regulation)</p></li>
<li><p>Challenges include issues with noise and experimental design, Time lag between regulatory levels not addressed and many open questions
remain (e.g methylation / gene expression), Direction of regulation not captured</p></li>
<li><p>We present our findings from hackathon case studies that helped us obtain benchmarks and define a common language for multi-omics</p></li>
<li><p><strong>Objectives of this paper</strong></p>
<ul>
<li>Provide guidelines on tools / data / technologies / methods and needs to model the multi-scale regulatory processes in biological systems for a computational biologist audience</li>
</ul></li>
<li><p><strong>Outline and messages</strong></p>
<ul>
<li>Cellular and molecular regulation is fundamentally multi-scale and captured by distinct data modalities</li>
<li>Traditional hypothesis-driven multi-omics/view studies only consider one facet of these technologies, but more can be learned through a holistic approach extending into atlases</li>
<li>We present our findings from hackathon case studies that helped us obtain a broader picture and language</li>
</ul>
<p>Outline of the paper:</p></li>
</ul>
<div id="fig:outline-again" class="fignos">
<figure>
<img src="images/Outline.png" alt="" /><figcaption><span>Figure 1:</span> Main challenges discussed during our brainstorming sessions from the hackathons.</figcaption>
</figure>
</div>
<h2 id="overview-of-hackathon-studies-to-illustrate-multi-omics-standards-and-challenges">Overview of hackathon studies to illustrate multi-omics standards and challenges</h2>
<p>Multi-omics technologies provide the unique capacity for full spatial and molecular characterization biological systems. In these analyses, each data modality can uniquely resolve specific biological scales from which complementary data integration techniques can resolve multi-scale interactions. In spite of this potential, computational techniques and benchmark strategies for even pairs of datasets across high-throughput measurement technologies remain an active area of research. The hackathon studies at the Mathematical Frameworks for Integrative Analysis of Emerging Biological Data Workshop and described here were tailored to highlight independent challenges of data integration. First, while spatial molecular profiling is rapidly emerging, these technologies often provide lower molecular resolution than non-spatial counterparts. In these cases, integration strategies that merge these datasets have the promise to enhance the molecular resolution of spatially resolved profiling. To address this challenge, We designed a hackathon using spatially resolved transcriptional data from seqFISH with corresponding non-spatial single cell profiling data for the mouse visual cortex from <span class="citation" data-cites="14LoEihpl">[<a href="#ref-14LoEihpl" role="doc-biblioref">1</a>]</span>. A second challenge for multi-omics technologies in cases for which tissue availability limits the ability to obtain multiple measurements in samples from identical conditions. This limitation raises the question as to whether information can be transferred from datasets between disparate sample cohorts. Therefore, we designed the second hackathon to contain two triple negative breast cancer cohorts profiled with single cell proteomics profiling from mass cytometry (CyTOF) <span class="citation" data-cites="bJBIpCn7">[<a href="#ref-bJBIpCn7" role="doc-biblioref">3</a>]</span> and spatial in-situ proteomics from Multiplexed Ion Beam Imaging (MIBI) <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">4</a>]</span>. While each of these hackathons use data at the same molecular scale, genetic and epigenetic alterations to DNA further drive the transcriptional regulation that mediates intra- and inter-cellular signaling processes underlying cellular fate transitions and states. Our third hackathon uses scNMT-seq data to obtain concurrent DNA methylation, chromatin accessibility, and RNA expression from the same cells to delineate the regulatory networks that underlie mouse gastrulation <span class="citation" data-cites="wFwe0y4i">[<a href="#ref-wFwe0y4i" role="doc-biblioref">5</a>]</span>. Altogether, exploration of the analysis approaches employed to address these disparate hackathons across biological contexts provides an unique opportunity to identify technology-specific challenges and unifying themes that are essential to effectively employ multi-omics datasets into new biological knowledge.</p>
<h2 id="scrna-seq-fish-as-a-case-study-for-spatial-transcriptomics">scRNA-seq + FISH as a case study for spatial transcriptomics</h2>
<h3 id="overview-and-biological-question">Overview and biological question</h3>
<p>Single cells are considered the smallest units and building blocks of each tissue, but they still require proper spatial and structural three-dimensional organization in order to assemble into a functional tissue that can exert its physiological function.
In addition, most tissues are composed of multiple cell types whose identity and function can be inferred through their unique transcriptomic profile.
In the last decade single-cell RNA-seq (scRNA-seq) played a key role to capture single cell gene expression profiles, which allowed us to map virtually all the different cell types and states in whole organisms.
Despite this remarkable achievement this technology is based on cellular dissociation and hence does not maintain spatial relationships between single cells.</p>
<p>More recently technologies have begun to emerge that can profile the transcriptome of single cells within their original environment.
These technological advancements offer the possibility to examine how gene expression is influenced by cell-to-cell interactions or organized in a spatially coherent manner.
One such approach is sequential single-molecule fluorescence in situ hybridization (seqFISH), which can identify single molecules at (sub)cellular resolution with high sensitivity.
Nevertheless, and in contrast with scRNAseq, seqFISH and many other spatial transcriptomic technologies often pose significant technological challenges and hence the number of profiled genes per cell is usually restricted to a smaller number (10-100s).</p>
<p>To overcome the lack of spatial information with scRNAseq and the common limited coverage in spatial datasets, we sought to combine and integrate a matching scRNAseq and seqFISH dataset, since both were generated from the mouse visual cortex region.
More specifically, in this hackathon we explored a number of strategies to identify the most likely cell types in the seqfish dataset based on information obtained from the scRNAseq dataset.
And in the opposite direction, we sought out how to transfer spatial information obtained from the seqfish dataset to that of the scRNAseq dataset.</p>
<div id="fig:spatial" class="fignos">
<figure>
<img src="images/seqFish_mockup.png" alt="" /><figcaption><span>Figure 2:</span> Overview of analysis. <em>note: letters order can be changed</em> <strong>A</strong> A spatial network was built from cells’ positions using Voronoi tessellation, whilst cell types were inferred from an SVM trained on scRNAseq data. Left: The neighbors aggregation method described in [challenge 2] computes aggregation statistics such as mean or standard deviation on the seqFISH gene expression data for each node and its first order neighbors. Right: This approach identified spatially coherent areas that can contain one or several cell types, and can be used to detect genes whose expression is modulated by spatial factors rather than cell type.<strong>
</strong>B** Assessment of cell type prediction using different normalization techniques and classifiers. Results performance (based on what?)are projected on a PCA plot, showing that methods that integration information from both seqFish and scRNAseq are distinct from methods that do not (along the x-axis). (<strong>Amrit, figure still in discussion</strong>)
<strong>C</strong> <strong>Caption missing, Josh</strong>
<strong>D</strong> Challenge 2: what is the minimal number of genes required for data integration? SVM classification models (C=1e-6, C=1e-3, C=1) were trained and evaluated with different number of genes in scRNAseq data using Recursive Feature Elimination (RFE). The results show that a small (<em>do you mean smaller that the original study?</em>) gene list to identify cell types in both data types, but the lack of goad standard hinders our ability to evaluate the relevance of such genes. <strong>Hang</strong>
.</figcaption>
</figure>
</div>
<h3 id="computational-challenges">Computational challenges</h3>
<h4 id="challenge-1-overlay-of-scrna-seq-onto-seqfish-for-resolution-enhancement">Challenge 1: overlay of scRNA-seq onto seqFISH for resolution enhancement</h4>
<p><strong>[suggestion 1]</strong><br />
Sequencing and imaging based single-cell transcriptomic profiling have complementary strengths.
Whereas single-cell RNAseq generates transcriptome-wide information, it does not have spatial information.
On the other hand, seqFISH (Lubeck 2014; Shah 2016) provides single-cell resolution spatial information, but typically profiles the expression level of only 100-300 genes.
Although the newer generation of seqFISH technology (called seqFISH+) has greatly enhanced its capacity which can now be used to profile 10,000 genes (Eng 2019), the technology is significantly more complex and costly.
As such, it is desirable to develop computational approaches to effectively integrate scRNAseq and seqFISH data analyses.</p>
<p>In this hackathon, the participants were provided with seqFISH (Zhu 2018) and scRNAseq (Tasic 2016) data corresponding to the mouse visual cortex and challenged to accurately identify cell-types by integrating both datasets.
Cell type labels, derived from scRNAseq analysis (Tasic 2016) and previous seqFISH/scRNAseq integration (Zhu 2018) were also provided as reference.
A variety of computational approaches were applied to achieve this goal, including: supervised classification with support vector machines (Coullomb, Xu), semi-supervised self-training (Singh), and unsupervised matrix factorization methods (Sodicoff) (Figure <a href="#fig:spatial">2</a>).
While the methodologies are different, a number of themes recur, such as the importance of gene selection and batch effect correction.
As expected, the ability to identify refined cell-type structure relies on the selection of cell-type specific marker genes in seqFISH data, suggesting a potential benefit of using single-cell RNAseq data to guide seqFISH experimental design.
Batch effect is another important factor affecting the accuracy of data integration.
While a number of batch effect correction methods have been developed (COMBAT, Seurat, Scanorama, etc), it remains challenging to distinguish technical from biological variations if the biological samples do not match exactly.</p>
<p><strong>[suggestion 2]</strong><br />
The mouse visual cortex consists of multiple complex cell types, however the number of profiled genes in the seqFISH dataset is limited to 125 genes.
Moreover, these genes were not prioritized based on their ability to discriminate between cell types and thus assigning the correct cell identity is challenging.
In contrast the scRNAseq dataset is transcriptome wide, thus including the 125 aforementioned genes.
As such we first used all genes to identify the cell type labels for each cell in the scRNAseq data with high certainty.
Next, we leveraged that information to build a classifier based on (a subset of) the 125 common genes only.
This classifier could subsequently be applied to the seqFISH dataset in order to assign cell types to each cell with high probability.</p>
<p>During the hackathon we tested various machine learning or data integration models, but also noted that initial dataset normalization strategies might have a significant impact on the final results (see common challenges <span class="citation" data-cites="Amrith">[<span class="citeproc-not-found" data-reference-id="Amrith"><strong>???</strong></span>]</span>).
Although unique molecular identifier (UMI) based scRNAseq and seqFISH can both be considered as count data, we observed dataset specific biases that could be attributed to either platform (imaging vs sequencing) or sample specific sources of variation.
Here we opted to apply a quantile normalization approach which forces a similar expression distribution for each shared gene.</p>
<p>The hackathon participants selected two machine learning classifiers, a supervised support vector machine (SVM) and a semi-supervised lasso and elastic-net regularized generalized linear model (glmnet).
To further improve the SVM model the participants tried multiple kernels and searched for optimal hyperparameters using a combined randomized and zoomed search.
In addition, different flavors of recursive feature elimination was used to find the optimal or minimum number of genes needed to correctly classify the majority of the cells.
Importantly, participants tested different classification accuracy metrics to alleviate the major class imbalance in the dataset, since more than 90% of cells were excitatory or inhibitory neurons.
The glmnet approach used a iterative model building approach, which combines both datasets and initially only retains the highest confidence labels and then gradually adds more cell type labels until all cells have been classified.
This type of self training approach might in fact be more generalizable to other datasets.</p>
<p>Finally, a data integration approach based on integrative non-negative matrix factorization (NMF) was used by applying the previously published LIGER approach.
By integrating both datasets in a similar subspace based on shared factors, cell type labels can be transferred using a nearest neighbor approach.</p>
<h4 id="challenge-2-determine-signatures-of-cellular-co-localization-or-spatial-coordinates-in-non-spatial-scrna-seq">Challenge 2: determine signatures of cellular co-localization or spatial coordinates in non-spatial scRNA-seq</h4>
<p><strong>[suggestion 1]</strong><br />
How could one identify spatial patterns in the seqFISH data? This broad question can be divided into a number of specific tasks, such as detecting genes whose expression is spatially coherent, cell types whose spatial distribution is confined to distinct regions, recurrent multi-cell-type interaction clusters, etc, and the spatial scale may vary from subcellular all the way to tissue-wide organizations.
While there have been abundant studies in the geo-spatial analysis domain, computational tools targeting specific spatial transcriptomic questions are still lacking.
In this hackathon, one group tackled this challenge by aggregating gene expression data from neighboring cells followed by spatial clustering (Coullomb).
Much more work in the future is need to further explore such information.</p>
<p><strong>[suggestion 2]</strong><br />
Most analyses that were originally developed for scRNAseq data can be immediately applied to spatial transcriptomic datasets, however methods to extract sources of variation that originate from spatial factors are still sparse.
To incorporate spatial information the cells from the seqFISH dataset were first connected through a spatial network based on Voronoi tessellation and then the expression of each individual cell was spatially smoothed by calculating the average gene expression levels over all the neighboring cells.
This smoothened and aggregated data matrix was subsequently used to create a 2 dimensional UMAP from which clusters were identified through a density based clustering approach.
The obtained cluster labels can then be mapped back to the original spatial locations for further visual inspection and analysis.</p>
<p><strong>[suggestion 2 detailed]</strong><br />
Most analyses that were originally developed for scRNAseq data can be immediately applied to spatial transcriptomic datasets, however methods to extract sources of variation that originate from spatial factors are still sparse.
In order to take into account both gene expression data and spatial information, the cells from the seqFISH dataset were first connected through a spatial network based on Voronoi tessellation.
Then, for each node, its RNA count data was aggregated with its first order neighbors’ count data.
The mean and standard deviation were computed for each gene in the gathered data in order to capture the global tendency as well as the variability in the area arround each node.
Thus, each node has <code>nb_genes x nb_statistics (here 2)</code> variables.
These “aggregation statistics” can be visualized on a 2D UMAP projection.
These data were clustered in UMAP reduced spaces of dimensionality between 2 and 9, higher dimensions allowing to define more fine-grained clusters.
The clustering was performed with HDBSCAN, a noise-aware density-based algorithm that can define arbitrary-shaped clusters.
These clusters can then be visualized on the 2D UMAP projection and on the 2D spatial map of seqFISH data.
The clusters are spatially coherent, some of them contain several cell types, and a given cell type is not necessarily limited to one specific cluster.
During the exploratory phase consisting in varying the number of dimensions and the minium cluster size, a specific spot area was found clustered for several parameters combinations, suggesting it wasn’t an artifact of the choice of parameters.
“Differential expression” analysis was performed between this spot and the other areas, although we don’t look at differences in gene data but in aggregation metrics.
This area seems to correspond to a “regeneration hub”, but this analysis has to be considered carefully and further analyzes is required to confirm this hypothesis.
This “neighbors aggregation” method has been extended to aggregate RNA counts (or other node attributes) to higher orders of neighbors in order to define aggregation metrics on wider areas, which could be useful for analyzes of bigger tissues.
One interesting extension would be to substract phenotypes contributions to RNA counts for each cell before performing the neighbors aggregation analysis in order to highlight genes that are modulated by spatial factors.
But if we want to retrieve the mean expression of a cluster for cells belonging to it, we should first check cluster’s convexity and be sure that no other cluster lies within it.</p>
<h2 id="spatial-proteomics-and-cross-study-analysis">Spatial proteomics and cross-study analysis</h2>
<h3 id="overview-and-biological-question-1">Overview and biological question</h3>
<p>The single-cell targeted proteomics hackathon investigated the tumor-immune microenvironment of primary breast cancer tissue.
The challenge was the joint cross-study, cross-platform integrative analysis of single cell proteomics data that had low feature overlap, were generated on different antibody-based targeted proteomics technological platforms and in different laboratories [1, 2].
Mass cytometry (CyTOF) from Wagner et al. <span class="citation" data-cites="bJBIpCn7">[<a href="#ref-bJBIpCn7" role="doc-biblioref">3</a>]</span> measured 73 proteins in two panels (immune, tumor) in 194 tissue samples from 143 subjects, of which 6 patients had triple-negative negative breast cancer.
The second dataset applied Multiplexed Ion Beam Imaging (MIBI) to quantify spatial in-situ expression of 36 proteins in 41 triple-negative breast cancer patients <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">4</a>]</span>. <a href="#fig:proteomics">3</a></p>
<p>Whilst this is a formidable data integration challenge, it reflects the bioinformatics analysis of clinical teams who wish to compare and investigate data collected on different cohorts of cancer patients.
The first questions simply asked if partially-overlapping proteomic data collected on different patients with similar phenotypes could be integrated, and asked participants to test if measurements in one technology could be transferred and used to predict information in the second.
The MIBI data provided spatial location and expression of proteins, therefore the challenge asked if the spatial expression patterns of proteins measured on mass-tag could be predicted.
Secondly it raised questions unique to spatial ’omics technologies.
Does spatial capture unique information, beyond cell compositions.
Could information about the spatial location of immune cell populations in breast cancer be discovered in integrated analyses of these datasets.
Finally the datasets had no overlap in patients, so how could heterogeneous phenotype information be used to integrate patient ‘omics data with low feature and no tumor biological sample overlap.</p>
<div id="fig:proteomics" class="fignos">
<figure>
<img src="images/scProt_mockup.png" alt="" /><figcaption><span>Figure 3:</span> <strong>A</strong> sc_targeted proteins hackathon challenge (<strong>Kris to simplify or merge with B</strong>).
<strong>B</strong> Challenge 1: Lack of overlap between protein features across studies (<strong>update with color friendly color</strong>).
<strong>C</strong> Challenge 2: Spatial analysis with Moran’s index: Moran’s index is a computed on Gabriel graph (using both dummy variables and protein expression measurements) and differs significantly between groups.
Figure shows boxplot of Moran’s index values on tumor/immune dummy variable with examples from Keren et al. <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">4</a>]</span> corresponding to each tumor category.
Red asterisks indicate significance of an ANOVA of each group with all others, and the p-value from an overall ANOVA across the three groups is reported above.
<strong>D</strong> Challenge 3: Partial overlap of data (<strong>Kris to avoid overlap with common challenge Fig 5 or remove</strong>).</figcaption>
</figure>
</div>
<h3 id="computational-challenges-1">Computational challenges</h3>
<h4 id="challenge-1-lack-of-overlap-between-protein-features-across-studies">Challenge 1: Lack of overlap between protein features across studies</h4>
<p>The low number of features precluded integration of features at the level of gene set or pathways.
There were only 20 proteins that were assayed in both studies (Figure <a href="#fig:proteomics">3</a>A-B).
The majority of features were cell-type markers or biomarkers targets of breast cancer therapeutic intervention.
The limited overlap in these studies necessitated the use of surrogate measures of cross- study association.</p>
<p>Although the overlap in proteins was low, many proteins were cell-type markers, providing the opportunity to perform cross-study integration of cell type proportions in tumor tissue samples.
Hackathon participants applied several semi-supervised and supervised algorithms to transfer cell labels and cell compositions from one dataset to the second.
To capture the hierarchical structure of cell lineage, Lauren Hsu (Harvard) applied a simple random forest (RF) approach to perform feature transfer learning of cell type labels.
An adaptation of the prediction strength approach described in Tibshirani <span class="citation" data-cites="gbdea2Ea">[<a href="#ref-gbdea2Ea" role="doc-biblioref">6</a>]</span> demonstrated model robustness: first, a model was trained on the labeled dataset and used to predict labels in the unlabeled dataset; next, a second model was trained based on the second dataset with the newly predicted labels; finally, she assessed the ability of the second model to recover the correct original labels when making predictions on the labeled dataset.</p>
<p>Yingxin Lin (Univ of Sydney) mapped the cells from CyTOF to imaging with spatial information by solving an entropic regularization optimal transport problem [4, 11], utilising the cosine distance of the common proteins between the two datasets as transport cost.
The constructed optimal transport plan can be considered as likelihood of cells from one modality mapped to cells from the other modality, which allows the prediction of protein expression measured only in CyTOF on imaging data.
By clustering on the imputed expression matrix, she was able to identify a sub tumour cell type that is not revealed in the original matrix.</p>
<p>However the scales of protein expression was a possible limiting factors When integrating cell compositions using the correlation expression of protein markers, some cell markers were expected on a range of cell types (e.g., CD45), whereas others are more specialized and represent a subset of those cells (e.g., CD4).
Others challenges associated with cell compositions analysis of proteomics analysis included uncertainty over antibody specificity and consistency between studies, the sensitivity and specificity of protein markers for cell types, tissue and disease heterogeneity</p>
<p>The assignment of cell type relied on manually curated protein annotation, and was dependent on domain-specific knowledge; for example that CD4 is expressed by T-cells.
To date, methods for cell type assignment, classification or extraction of differentially expressed proteins cannot easily be applied to targeted proteomics.
Participants expressed a need for a unifying map between cells present in different datasets, and for annotation resources to provide quality metric or priors of protein cell type markers.
There is a need for protein expression atlases to support cell type classification and potentially if this could be developed from large scale consortiums IHC of proteins (Human Protein Atlas [5, 6]), although the antibodies used and their performances might vary between labs.</p>
<p>Standards/QC/Normalization</p>
<h4 id="challenge-2-spatial-protein-expression-analysis">Challenge 2: spatial protein expression analysis</h4>
<p>Whereas the CyToF mass spectrometry provided protein expression and counts/composition of cells in breast tumor-immune environment, the MIBI-TOF data provided spatial information that quantified cell attributes (shape/size/spatial coordinates) in addition to expression levels, thus providing the opportunity to examine protein expression, cell microenvironment, and predict cell-cell interactions and the cellular community ecosystem.</p>
<p>Spatial information can be encoded as a set of XY coordinates (cell centroid), a line (eg tumor-immune boundary) or a polygon, which is a closed plane defined by a number of lines.
A polygon can define complex shapes such as a cell or a community of cells.
Spatial protein expression can be summarized using spatial descriptive statistics, such as the autocorrelation of the expression of a protein within a neighborhood of polygons.
The neighborhood of polygons can be defined with a Euclidean distance or sphere, by a number of bounded cells or other measures, many of which were developed in geographical information science or ecology and assess if a spatially measured variable has a random, dispersed or clustered pattern [7].</p>
<p>Kris Sankaran examined the extent to which expression data could be used to predict spatial properties of tissue samples.
To build predictors, cells were first clustered (K = 20) on the basis of protein expression.
Sample-level expression summaries were defined as the proportions of cells belonging to each cluster.
To build the spatial response variables, a K-nearest neighbor graph was obtained from cell centroids (K = 5).
For each cell, the average distance to its 5 nearest neighbors was computed, reflecting its local density.
Further, the entropy of the cluster memberships across nearest neighbors was found, reflecting local heterogeneity.
To summarize samples’ cell ecosystems, cell-level statistics were averaged across each sample’s cells.
A random forest model trained from expression to spatial predictors achieved an average cross validation RMSEs of (tk ) for neighborhood size and entropy, respectively, relative to baselines of () obtainable by predicting the mean.</p>
<p>Dr. Pratheepa Jeganathan applied topic modelling and defined five topic trained on protein expression and cell compositions in the CyToF data were sufficient to predict cell co-locations, in 10% MIBI-ToF Test data.
Pratheepa Jeganathan (Stanford) applied a Bayesian modelling approach based on latent Dirichlet allocation (Blei, Latent dirichlet allocation Journal of machine Learning research 3.Jan (2003): 993-1022).
Topic modeling was used to identify the dominated topics and assign
spatial location of MIBI-TOF cells to the CyTOF data or vice-versa, based on the topic distribution in each cell (<strong>Ref topic modelling?</strong>).
Among the five topics identified, the first topic was dominated in most of the immune cells from CyTOF data and the other four dominated in all other cells.
Cells from MIBI-TOF were depicted in five clusters (link to vignette) and were consistently based on the observed and predicted marker expression, but these clusters were not identified with only observed marker expressions.
[ further details from Pratheepa available in pdf file in debrief folder]</p>
<p>Yingxin Lin (Sydney) examined the prognostic performance of different higher level spatial metrics.
She measured protein autocorrelation using Moran’s Index (I) with a sphere distance, cell type localisation using nearest neighbour correlation, or cell type interaction composition, Ripley’s L-function.
High-dimensional Cox models with fused lasso penalty and random forest survival models were fitted utilising different features, including clinical features such as tumour stage, tumour grade, age and tumour size, as well as features like cell type composition.
Evaluating by the c-index via cross-validation, the spatial metrics are found to be predictive, especially in triple negative breast cancer where clinical features such as grade are poorly prognostic.</p>
<p>Lauren Hsu (Harvard) also considered Moran’s I but used a graph-based neighborhood measure (Gabriel graph, based on Delaunay triangulation) instead of a sphere euclidean distance, and found that Moran’s I differed significantly between the three prognostic tumor scores described by Keren, et al. <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">4</a>]</span>(Figure <a href="#fig:proteomics">3</a>C).</p>
<p>Need for development of spatial measure - different in dimensions of RNA v proteins</p>
<h4 id="challenge-3-fourth-corner-integration-of-data-at-the-level-of-phenotype">Challenge 3: Fourth corner Integration of data (at the level of phenotype)</h4>
<p>Another question often faced in cross-study integration is integration of biological samples that are non-overlapping but have similar phenotypes.
The aim is to identify biomarkers from the different omics data to predict the same phenotype, and, more importantly, to explore how the markers selected from multiple datasets are in agreement with or distinct from each other.
The integration of the markers from each dataset should enable to extend biological knowledge that is not available by single omics data.
To solve the challenge, phenotypical data (such as the cell attributes) are the critical factors that should be used to link the two datasets (Figure <a href="#fig:proteomics">3</a>D).</p>
<p>The participants were successful at data integration using patient phenotype measures such as grade, stage and overall survival.
Breast cancer is highly heterogeneous, and multiple breast cancer molecular subtypes have been described [8, 9].
Both MIBI and Jackson data used different approaches to cell type annotation and had 13 proteins in common.</p>
<!-- Yingxin. MIBI, Jackson data.  13 proteins in common and both had used different approaches to cell type annotation, optimal transport.  KM curve Fig 1e?  
benchmarking datasets - Jackson. Assessment of biological relevance/success of methods -->
<p>Borrowing from ecology and french school of ordination, Chen Meng (Munich) described this problem as a case of the fourth corner problem (or RLQ).
Briefly, given two omics data where both rows (features) and columns (samples) are non overlapping, and phenotypical data available for each omics data, multiplying the two phenotypical factors will derive a bridging matrix that links the features of two omics data.
We should note that the two phenotypical matrices need to be multipliable, i.e. the phenotypical data should describe the same phenotypical factors over the samples in the corresponding dataset.
The Chessel fourth corner RLQ is a matrix decomposition method to solve the problem [<span class="citation" data-cites="KsY7PFJ8"><a href="#ref-KsY7PFJ8" role="doc-biblioref">7</a></span>; doi:10.1111/ecog.02302].
It decomposes the bridging matrix (phenotypical matrix) into components, each of which often represents a specific phenotypical pattern in the data.
The loading matrix of each of the omics data indicate how a feature is correlated with phenotypical factors.</p>
<h3 id="summary">Summary</h3>
<p><strong>this could be included in other section</strong></p>
<p>In contrast to traditional fine resolution of mapping individual genes or features between studies, the proteomics challenge investigated hierarchical structure among the ’omics, cell and phenotype layers and applied a number of measures of higher order concordance to integrate cross study.
Different questions asked from different angles based on the dataset:Integration, clinical, spatial</p>
<p>Extraction “real” and “abstract feature” space were applied in data integrations.
Abstract lower dimensional representations of spatial coordinates successfully captured higher level cellular structure and were more prognostics that individual feature information, suggesting that new measures of the tumor or cell ecosystems of interacting cells are needed because these interactions are fundamental to disease progression.
These efforts will require standardized vocabulary, benchmarked methods, and common abstracted variables that can be compared between studies.
Vital to these will be defining a new cell and cell community annotations, <strong>DUNCAN</strong></p>
<p>The field will need to define vocabulary and relationships between different scales, when integrating high definition fine-resolution feature level, or subcellular molecular data with global, coarse or lower-resolution bulk data, however integrating of spatial information and of data across scale is not unique to biology.
Similar spatial and scales issues have been addressed in environmental ecology, weather science and geographical information system analysis.</p>
<p>Future Limitation of channels - Single cell mass spec v spatial antibody</p>
<h2 id="scnmt-seq-as-a-case-study-for-epigenetic-regulation">scNMT-seq as a case-study for epigenetic regulation</h2>
<h3 id="overview-and-biological-question-2">Overview and biological question</h3>
<p>The maturation of single-cell sequencing technologies has enabled the identification of transcriptional profiles associated with lineage diversification and cell fate commitment<span class="citation" data-cites="8vGho6cJ">[<a href="#ref-8vGho6cJ" role="doc-biblioref">8</a>]</span>. Yet, the accompanying epigenetic changes and the role of epigenetic layers in driving cell fate decisions still remains poorly understood<span class="citation" data-cites="3QdXjbeH">[<a href="#ref-3QdXjbeH" role="doc-biblioref">9</a>]</span>.</p>
<p>scNMT-seq is one of the first experimental protocols that enable simultaneous quantification of RNA expression and epigenetic information from individual cells<span class="citation" data-cites="1FWgnoNlO">[<a href="#ref-1FWgnoNlO" role="doc-biblioref">10</a>]</span>. Briefly, in scNMT-seq cells are incubated with a GpC methyltransferase enzyme that labels accessible GpC sites via DNA methylation. Thus, after bisulfite sequencing, GpC methylation marks can be interpreted as direct readouts for chromatin accessibility. This stands in contrast to CpG methylation marks, which can be interpreted as endogenous DNA methylation. In addition, by physically separating the genomic DNA from the mRNA, scNMT-seq can profile RNA expression, DNA methylation and chromatin accessibility readouts from the same cell.</p>
<h3 id="data-set-description">Data set description</h3>
<p>Gastrulation marks a major lineage specification event in mammalian embryos, accompanied by profound transcriptional rewiring and epigenetic remodelling <span class="citation" data-cites="wFwe0y4i">[<a href="#ref-wFwe0y4i" role="doc-biblioref">5</a>]</span>. scRNA-seq studies have identified major transcriptional changes associated with cell fate commitment, but the accompanying epigenetic reprogramming and the coordination between different epigenetic layers remains poorly understood.</p>
<p>In this hackaton we used a data set where scNMT-seq was applied to mouse gastrulation <span class="citation" data-cites="1H9T8tTsB">[<a href="#ref-1H9T8tTsB" role="doc-biblioref">11</a>]</span>. A total of 749 cells across four developmental stages (E4.5 to E7.5) passed quality control for all three data modalities. For simplicity, in the workshop we focused on the integration of RNA expression and DNA methylation, quantified over the following genomic contexts: gene bodies (D=15837), promoters (D=12092), CpG islands (D=5536), p300 binding sites (D=101), CTCF binding sites (D=175) and DHS (D=66) open sites.</p>
<p>Applying standard dimensionality reduction algorithms confirms that all three embryonic stages can be separated on the basis of RNA expression. The task of the workshop was to evaluate whether the same stages can also be discerned on the basis of DNA methylation.</p>
<h3 id="computational-integration">Computational integration</h3>
<p>We considered three computational strategies:</p>
<ul>
<li><strong>PLS (as implemented in DIABLO<span class="citation" data-cites="cZOVX9E7">[<a href="#ref-cZOVX9E7" role="doc-biblioref">12</a>]</span>):</strong> projection to least squares model. A sparse generalisation of canonical correlation analysis that maximises covariation between prespecified pairs of data modalities.</li>
<li><strong>LIGER</strong> <span class="citation" data-cites="MaZsghuS">[<a href="#ref-MaZsghuS" role="doc-biblioref">13</a>]</span>: unsupervised non-negative matrix factorisation model for manifold alignment. It assumes a common feature space by aggregating DNA methylation over gene-centric elements (promoters or gene bodies) but allows cells to vary between data modalities.<br />
</li>
<li><strong>MOSAIC</strong> [XXX]: a multi-omics supervised clustering algorithm inspired from <code>survClust</code>.</li>
</ul>
<h3 id="computational-challenges-2">Computational challenges</h3>
<h4 id="challenge-1-defining-genomic-features">Challenge 1: defining genomic features</h4>
<p>The first challenge concerns the definition of the input data. The output of single-cell bisulfite sequencing are binary DNA methylation measurements for individual CpG sites. Integrative analysis at the CpG level is extremely challenging due to (1) the sparsity levels, (2) the binary nature of the readouts, and (3) the challenging interpretability of individual dinucleotides.
To address these problems, DNA methylation measurements are typically aggregated over predefined sets of genomic elements (i.e. promoters, enhancers, etc.). This preprocessing step reduces sparsity, permits the calculation of binomial rates that are approximately continuous and can also improve interpretability of the input features.</p>
<p>There are two common strategies to define genomic elements. The first one is to use a running window approach across the entire genome. This strategy has been succesful to distinguish heterogeneous cell types, but it does not improve interpretabiliy and it leads to a massively large feature set. The alternative strategy is to adopt a supervised approach where ChIP-seq data or chromatin accessibility information is employed to restrict the feature space to genomic regions of regulatory potential.</p>
<!-- n our results we observe remarkable differences between genomic contexts on the integration performance.  -->
<p>[DESCRIBE RESULTS]</p>
<p>Our results confirm that the appropriate selection of the feature space is critical for a successful integration with RNA expression.</p>
<!-- DESCRIBE REGULATORY CHROMATIN ATLASES -->
<h4 id="challenge-2-missing-values-in-dna-methylation">Challenge 2: Missing values in DNA methylation</h4>
<p>Because of the low amounts of starting material, single-cell bisulfite sequencing protocols are limited by incomplete CpG coverage. Nonetheless, in contrast to scRNA-seq, missing data can be discriminated from dropouts.</p>
<p>Two strategies were put forward in the workshop to handle missing values. The first is to define an inference framework that omits missing values, as done in PLS and MOSAIC. The second approach, for methods that do not handle missing information, including LIGER, is to perform <em>a priori</em> imputation of DNA methylation values.</p>
<p>Here we compared the integration performance for PLS and MOSAIC with and without imputation. Notably we observe (…)</p>
<p>[DESCRIBE RESULTS]</p>
<h4 id="challenge-3-linking-epigenetic-features-to-gene-expression">Challenge 3: Linking epigenetic features to gene expression</h4>
<p>One of the main advantages of single-cell multi-modal assays is the ability to unbiasedly link epigenetic variation with gene expression.
Transcriptional activation is associated with specific chromatin states near the gene of interest. This includes deposition of activatory histone marks such as H3K27ac (in promoters and enhancers), H3K4me3 (in promoters) and H3K36me3 (in gene bodies), binding of transcription factors, promoter and/or enhancer demethylation and chromatin remodelling. All these events are closely interconnected and leave a footprint across multiple molecular layers that can be (partialy) recovered by performing an association analysis between a specific chromatin readout and mRNA expression. However, given the large amount of genes and regulatory regions, this task can become prohibitively large and it is mandatory to restrict the feature space to avoid a complex multiple testing problem.</p>
<p>A simple and practical approach from a computational perspective involves considering only putative regulatory elements within each gene’s genomic neighbourhood. Nonetheless, this might miss important links with regulatory elements located far away from the neighbourhood.</p>
<p>In recent years, chromosome conformation capture experiments, have uncovered a complex network of chromatin interactions inside the nucleus connecting regions separated by multiple megabases along the genome and potentially involved in gene regulation. Early genome-wide contact maps generated by HiC uncovered domains spanning on the order of 1 Mb (in humans) within which genes would be coordinately regulated. Thus, a second strategy to associate putative regulatory elements to genes is to build on existing promoter-centered chromatin contact networks to restrict the association analysis to putative regulatory elements that are in 3D contact with genes.
Although this is a promising strategy to reduce the complexity of the association analysis, most of our 3D interaction datasets are produced in bulk samples and it is so far unclear how much of these structures are preserved across individual cells. Single-cell conformation capture experiments are still limited by data sparsity and high levels of technical noise, but we envision that technological advances in this area will deepen our understanding on the regulatory roles of chromatin states.</p>
<h2 id="commonalities-between-analytical-multi-omics-approaches-for-hackathons">Commonalities between analytical multi-omics approaches for hackathons</h2>
<p>We summarize the common main challenges faces across all hackathons, and the common approaches adopted to analyse multi-omics single cell data.</p>
<p>Table ?? summarizes the main methods that were applied across all hackathons. Common main challenges included the assessment of the effect of pre-processing steps (normalization, upstream feature selection), the lack of overlap between cells or features (Figure ??), managing differences in scale across data sets, the application of generic approaches developed for bulk data and adapted for single cell data, study specific approaches for spatial analysis (sc spatial and sc proteomics studies) and the inclusion of additional information. A very large number of methods that were applied derive from bulk RNA-seq literature, with the exception of projection methods such as tSNE, UMAP and LIGER (the latter two also based on the common techniques NMF and PCA that were further developed for single cell data).</p>
<p>The choice of methods that were study-specific relied mostly on the challenge or biological question to address. For example, data integration was moslty addressed using projection approaches across all studies, whilst single cell spatial analysis required specific approaches based on Hidden Markov random field or Moran’s Index (Figure <a href="#fig:proteomics">3</a>B).</p>
<!--
 - **Table** describes method, foundation in the context of previous bulk and single cell literature, and technology dependence
    - Attempts to tweak existing methods and challenges associated in hackathons
    - List methods that are either technology dependent (e.g. spatial) vs universal and how to choose them
-->
<h3 id="dependence-on-pre-processing-method-andor-variable-selection">Dependence on pre-processing method and/or variable selection</h3>
<p>Pre-processing steps strongly affect downstream analyses. Our participants thoroughly assessed the effect of normalisation and data transformation (e.g. sc spatial, Figure <a href="#fig:spatial">2</a>Letter), preliminary feature selection (mostly on based on highly variable genes) or feature summarization (scNMT-seq study). Comparisons between analyses were facilitated by providing processed input data (ref to software section), but such step was not sufficient to face reproducibility issues between the original published study and the new analyses. For example in the sc spatial study, Coullomb selected 19 genes (<em>in scRNA-seq? or seqFISH?</em>) whereas the original paper (incl ref) was based on 47 genes. No consensus was reached regarding what was the best way to process such emerging data, as no ground truth nor established biological results are yet available (ref: section benchmark).</p>
<h3 id="approaches-for-partial-overlap-of-information-cells-features">Approaches for partial overlap of information (cells / features)</h3>
<p>Degree of overlap between datasets varied dramatically within each study. Intuitively, one requires at least one type of overlap (whether on the features, or on cells, Figure ??) in order to integrate information across modalities. The field has made progress in developing methods to integrate data sets across the same (bulk) samples of single cells, mostly based on dimension reduction techniques. Amongst them, NMF (LIGER), Projection to Latent Structures (sGCCA) were used for the scNMT-seq study. When there was no cell overlap (sc spatial, sc proteomics), prediction methods were used to predict gene, protein or spatial expression values based on nearest neighbors, latent variables or optimal transpor, or to predict cell types (Hsu). The most challenging study was the sc proteomics, which raised the potential issue of no overlap between cells or features - the so called fourth corner that relies on phenotypes (ref sc proteomics section). We anticipate that this scenario will be avoided once technological progress and increase in data sets availability is achieved <span class="citation" data-cites="doi">[<span class="citeproc-not-found" data-reference-id="doi"><strong>???</strong></span> 10.1186/s13059-020-1926-6]</span>.</p>
<p><strong>to do: add in table the overlap between cells (i.e. sc NMT-seq)</strong></p>
<!--
- Overlap in each study
  - seqFish: same features but not cells; scProt: same proteins, not cells but similar patients; scNMT-seq: same cells but not features
  - How it was solved (Table)
- Anchoring information across datasets or studies is needed (Figure)
- Incorporation of existing biological knowledge
  - ‘From discovery to detection’ (Meuleman + debrief), time is ripe to include more knowledge in our data driven approaches
- Challenge: Partial cell overlap (but no features matching) and No overlap were not addressed
-->
<h3 id="managing-differences-in-scale-and-size-across-datasets">Managing differences in scale and size across datasets</h3>
<p><strong>potentially move this section higher? and amend order in table</strong></p>
<p>As all studies in our hackathon did not match either cells or features, different types of techniques were used to address the differences in scale or resolution across data sets. For sc spatial and sc proteomics, participants focused on a common set of genes (via feature selection in sc spatial) or proteins. The scNMT-seq study that included overlap between cells raised the issue of differences in data set size (e.g. number of features). Some projection-based methods can be limited in this setting (e.g. MOFA), requiring a similar number of features in each data set, whilst others such as PLS / sGCCA are not limited by such constraint and enabled flexible analysis (Abadi). Difference in data scale may result in one data set contributing to either too much variation or noise during data integration. techniques such as re-scaling (Jenagan), batch effect removal approaches, such as Combat <span class="citation" data-cites="doi">[<span class="citeproc-not-found" data-reference-id="doi"><strong>???</strong></span> 10.1093/biostatistics/kxj037]</span> (Singh), or weighting specific data sets (Arora, Abadi) were considered and all offer further improvement in the analyses.</p>
<figure>
<img src="images/summary_fig_person.png" style="width:50.0%" alt="" /><figcaption>Figure caption: <strong>figure will be updated</strong>
A) scSpatial: required overlap of features (genes), but cells do not overlap. Cell type prediction for seqFISH data was performed based on scRNA-seq (known) [credit: Amrit Singh / Kris S]
B) scProteomics: a small number of features overlap (proteins) but patients and cells do not overlap. Data imputation (?), spatial co-localization or cell type prediction was performed [credit: Lauren Hsu and Pratheepan Jenagan / Kris S]
C) scNMT-seq: cells are matching across assays but features do not overlap. Data integration was performed [credit: Al Abadi / Kris S]
D) Nor cells nor features are matching [credit: Chen Meng / Kris S]</figcaption>
</figure>
<p>Table: Different methods were used in the hackathon. * indicates the method was not applied on the hackathon data. For some common challenges, ‘bulk’ indicates the method was originally developed for bulk omics, ‘sc’ indicates the method was specifically developed specifically for single cell data <strong>table will include links to vignettes</strong> {#tbl:common}</p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-c8qn{background-color:#ffffff;color:#333333;font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-7euo{background-color:#ffffff;color:#333333;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
<tr>
<th class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Common challenges</span>
</th>
<th class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Tasks</span>
</th>
<th class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">sc Spatial</span>
</th>
<th class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">sc targeted proteomics</span>
</th>
<th class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">sc NMT-seq</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tg-7euo">
<span style="font-weight:700;font-style:normal;text-decoration:none">Pre-processing </span>
</td>
<td class="tg-7euo">
<span style="font-weight:700;font-style:normal;text-decoration:none">Normalisation &amp; data transformation</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Data distribution checks (Coullomb, Singh)</span><br><span style="font-weight:400;font-style:normal;text-decoration:none">High Variable Genes selection (Xu)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Variance Stabilization Normalisation <span class="citation" data-cites="1156sEPws">[<a href="#ref-1156sEPws" role="doc-biblioref">14</a>]</span> (Meng)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Arcsinh transformation (Jeganathan).</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Inverse transformation (Jenagan)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Selection of patients (Jenagan)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Summaries of DNA measurements (input data provided in hackathon)</span><br>
</td>
</tr>
<tr>
<td class="tg-c8qn" rowspan="4">
<span style="font-weight:700;font-style:normal;text-decoration:none">Overlap</span>
</td>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none"> Cell overlap<br> </span>
<span style="font-weight:400;font-style:normal;text-decoration:none">(features not matching)</span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
<span style="font-weight:700;font-style:normal;text-decoration:none">Dimension reduction and projection methods:</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">15</a>]</span> (Welch) (sc)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">16</a>]</span>(Abadi) (bulk)</span><br>
</td>
</tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Partial feature overlap <br></span>
<span style="font-weight:400;font-style:normal;text-decoration:none">(cells not matching)</span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Imputation: </span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Direct inversion with latent variables (Sankaran)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Optimal transport to predict protein expression (Lin)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">K Nearest Neighbor averaging (Jenathan<em>)</span><br><br>
<span style="font-weight:700;font-style:normal;text-decoration:none">No imputation:</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Biological Network Interaction (Foster</em>)</span>
</td>
<td class="tg-7euo">
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Partial cell overlap <br> </span>
<span style="font-weight:400;font-style:normal;text-decoration:none">(features not matching)</span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Multi block PCA <span class="citation" data-cites="v4W8vQ17">[<a href="#ref-v4W8vQ17" role="doc-biblioref">17</a>]</span> (Meng*)</span>
</td>
<td class="tg-7euo">
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">No cell overlap </span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none"> (complete feature overlap)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Averaging nearest neighbors in latent space to impute unmeasured expression values (Coullomb?)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Transfer cell type label with Random Forest (Hsu)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">15</a>]</span> (Welch)</span>
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">No cell overlap </span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none"> (partial feature overlap)</span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Topic modelling to predict cell spatial co-location or spatial expression (Jenathan, partial feature overlap)</span><br>
</td>
<td class="tg-7euo">
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none"> No overlap</span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">RLQ <span class="citation" data-cites="UCIhFB5B">[<a href="#ref-UCIhFB5B" role="doc-biblioref">18</a>]</span> (Chen*)</span>
</td>
<td class="tg-7euo">
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Managing differences in scale</span><br>
</td>
<td class="tg-7euo">
<span style="font-weight:700;font-style:normal;text-decoration:none">Data integration</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">15</a>]</span> (Sodicoff) (sc)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">ComBat (Singh)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Projection methods MFA, sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">16</a>]</span> (Singh*) (bulk)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">UMAP/tSNE (Sodicoff) (sc)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Multi-block PCA <span class="citation" data-cites="v4W8vQ17">[<a href="#ref-v4W8vQ17" role="doc-biblioref">17</a>]</span></span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Weighting matrices based on their similarities: STATIS, MFA (Chen*)(bulk)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Scale MIBI-TOF to the range of CyTOF values (Jenagan)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">15</a>]</span> (Welch) (sc)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Projection method sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">16</a>]</span>(Abadi) (bulk)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Multi Omics Supervised Integrative Clustering with weights (Arora) (bulk)</span>
</td>
</tr>
<tr>
<td class="tg-c8qn" rowspan="2">
<span style="font-weight:700;font-style:normal;text-decoration:none">Generic approaches </span>
</td>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Classification &amp; feature selection</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Backward selection with SVM (Coullomb)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">self training ENet (Singh)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Balanced error rate (Coullomb, Singh)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Recursive Feature Elimination (Xu)</span><br><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">(all bulk)</span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Multi Omics Supervised Integrative Clustering (Arora) (bulk)</span><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">Lasso penalization in regression-type models (bulk)</span><br>
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Cell type prediction</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Projection with LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">15</a>]</span> (Sodicoff)</span><br><span style="font-weight:400;font-style:normal;text-decoration:none">SVM (Coullomb, Xu)</span><br><span style="font-weight:400;font-style:normal;text-decoration:none">ssEnet (Singh) </span><br><span style="font-weight:400;font-style:normal;text-decoration:none">(all bulk)</span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Study specific approaches</span>
</td>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Spatial analysis</span><br><br><br><br>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Hidden Markov random field </span><br><span style="font-weight:400;font-style:normal;text-decoration:none">Voronoi tesselation (Coullomb) (bulk)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Spatial autocorrelation with Moran’s Index (Hsu, Lin)</span><br><br><span style="font-weight:400;font-style:normal;text-decoration:none">Selection of spatial discriminative features:</span><br><span style="font-weight:400;font-style:normal;text-decoration:none">Moran’s Index, NN correlation, Cell type</span><br><span style="font-weight:400;font-style:normal;text-decoration:none">interaction composition, </span><br><span style="font-weight:400;font-style:normal;text-decoration:none">L function (Lin)</span><br><br>
<span style="font-weight:400;font-style:normal;text-decoration:none">(all bulk?)</span>
</td>
<td class="tg-7euo">
</td>
</tr>
<tr>
<td class="tg-c8qn">
<span style="font-weight:700;font-style:normal;text-decoration:none">Inclusion of additional information </span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none"> </span>
</td>
<td class="tg-7euo">
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Survival prediction: Cox regression based on spatial features (Lin)</span>
</td>
<td class="tg-7euo">
<span style="font-weight:400;font-style:normal;text-decoration:none">Include annotated hypersensitive sites index to anchor new/unseen data from DNase-seq, (sc)ATAC-seq, scNMT-seq, for </span><span style="font-weight:400;font-style:italic;text-decoration:none">de novo</span><span style="font-weight:400;font-style:normal;text-decoration:none"> peak calling (Meuleman*) (bulk)</span>
</td>
</tr>
</tbody>
</table>
<h2 id="challenges-for-interpretation">Challenges for interpretation</h2>
<p>There are many difficulties involved of the understanding and communication of results from complex data sets and analyses as we have seen in <a href="#scnmt-seq-as-a-case-study-for-epigenetic-regulation">scNMT-seq as a case-study for epigenetic regulation</a>,
<span class="citation" data-cites="ref">[<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>]</span>(sec:scProteomics),
<span class="citation" data-cites="ref">[<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>]</span>(sec:scSpatial).</p>
<p>We’ll separate out the different challenges into different levels.</p>
<h3 id="interpretation-for-data-scientists-reading-the-methods-sections-requires-a-good-understanding-of-the-building-blocks">Interpretation for data scientists reading the methods sections requires a good understanding of the building blocks</h3>
<p>The first is the communication within the community of data scientists, computer scientists and computational biologists ie communicating about methods within a community of practitionners who do not have the same vocabulary or background.</p>
<p>Many tools are used as black boxes and users
don’t know or agree on what exactly the methods are doing (MOFA and tSNE are examples).
The first step in unblinding these black boxes used as methodology shortcuts is to have a clear glossary of terms and how we are using them.
Many synonyms for multimodal data exist and some have nuances, see the table we have compiled (ref: Table1).
Understanding the relation between methods developed by different teams is essential and we often try to organize the methods first, thus it is useful to create a dichotomy of methods and their underlying properties.</p>
<p>A very useful tool for making methodological black boxes more transparent are simulated data.
These can follow benchmark methods such as those presented in <span class="citation" data-cites="ref">[<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>]</span>(sec:sec-benchmark) and use well defined generative processes to clarify what some complex methods do.</p>
<p>Visualization of the data, following the step by step transformations and optimizations of data representations also help clarify how certain methods fit models or compress and reduce data dimensionality.
These visualizations are often very specialized (think for instance, correspondence analyses, goodness of fit plots like qqplots or rootograms or mean-variance fitting).
These intermediary plots don’t usually end up in the main text of final biological publications and serve as intermediary checks to unpack the black boxes.</p>
<h3 id="subsec:super">Supervised versus unsupervised</h3>
<p>One simple delineation between methods is that some
aim to predict a clearly defined outcome at the start of the project, such as recognizing the environment of tumor cells versus that of healthy cells <span class="citation" data-cites="ref">[<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>]</span>(sec:scProteomics).
The supervised setting often provides easier interpretations, one can easily rank the covariates and contiguous data in terms of their predictive potential.</p>
<p>On the other hand when data are collected using multiple
different technologies the data integration needs to provide organizing patterns that enable interpretation.
Clustering is often used as one unsupervised method and is a good example of the use of a latent variable, in this case a factor or categorical variable which was not directly measured on the data but is often used to enable simple interpretations.</p>
<p>In cellular biology, a favorite such division into clusters is that involved in the definition of cell type
<span class="citation" data-cites="H4wZSl5d">[<a href="#ref-H4wZSl5d" role="doc-biblioref">19</a>]</span>.</p>
<p>Sometimes people get carried away in “clustering data” and manipulate the data, in cytometry one often sees cell gating done.
The goal there is to eliminate cells in intermediary states to give clearly delineated inventories of cell types or cells in discrete states, this is a static description and will not enable researchers down the road to predict or understand transtitions between types.</p>
<p>Although a latent factor can be a useful first approximation, keep in mind that development of cells and their fate is a dynamic process and it can often be beneficial to keep data that enable interpretation of the cell trajectories: in that case, locally the underlying latent variable of interest is continuous along a gradient of development.</p>
<p>So far, we have seen two types of latent variables: clusters and a one dimensional continuous “gradient”, (pseduo-time, disease progression are two examples of such latent gradients).
However the idea of latent variables is a rich anchor for many multimodal methods and can often be useful in highlighting what the modalities have in “common” and how they differ.
The commonalities are well understood in the case of classical multivariate factor analyses where the data are decomposed into “commonalities” and uniqueness components <span class="citation" data-cites="q9SIZrho">[<a href="#ref-q9SIZrho" role="doc-biblioref">20</a>]</span>.</p>
<p>A schematic summary of the different stages in interpretation is provided here:</p>
<div id="fig:interpretation" class="fignos">
<figure>
<img src="images/Interpretation_mockup.png" style="width:70.0%" alt="" /><figcaption><span>Figure 4:</span> <strong>A</strong> Schematic diagram of stages of interpretaion and integration of data sources (<strong>Kris to redesign</strong>).
<strong>B</strong> Standards in Geographic Information Systems enable the integration of multiple layers of data (<strong>Kris to redesign</strong>).
<strong>C</strong> Brushing an UMAP with a covariate can illustrate the dynamics of cell changes (<strong>Kris to reinclude own fig</strong>).</figcaption>
</figure>
</div>
<p>Multiple domains of knowledge can be combined easily if there is a common coordinate system, as in geospatial analyses.This is often a goal in multimodal or conjoint analyses, when the first step is to find a common compromise or consensus on which to project each of the individual modalities.
Conjoint analyses also known as STATIS <span class="citation" data-cites="4fOW94wl">[<a href="#ref-4fOW94wl" role="doc-biblioref">21</a>]</span> was a very early multimodal method designed as PCA of PCAs where the first step in the analyses was to find what the different modalities had in common and define a consensus <span class="citation" data-cites="18b0ymB7t">[<a href="#ref-18b0ymB7t" role="doc-biblioref">22</a>]</span> onto which the individual tables were projected.
This method can be seen as an extension of the class of matrix decomposition methods to data cubes.
Many extensions to matrix decompositions have been designed for multimodal data, <span class="citation" data-cites="nhuT45y5">[<a href="#ref-nhuT45y5" role="doc-biblioref">23</a>]</span> offers an overview of the relations between many of them.</p>
<h3 id="reasonning-by-analogy-with-geospatial-problems">Reasonning by analogy with geospatial problems</h3>
<p>In both the proteomics example <span class="citation" data-cites="ref">[<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>]</span>(sec:scProteomics)
and the <span class="citation" data-cites="ref">[<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>]</span>(sec:scSpatial) examplary data, a spatial dimension is already naturally available.
As in previous studies one can leverage
extensive methods developed in spatial statistics to
quantify spatial effects <span class="citation" data-cites="1ABBBCpyT">[<a href="#ref-1ABBBCpyT" role="doc-biblioref">24</a>]</span>.
Contiguity and clustering can be tested and easily understood in the spatial context.</p>
<p>In these cases, layers of information can be mapped to the natural coordinate system in the same way
a GIS system incorporates them (Figure <a href="#fig:interpretation">4</a>B).</p>
<p>The spatial coordinate system analogy can be pursued
further by finding a “consensus space” that provides a common coordinate system.</p>
<p>There are however pitfalls in using very sophisticated dimension reduction techniques which lead to over-interpretation or misinterpretation
(size of clusters in tSNE related to sampling baselines rather than density, …)</p>
<h3 id="disparate-sources-of-evidence-are-more-compelling-than-more-of-the-same.">Disparate sources of evidence are more compelling than more of the same.</h3>
<p>Following <a href="https://www.encyclopedia.com/people/philosophy-and-religion/roman-catholic-and-orthodox-churches-general-biographies/john-henry-newman">Cardinal Newman’s principle</a><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
disparate sources of evidence, or in this case data from different technologies, are more compelling than many replicates of the same technology.
Thus, if different technologies allow a consensus on underlying latent variables, this information is worth retaining.</p>
<h3 id="explaining-results-to-biologists-through-generative-models-and-simulations-ex-factor-analysis-hierarchical-models.">Explaining results to biologists through generative models and simulations (ex: Factor Analysis, Hierarchical models).</h3>
<p>Several difficulties arise when explaining summaries and conclusions, problems encountered include non-identifiability of models
or non-sufficiency of summaries, simulations can often provide effective communication tools.</p>
<p>One can often generate data from different probabilistic models and show that the methods cannot differentiate between the generation processes, this is the identifiability problems that most overparametrized models lead to.
Added constraints on the parameters can often
be integrated into the analyses to make them more realistic and reduce if not eliminate the identifiability issues.</p>
<h3 id="meaningful-interpretation-by-linking-in-databases">Meaningful Interpretation by linking in databases</h3>
<p>In the right side of Figure <a href="#fig:interpretation">4</a>A we show how connections to layers of information from outside databases can be incorporated into the final output. Real biological understanding is often subordinated to the integration
of this contiguous information.
Either from the metadata already available in the multiassay containers as for instance in the <a href="https://bioconductor.org/packages/release/bioc/html/MultiAssayExperiment.html">MultiAssayExperiment package</a> or from exterior sources such as Gene Ontologies, Biomart <span class="citation" data-cites="XkAC715J">[<a href="#ref-XkAC715J" role="doc-biblioref">25</a>]</span>, Kegg, Human Cell Atlas (HCA) or other sources often available through links provided within systems like bioconductor ().</p>
<p>Redundant biological knowledge is often enlightening,
as many methods suffer from identifiability issues (ie in a gradient, the direction of the direction is unknown).
By providing information on the extreme points in a map
or brushing a map with known gene expression features
one can delineate orientations and clusters.</p>
<p>For instance coloring by CD56 across time shows the dynamics of immune response <span class="citation" data-cites="1GblcsF7">[<a href="#ref-1GblcsF7" role="doc-biblioref">26</a>]</span> (Figure <a href="#fig:interpretation">4</a>C).</p>
<h3 id="visualization-tools-for-interpretation-and-communication-to-biologists">Visualization tools for interpretation and communication to biologists</h3>
<p>An example of effective visual interpretation tools is interactive brushing of UMAP plot, see Figure <a href="#fig:interpretation">4</a>C by Kris Sankaran.</p>
<h3 id="missing">Missing</h3>
<ul>
<li><p>Validation through complementary data and sequential experimental design.</p></li>
<li><p>Examples from other parts, references and commentary here missing until documents become availabe (<span class="citation" data-cites="sec:seqFish">[<span class="citeproc-not-found" data-reference-id="sec:seqFish"><strong>???</strong></span>]</span>)</p></li>
</ul>
<h3 id="references">References</h3>
<p>Cell type definition:
<span class="citation" data-cites="H4wZSl5d">[<a href="#ref-H4wZSl5d" role="doc-biblioref">19</a>]</span></p>
<p>Factor Analysis:
<span class="citation" data-cites="q9SIZrho">[<a href="#ref-q9SIZrho" role="doc-biblioref">20</a>]</span></p>
<p>Statis, conjoint analysis:
<span class="citation" data-cites="4fOW94wl">[<a href="#ref-4fOW94wl" role="doc-biblioref">21</a>]</span></p>
<p>The French way:
<span class="citation" data-cites="18b0ymB7t">[<a href="#ref-18b0ymB7t" role="doc-biblioref">22</a>]</span></p>
<p>Overview and connections of methods: KS
<span class="citation" data-cites="nhuT45y5">[<a href="#ref-nhuT45y5" role="doc-biblioref">23</a>]</span></p>
<p>Kevin Murphy:
Probabilistic Machine Learning, MIT Press
<span class="citation" data-cites="doi:10.5555/2380985">[<span class="citeproc-not-found" data-reference-id="doi:10.5555/2380985"><strong>???</strong></span>]</span>
<span class="citation" data-cites="aSqxpadK">[<a href="#ref-aSqxpadK" role="doc-biblioref">27</a>]</span>
<span class="citation" data-cites="aSqxpadK">[<a href="#ref-aSqxpadK" role="doc-biblioref">27</a>]</span></p>
<p>GIS: reference
https://www.usgs.gov/faqs/what-a-geographic-information-system-gis</p>
<p>Original: https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/styles/full_width/public/thumbnails/image/8BaseLayersofTheNationalMap.JPG</p>
<p>Biomart:
<span class="citation" data-cites="XkAC715J">[<a href="#ref-XkAC715J" role="doc-biblioref">25</a>]</span></p>
<p>UMAP:
<span class="citation" data-cites="172t1QM5n">[<a href="#ref-172t1QM5n" role="doc-biblioref">28</a>]</span>
https://arxiv.org/abs/1802.03426v2</p>
<p>Spatial tumor and immune cells:
<span class="citation" data-cites="1ABBBCpyT">[<a href="#ref-1ABBBCpyT" role="doc-biblioref">24</a>]</span></p>
<p>CD56 Immune cell coloring, paper with C. Blish:
<span class="citation" data-cites="1GblcsF7">[<a href="#ref-1GblcsF7" role="doc-biblioref">26</a>]</span></p>
<p>Footnote:
Cardinal Newman wrote <strong>The Grammar of Assent.</strong> and cited in [Bruno de Finetti, Volume 1, 1974 Theory of Probability]:</p>
<p><em>Supposes a thesis (e.g. the guilt of an accused man) is supported by a great deal of circumstantial evidence of different forms, but in agreement with each other; then even if each piece of evidence is in itself insufficient to produce any strong belief, the thesis is decisively strengthened by their joint effect.</em></p>
<h2 id="techniques-and-challenges-for-benchmarking-methods">Techniques and challenges for benchmarking methods</h2>
<h3 id="definition-of-benchmarking">Definition of benchmarking</h3>
<p>Often, the goal in benchmarking is recovery of known cell types with
processing of raw data, quantification, and clustering. The
Adjusted Rand Index (ARI) or other metrics for partitions are
used.</p>
<p>One may also attempt to benchmark methods for their ability to
discover known relationships between data modalities, e.g. gene
regulatory relationships observed between chromatin accessibility
and gene expression. However, this is made difficult by the fact
that these relationships are not fully known at the single cell
level.</p>
<div id="fig:benchmark" class="fignos">
<figure>
<img src="images/Benchmark_mockup.png" alt="" /><figcaption><span>Figure 5:</span> <strong>A</strong> Silver standard: Svensson et al. (2017) Nat Methods; Wang et al. (2019) bioRxiv; Cole et al. (2019) Cell Systems; Zhang et al. (2017) bioRxiv;
Soneson et al. (2018) Nat Methods; Saelens et al. (2019) Nat Biotechnol; Gold standard control data: Tian et al. (2019) Nat Meth; Freytag et al. (2018) F1000Res; Gold standard simulated data with the splatter R package appia et al. (2017) Genome Biol [credit: Matt Ritchie] (<strong>Refs to be added proper</strong>).
<strong>B</strong> scNMT-seq study: correlations with linear projections (MOFA+) evaluated with cross-validation [credit: Mike Love].</figcaption>
</figure>
</div>
<h3 id="strategies-for-benchmarking">Strategies for benchmarking</h3>
<p>Benchmarking multi-modal methods on typical multi-modal datasets is inherently difficult, as we rarely
know the ground truth <span class="citation" data-cites="chgaiKOU">[<a href="#ref-chgaiKOU" role="doc-biblioref">29</a>]</span>. Simulation is useful for having known truth, but it is difficult to
simulate realistic covariance structure across features and across
data modalities (Figure <a href="#fig:benchmark">5</a>A).</p>
<h4 id="creating-benchmarking-datasets">Creating benchmarking datasets</h4>
<p>(<strong>add examples from Google Doc</strong>)
Benchmark datasets for single cell studies have largely centered around
measuring sequencing depth and diversity of cell types derived from
a single assay of interest (e.g. scRNAseq). A benchmark dataset
serves a few purposes:</p>
<ul>
<li>Provides ground truth for the intended effect of exposure in a
proposed study design.</li>
<li>Provides validation for a data integration task for which a new
computational method may be proposed.</li>
</ul>
<p>For multi-modal assays, while the intended effects can vary based on
the leading biological questions, one may abstract out common data
integration tasks such as co-embedding, mapping or correlation, and
inferring causal relationships. We distinguish data integration from
further downstream analyses that may occur on integrated samples
such as differential analysis of both assays with regard to to a certain
exposure.</p>
<p>Both the intended effects and data integration task rely on study
design that takes into account:</p>
<ul>
<li><p>Biological and technical variability via replicates, block
design, and randomization.</p></li>
<li><p>Power analysis for the intended effect or data integration
task.</p></li>
<li><p>Dependencies between modalities, for e.g. gene expression
depending on gene regulatory element activity, requires that
experiment design must also account for spatial and temporal
elements in sampling for a given observation.</p>
<p>As such, no universal benchmark data scheme may suit every
combination of modality, and benchmark datasets may be established
for commonly used combinations of modalities or technologies,
towards specific data integration tasks.</p></li>
</ul>
<h4 id="cross-validation-within-study">Cross-validation within study</h4>
<p>For example the <a href="https://github.com/Wancen/CV-MOFA">cross-validation analysis of the scNMT-seq dataset</a>
was performed using MOFA+ (Figure <a href="#fig:benchmark">5</a>B). Such an evaluation of methods using permutation or cross-validation
has been performed previously, typically to optimize a tuning
parameter or other aspects of model selection. Permutation has been
used to create null datasets, either as demonstration that a method
is not overfitting, or for tuning parameter selection, where the
optimal parameter setting should produce an objective that is far
from the null distribution
<span class="citation" data-cites="vJJXeGCv MYhQ5fRN NSuq56O9">[<a href="#ref-vJJXeGCv" role="doc-biblioref">30</a>,<a href="#ref-MYhQ5fRN" role="doc-biblioref">31</a>,<a href="#ref-NSuq56O9" role="doc-biblioref">32</a>]</span>.
Cross-validation using folds or leave-one-out has likewise been used in many multi-modal method development papers
<span class="citation" data-cites="13ibOJcF0 maAEgLQK yVYfg2ZK YY25QUrX 5B54vifR tOD4Gkgt AQWTNms4 bFa7ptnr wkhRfjyx wP2BgpVi QSXGprag cZOVX9E7">[<a href="#ref-cZOVX9E7" role="doc-biblioref">12</a>,<a href="#ref-13ibOJcF0" role="doc-biblioref">33</a>,<a href="#ref-maAEgLQK" role="doc-biblioref">34</a>,<a href="#ref-yVYfg2ZK" role="doc-biblioref">35</a>,<a href="#ref-YY25QUrX" role="doc-biblioref">36</a>,<a href="#ref-5B54vifR" role="doc-biblioref">37</a>,<a href="#ref-tOD4Gkgt" role="doc-biblioref">38</a>,<a href="#ref-AQWTNms4" role="doc-biblioref">39</a>,<a href="#ref-bFa7ptnr" role="doc-biblioref">40</a>,<a href="#ref-wkhRfjyx" role="doc-biblioref">41</a>,<a href="#ref-wP2BgpVi" role="doc-biblioref">42</a>,<a href="#ref-QSXGprag" role="doc-biblioref">43</a>]</span>.</p>
<p>A challenge with within study cross-validation is how to
match dimensions of latent space across folds. Previous evaluations
of multi-modal methods using cross-validation have focused on the
top factor, swapping the sign of the project as needed to align
the top latent factor across folds <span class="citation" data-cites="IZfv7up4">[<a href="#ref-IZfv7up4" role="doc-biblioref">44</a>]</span>.</p>
<p>Finally, we note that for assessing clustering, a number of papers
have suggested to resampling or data-splitting strategies to
determine prediction strength
<span class="citation" data-cites="4CvJHFCU QfQVcW0v gbdea2Ea I1iOQSFC">[<a href="#ref-gbdea2Ea" role="doc-biblioref">6</a>,<a href="#ref-4CvJHFCU" role="doc-biblioref">45</a>,<a href="#ref-QfQVcW0v" role="doc-biblioref">46</a>,<a href="#ref-I1iOQSFC" role="doc-biblioref">47</a>]</span>.
For clustering of cells into putative cell types or cell states,
such previously developed techniques could be applied in a
multi-modal setting.</p>
<p>Cross-study validation would assess if relationships discovered in
one dataset present in other datasets, potentially looking across
single cell and bulk.</p>
<h3 id="using-hackathon-studies-as-community-benchmarking">Using hackathon studies as community benchmarking</h3>
<p><strong>to fill here, could mention the dream challenge and link back to our own experience / learnings</strong></p>
<h2 id="software-strategies-to-enable-analyses-of-multimodal-single-cell-experiments">Software strategies to enable analyses of multimodal single cell experiments</h2>
<p>In this section, we reflect on the challenges we have faced when analyzing this series of hackathons whilst using analytic software for visualization and inference in multimodal single-cell experiments. Our discussion is necessarily limited in scope, but
we provide pointers to concrete details when relevant.</p>
<h3 id="basic-aims">Basic aims</h3>
<p>We take it for granted that <strong>openness</strong> is a <em>sine qua non</em> for computational tooling in this
area. All components need to be accessible for full vetting by the community, so licensing
in Creative Commons, Artistic, or GNU frameworks is expected. We also aim for a <strong>coordinated approach</strong>,
so that duplication of effort between groups working on similar problems can be avoided. Finally,
we seek solutions that are <strong>efficient</strong>, avoid <strong>lock-in</strong>, and lead to reproducible analyses.
Real-time improvements to the tool-set should
be feasible, respecting needs for stability, reliability, and continuity of access to evolving components.</p>
<p>These objectives are fluid and open to interpretation. Community engagement and communication are
important to achieving desired goals in this domain.</p>
<h3 id="key-questions">Key questions</h3>
<ul>
<li>How should multimodal single cell data be managed for interactive and batch analyses?</li>
<li>What methods will help software developers create scalable solutions for multimodal single cell analysis?</li>
<li>How can we ensure that visualization methods that are central to multimodal single cell analysis
are usable by researchers with visual impairments?</li>
</ul>
<p>These questions will ultimately be answered through the creation of a <strong>software ecosystem</strong> <span class="citation" data-cites="dwXJ9SC4 102RKxFFz 14np73aSU">[<a href="#ref-dwXJ9SC4" role="doc-biblioref">48</a>,<a href="#ref-102RKxFFz" role="doc-biblioref">49</a>,<a href="#ref-14np73aSU" role="doc-biblioref">50</a>]</span>.
As an example of an ecosystem of broad scope, we cite bioconductor.org <span class="citation" data-cites="E7tdylV2">[<a href="#ref-E7tdylV2" role="doc-biblioref">51</a>]</span>. This project
produces code in R for <strong>data representation and data services</strong> for many data modalities used
in genome-scale experimentation. Bioconductor’s resources for achieving <strong>scalability</strong> <span class="citation" data-cites="10Moc29vA">[<a href="#ref-10Moc29vA" role="doc-biblioref">52</a>]</span> include
tools for analyzing massive data resources with tunable RAM footprints <span class="citation" data-cites="10.18129/B9.bioc.DelayedArray 10.18129/B9.bioc.rhdf5">[<span class="citeproc-not-found" data-reference-id="10.18129/B9.bioc.DelayedArray"><strong>???</strong></span>,<span class="citeproc-not-found" data-reference-id="10.18129/B9.bioc.rhdf5"><strong>??</strong></span>]</span>, and tooling for
supporting fault-tolerant parallel distributed computing in various cluster and cloud contexts <span class="citation" data-cites="DxMfDYNc">[<a href="#ref-DxMfDYNc" role="doc-biblioref">53</a>]</span>.
Finally, Bioconductor supports <em>developers</em> who seek to build broad user bases by providing
multiplatform/multistream <strong>continuous integration/continuous delivery</strong> of contributed packages <span class="citation" data-cites="oRTa5zGU">[<a href="#ref-oRTa5zGU" role="doc-biblioref">54</a>]</span>,
and <em>users</em> with different skill sets by articulating standards for documentation, and testing, and
by hosting community forums and workshops <span class="citation" data-cites="SkTqlnmn">[<a href="#ref-SkTqlnmn" role="doc-biblioref">55</a>]</span>.</p>
<h3 id="data-management-strategies">Data management strategies</h3>
<p><strong>A ready-to-use integrative data class with <code>multiAssayExperiment</code>.</strong>
The Bioconductor S4 class implementing an abstract data type called <code>multiAssayExperiment</code> is highly relevant
for multimodal single-cell experiments as each mode is characterized by a different collection of features on possibly non-overlapping collections
of samples <span class="citation" data-cites="gdnUpsQo">[<a href="#ref-gdnUpsQo" role="doc-biblioref">56</a>]</span>.</p>
<p>The Metadata on features is bound directly into the class instance. For example,
genes and transcripts can be enumerated using Ensembl <span class="citation" data-cites="oDiClyTE">[<a href="#ref-oDiClyTE" role="doc-biblioref">57</a>]</span> catalog identifiers, represented as
<code>GRanges</code> instances <span class="citation" data-cites="14d6Jzwus">[<a href="#ref-14d6Jzwus" role="doc-biblioref">58</a>]</span>; regions of accessibility
from, e.g., ATAC-seq experiments, may be defined using genomic coordinates in a clearly specified reference build. Metadata on
samples includes all relevant information on experimental conditions such as treatment,
protocol, and date of technical processing. Figure <a href="#fig:spatialExpt">6</a> shows how this
class was used to amalgamate and annotate results of a multimodal dataset consisting of seqFISH and scRNA-seq experimental data.
To combine these two different experiments, the seqFISH data were stored into the SpatialExperiment S4 class object, while the scRNA-seq data were stored into a SingleCellExperiment Bioconductor class object <span class="citation" data-cites="R7sfk7Aq">[<a href="#ref-R7sfk7Aq" role="doc-biblioref">59</a>]</span>.
Then, these objects were easily stored into a MultiAssayExperiment class object and released with the SingleCellMultiModal Bioconductor package <span class="citation" data-cites="doi:10.18129/B9.bioc.SingleCellMultiModal">[<span class="citeproc-not-found" data-reference-id="doi:10.18129/B9.bioc.SingleCellMultiModal"><strong>???</strong></span>]</span>.</p>
<div id="fig:spatialExpt" class="fignos">
<figure>
<img src="images/MSA_SpE.png" style="width:50.0%" alt="" /><figcaption><span>Figure 6:</span> Panel A: Combination of seqFISH-based SpatialExperiment
and SingleCellExperiment instances into a MultiAssayExperiment. Panel B: details of the SpatialExperiment class design.</figcaption>
</figure>
</div>
<p>The <code>multiAssayExperiment</code> class includes
1) Assay slots containing variables or features from multiple modalities (e.g. gene expression units from scRNA-seq and protein units in sc-proteomics), either from the same cells or distinct cells from the same or distinct starting samples or biological specimen of origin. In some cases, the feature may be multidimensional (e.g. spatial coordinates, locations of eQTLs).
2) Metadata for sample of origin for the individual cells, e.g. study, center, phenotype, perturbation.
3) A map between the different assays to enable analysis</p>
<p>Some of our contributors (Al Abadi, Patheepa Jeganathan) used the <code>multiAssayExperiment</code> class to integrate the multi-modal single cell data (scNMT-seq, sc Proteomics, <strong>pointers to vignettes</strong>), allowing for easier preprocessing, transformation, extraction of spatial information from raster objects, addition of cell information and visualization <strong>Al, details please if needed</strong>.</p>
<!--In our hackathon context, we considered multi-assay measurements from the same cell (e.g. scNMT-seq) or integration of multi-assay measurements from  (seqFish, scProteomics).
-->
<p>Challenges we faced in our hackathons were that some of the observations of different modalities were not be directly comparable (e.g. RNA may be measured from individual cells, but spatial transcriptomics may cover a few cells in the matched area) and because of the absence of universal standards, the metadata varied from analysis to analysis.</p>
<h3 id="scalability-strategies">Scalability strategies</h3>
<p>In addition to standardize data infrastructures that allows for scalability of <em>storing</em> and <em>access</em> of large datasets <span class="citation" data-cites="KhbsUBNe mOp2pMsC">[<a href="#ref-KhbsUBNe" role="doc-biblioref">60</a>,<a href="#ref-mOp2pMsC" role="doc-biblioref">61</a>]</span>, new strategies are emerging that allow for scalable <em>algorithms</em> that allow for data to be stored in memory or on disk such as unsupervised clustering of cell types in either R <span class="citation" data-cites="g9O7LIML 19jAJjD6o">[<a href="#ref-g9O7LIML" role="doc-biblioref">62</a>,<a href="#ref-19jAJjD6o" role="doc-biblioref">63</a>]</span> or Python <span class="citation" data-cites="qIZTS1II">[<a href="#ref-qIZTS1II" role="doc-biblioref">64</a>]</span>. While these strategies were originally developed in application of single-cell RNA-sequencing analyses, these scalable algorithms are applicable to multimodal single-cell experiments.</p>
<h3 id="data-access-for-the-hackathons-and-long-term-software-strategy-for-multimodal-single-cell-experiments">Data access for the hackathons and long term software strategy for multimodal single-cell experiments</h3>
<p>Reproducibility and transparency are crucial aspect in hackathons, starting with data availability. Providing data to the community is a long standing issue (e.g. SAGEBionetwork <strong>complete Elana</strong>). In our context, input data across all hackathons were pre-processed with steps documented, and the data were added into the ExperimentHub package <code>SingleCellMultimodal</code> [doi:10.18129/B9.bioc.SingleCellMultiModal], developed to incorporate multiple multi modal datasets in MultiAssaiExperiment format so that they can be used for further computational developments by others. At the moment, it includes the hackathons scNMT-seq and the seqFISH+scRNA-seq (Fig. <a href="#fig:spatialExpt">6</a>) datasets, easily stored because of the samples overlapping between multiple modalities, while we are working on the integration of the scProteomics dataset which has no overlap between samples.</p>
<p>The vignettes of all contributors were included into containers <strong>Al, details please</strong> using the <code>ExperimentHub</code> package as a dependency. In these containers, we used consistent assay access methods to powerful implementation strategies (possibly through methods inheritance. e.g. from <code>SummarizedExperiment</code> <strong>Al please amend</strong>). Such setting will in the long-term facilitate Continuous Integration (CI) of the analyses and preprocessing changes and Continuous Delivery (CD)
of the analysis reports. The CI/CD workflow may also be automated on a hosted server and containerized
reports can be generated for enhanced efficiency and portability.</p>
<h3 id="reducing-barriers-to-interpretable-visualizations">Reducing barriers to interpretable visualizations</h3>
<p>Color is a powerful data visualization tool that helps representing the different dimensions of our increasingly complex and rich scientific data.
Color vision deficiencies affect a substantial portion of the population<span class="citation" data-cites="x7pNDE94">[<a href="#ref-x7pNDE94" role="doc-biblioref">65</a>]</span> and leads to difficulties in perceiving patterns (the basis for the Ishihara’s color vision tests) in multi-colored figures. In some cases, the perceived patterns such as heat maps and reduced dimension plots can differ between individuals with normal and color deficient vision.</p>
<p>One strategy to present scientific information accessible information to all readers is to include colorblind friendly visualizations <span class="citation" data-cites="11uDSb0Nf Ecm3XS4">[<a href="#ref-11uDSb0Nf" role="doc-biblioref">66</a>,<a href="#ref-Ecm3XS4" role="doc-biblioref">67</a>]</span> as a default setting, using palettes such as form the R packages viridis <span class="citation" data-cites="lLv68Zzx">[<a href="#ref-lLv68Zzx" role="doc-biblioref">68</a>]</span> and dittoSeq <span class="citation" data-cites="19usrpNlS">[<a href="#ref-19usrpNlS" role="doc-biblioref">69</a>]</span>, whilst limiting to a number of 10 colors. Additional visual cues to differentiate regions (hatched areas) or cells (point shapes) can also reduce the dependence on colors. The inclusion an “accessibility caption” accompanying figures which “guide” the reader’s perception of the images would greatly benefit broader data accessibility.</p>
<!-- Overall, a broader discussion regarding the accessibility of our figures that is not just limited to color vision deficiencies would be greatly beneficial towards improving data accessibility.
Perhaps one tool to address broader accessibility could be
[US Government tools for accessibility](https://accessibility.18f.gov/tools/)
-->
<h3 id="details-of-working-components-trimmed">Details of working components – trimmed</h3>
<p>you can interact with underlying data at <a href="https://docs.google.com/spreadsheets/d/1tSUQ9iDKqq72TB9G3Cx1evg2sekS-ytx5wRXDv6vxfg/edit?usp=sharing">google sheet</a></p>
<table>
<colgroup>
<col style="width: 12%" />
<col style="width: 53%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Brief name (link)</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Matlab package</td>
<td><a href="https://gitlab.com/gernerlab/cytomap">CytoMAP</a></td>
<td>CytoMAP: A Spatial Analysis Toolbox Reveals Features of Myeloid Cell Organization in Lymphoid Tissues</td>
</tr>
<tr class="even">
<td>Matlab package</td>
<td><a href="https://github.com/BodenmillerGroup/histoCAT">histoCAT</a></td>
<td>histoCAT: analysis of cell phenotypes and interactions in multiplex image cytometry data</td>
</tr>
<tr class="odd">
<td>Python library</td>
<td><a href="https://pytorch.org">PyTorch</a></td>
<td>General framework for deep learning</td>
</tr>
<tr class="even">
<td>Python package</td>
<td><a href="https://github.com/BiomedicalMachineLearning/SpaCell">SpaCell</a></td>
<td>SpaCell: integrating tissue morphology and spatial gene expression to predict disease cells</td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/theislab/scanpy">Scanpy</a></td>
<td>Python package for single cell analysis</td>
</tr>
<tr class="even">
<td>R data class</td>
<td><a href="https://bioconductor.org/packages/MultiAssayExperiment">MultiAssayExperiment</a></td>
<td>unify multiple experiments</td>
</tr>
<tr class="odd">
<td>R data class</td>
<td><a href="https://github.com/drighelli/SpatialExperiment">SpatialExperiment</a></td>
<td>SpatialExperiment: a collection of S4 classes for Spatial Data</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/RubD/Giotto">Giotto</a></td>
<td>Spatial transcriptomics</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://github.com/BodenmillerGroup/cytomapper">cytomapper</a></td>
<td>cytomapper: Visualization of highly multiplexed imaging cytometry data in R</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/RachelQueen1/Spaniel/">Spaniel</a></td>
<td>Spaniel: analysis and interactive sharing of Spatial Transcriptomics data</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://github.com/satijalab/seurat">Seurat</a></td>
<td>R toolkit for single cell genomics</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/LieberInstitute/spatialLIBD">SpatialLIBD</a></td>
<td>Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://cardinalmsi.org/">Cardinal</a></td>
<td>Cardinal: an R package for statistical analysis of mass spectrometry-based imaging experiments</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/FertigLab/CoGAPS">CoGAPS</a></td>
<td>scCoGAPS learns biologically meaningful latent spaces from sparse scRNA-Seq data</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://github.com/genesofeve/projectR">projectR</a></td>
<td>ProjectR is a transfer learning framework to rapidly explore latent spaces across independent datasets</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/waldronlab/SingleCellMultiModal">SingleCellMultiModal</a></td>
<td>Serves multiple datasets obtained from GEO and other sources and represents them as MultiAssayExperiment objects</td>
</tr>
<tr class="odd">
<td>R scripts</td>
<td><a href="https://github.com/drighelli/SpatialAnalysis">SpatialAnalysis</a></td>
<td>Scripts for SpatialExperiment usage</td>
</tr>
<tr class="even">
<td>Self-contained GUI</td>
<td><a href="https://github.com/jfnavarro/st_viewer">ST viewer</a></td>
<td>ST viewer: a tool for analysis and visualization of spatial transcriptomics datasets</td>
</tr>
<tr class="odd">
<td>Shiny app</td>
<td><a href="https://zouter.shinyapps.io/server/">Dynverse</a></td>
<td>A comparison of single-cell trajectory inference methods: towards more accurate and robust tools</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/mixOmicsTeam/mixOmics">mixOmics</a></td>
<td>R toolkit for multivariate analysis of multi-modal data</td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/YosefLab/scVI">totalVI</a></td>
<td>A variational autoencoder (deep learning model) to integrate RNA and protein data from CITE-seq experiments</td>
</tr>
<tr class="even">
<td>Python web application</td>
<td></td>
<td><a href="https://imjoy.io/#/">ImJoy</a></td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/napari/napari">napari</a></td>
<td>Interactive big multi-dimensional 3D image viewer</td>
</tr>
<tr class="even">
<td>Software</td>
<td><a href="https://qupath.github.io/">QuPath</a></td>
<td>Multiplex whole slide image analysis</td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/hammerlab/cytokit">Cytokit</a></td>
<td>Multiplex whole slide image analysis</td>
</tr>
<tr class="even">
<td>Python package</td>
<td><a href="https://gitlab.com/engje/cmif">cmIF</a></td>
<td>Multiplex whole slide image analysis</td>
</tr>
<tr class="odd">
<td>Software</td>
<td><a href="https://github.com/kruegert/facetto">Facetto</a></td>
<td>Multiplex whole slide image analysis, not available yet</td>
</tr>
<tr class="even">
<td>Software, Python based</td>
<td><a href="https://cellprofiler.org/">CellProfiler</a></td>
<td>Image analysis</td>
</tr>
</tbody>
</table>
<h2 id="discussion">Discussion</h2>
<h3 id="emerging-analytical-methods-and-technologies">Emerging analytical methods and technologies</h3>
<h3 id="community-needs-for-data-structures-analysis-methods-etc">Community needs for data structures, analysis methods, etc</h3>
<h2 id="glossary">Glossary</h2>
<div id="tbl:table_gloss" class="tablenos">
<table>
<caption><span>Table 1:</span> Glossary of interchangeable terms in the field of single-cell and bulk multi-omics (multi-source) data analysis. </caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>Consensus Term</th>
<th>Related Terms</th>
<th>Description</th>
<th>Citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>network</td>
<td>graph, adjacency matrix</td>
<td>A set of <em>nodes</em>, representing objects of interest, linked by <em>edges</em>, representing specific relationships between nodes.</td>
<td>?</td>
</tr>
<tr class="even">
<td>node</td>
<td>vertex</td>
<td>Element of interest in a network and linked to other nodes. For example: people, cells, proteins or genes. Nodes can have several properties called <em>attributes</em> like cell type or position.</td>
<td>?</td>
</tr>
<tr class="odd">
<td>edge</td>
<td>link</td>
<td>The relationship between 2 nodes in a network. For example: friendship in social networks, cells in contact in a spatial network, or gene-gene interactions in a gene regulatory network.</td>
<td>?</td>
</tr>
<tr class="even">
<td>concordant</td>
<td>concordant, coherent, consistent</td>
<td>?</td>
<td><span class="citation" data-cites="IZfv7up4"><a href="#ref-IZfv7up4" role="doc-biblioref">44</a></span></td>
</tr>
<tr class="odd">
<td>contributions</td>
<td>variable weights, loadings, eigenvector, axis, direction, dimension, coefficients, slopes</td>
<td>Contributions of the original variables in constructing the components.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">43</a></span>, <span class="citation" data-cites="18fTyQGoG"><a href="#ref-18fTyQGoG" role="doc-biblioref">70</a></span></td>
</tr>
<tr class="even">
<td>latent factors</td>
<td>variates, scores, projections, components, latent/hidden/unobserved variables/factors</td>
<td>Weighted linear combinations of the original variables.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">43</a></span>, <span class="citation" data-cites="18fTyQGoG"><a href="#ref-18fTyQGoG" role="doc-biblioref">70</a></span></td>
</tr>
<tr class="odd">
<td>multimodal</td>
<td>Multiview, multiway arrays, multimodal, multidomain, multiblock, multitable, multi-omics, multi-source data analysis methods, N-integration</td>
<td>Methods pertaining to the analysis of multiple data matrices for the same set of observations.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">43</a></span>, <span class="citation" data-cites="nhuT45y5"><a href="#ref-nhuT45y5" role="doc-biblioref">23</a></span>, <span class="citation" data-cites="2SDWXiwB"><a href="#ref-2SDWXiwB" role="doc-biblioref">71</a></span></td>
</tr>
<tr class="even">
<td>conjoint analysis</td>
<td>conjoint analysis, P-integration, meta-analysis, multigroup data analysis</td>
<td>Methods pertaining to the analysis of multiple data matrices for the same set of variables.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">43</a></span>, <span class="citation" data-cites="18fTyQGoG"><a href="#ref-18fTyQGoG" role="doc-biblioref">70</a></span>, <span class="citation" data-cites="UqaGRGDg"><a href="#ref-UqaGRGDg" role="doc-biblioref">72</a></span></td>
</tr>
<tr class="odd">
<td>variable</td>
<td>feature, variable</td>
<td>A measurable quantity that describes an observation’s attributes. Variables from different modalities include age, sex, gene or protein abundance, single nucleotide variants, operational taxonomic units, pixel intensity <em>etc.</em></td>
<td>?</td>
</tr>
<tr class="even">
<td>biomarker</td>
<td>marker, biomarker</td>
<td>A variable that is associated with normal or disease processes, or responses to exposures, or interventions. Any change in this variable is also associated with a change in the associated clinical outcome. These variables may be used for diagnostic, monitoring, Pharmacodynamic responses. Examples include LDL cholesterol, CD4 counts, hemoglobin A1C.</td>
<td><span class="citation" data-cites="AtapBaNb"><a href="#ref-AtapBaNb" role="doc-biblioref">73</a></span></td>
</tr>
<tr class="odd">
<td>panel</td>
<td>biomarker panel, biomarker signature</td>
<td>A subset of the originally measured variables that are determined to be associated with the outcome or response variable. This may be determined using statistical inference, feature selection methods, or machine/statistical learning.</td>
<td><span class="citation" data-cites="17aD4MFPS"><a href="#ref-17aD4MFPS" role="doc-biblioref">74</a></span>, <span class="citation" data-cites="XWx8RAwW"><a href="#ref-XWx8RAwW" role="doc-biblioref">75</a></span></td>
</tr>
<tr class="even">
<td>observation</td>
<td>sample, observation, array</td>
<td>A single entity belonging to a larger grouping. Examples include patients, subjects, participants, cells, biological sample, usually the unit of observation on which the variables are measured <em>etc.</em></td>
<td>?</td>
</tr>
</tbody>
</table>
</div>
<h2 class="page_break_before" id="references-1">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-14LoEihpl">
<p>1. <strong>Adult mouse cortical cell taxonomy revealed by single cell transcriptomics</strong> <br />
Bosiljka Tasic, Vilas Menon, Thuc Nghi Nguyen, Tae Kyung Kim, Tim Jarsky, Zizhen Yao, Boaz Levi, Lucas T Gray, Staci A Sorensen, Tim Dolbeare, … Hongkui Zeng<br />
<em>Nature Neuroscience</em> (2016-01-04) <a href="https://doi.org/f778w5">https://doi.org/f778w5</a> <br />
DOI: <a href="https://doi.org/10.1038/nn.4216">10.1038/nn.4216</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26727548">26727548</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4985242">PMC4985242</a></p>
</div>
<div id="ref-13v18bjoF">
<p>2. <strong>Identification of spatially associated subpopulations by combining scRNAseq and sequential fluorescence in situ hybridization data</strong> <br />
Qian Zhu, Sheel Shah, Ruben Dries, Long Cai, Guo-Cheng Yuan<br />
<em>Nature Biotechnology</em> (2018-10-29) <a href="https://doi.org/gfgn8x">https://doi.org/gfgn8x</a> <br />
DOI: <a href="https://doi.org/10.1038/nbt.4260">10.1038/nbt.4260</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30371680">30371680</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6488461">PMC6488461</a></p>
</div>
<div id="ref-bJBIpCn7">
<p>3. <strong>A Single-Cell Atlas of the Tumor and Immune Ecosystem of Human Breast Cancer</strong> <br />
Johanna Wagner, Maria Anna Rapsomaniki, Stéphane Chevrier, Tobias Anzeneder, Claus Langwieder, August Dykgers, Martin Rees, Annette Ramaswamy, Simone Muenst, Savas Deniz Soysal, … Bernd Bodenmiller<br />
<em>Cell</em> (2019-05) <a href="https://doi.org/gfzbz7">https://doi.org/gfzbz7</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2019.03.005">10.1016/j.cell.2019.03.005</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30982598">30982598</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6526772">PMC6526772</a></p>
</div>
<div id="ref-18RF7h7kj">
<p>4. <strong>A Structured Tumor-Immune Microenvironment in Triple Negative Breast Cancer Revealed by Multiplexed Ion Beam Imaging</strong> <br />
Leeat Keren, Marc Bosse, Diana Marquez, Roshan Angoshtari, Samir Jain, Sushama Varma, Soo-Ryum Yang, Allison Kurian, David Van Valen, Robert West, … Michael Angelo<br />
<em>Cell</em> (2018-09) <a href="https://doi.org/gd4wms">https://doi.org/gd4wms</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2018.08.039">10.1016/j.cell.2018.08.039</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30193111">30193111</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6132072">PMC6132072</a></p>
</div>
<div id="ref-wFwe0y4i">
<p>5. <strong>Epigenetic regulation in development: is the mouse a good model for the human?</strong> <br />
Courtney W Hanna, Hannah Demond, Gavin Kelsey<br />
<em>Human Reproduction Update</em> (2018-09) <a href="https://doi.org/gd3d4z">https://doi.org/gd3d4z</a> <br />
DOI: <a href="https://doi.org/10.1093/humupd/dmy021">10.1093/humupd/dmy021</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29992283">29992283</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6093373">PMC6093373</a></p>
</div>
<div id="ref-gbdea2Ea">
<p>6. <strong>Cluster Validation by Prediction Strength</strong> <br />
Robert Tibshirani, Guenther Walther<br />
<em>Journal of Computational and Graphical Statistics</em> (2005-09) <a href="https://doi.org/fvtcf4">https://doi.org/fvtcf4</a> <br />
DOI: <a href="https://doi.org/10.1198/106186005x59243">10.1198/106186005x59243</a></p>
</div>
<div id="ref-KsY7PFJ8">
<p>7. <strong>Matching species traits to environmental variables: a new three-table ordination method</strong> <br />
S. Dolédec, D. Chessel, C. J. F. ter Braak, S. Champely<br />
<em>Environmental and Ecological Statistics</em> (1996-06) <a href="https://doi.org/fhwz55">https://doi.org/fhwz55</a> <br />
DOI: <a href="https://doi.org/10.1007/bf02427859">10.1007/bf02427859</a></p>
</div>
<div id="ref-8vGho6cJ">
<p>8. <strong>Using single‐cell genomics to understand developmental processes and cell fate decisions</strong> <br />
Jonathan A Griffiths, Antonio Scialdone, John C Marioni<br />
<em>Molecular Systems Biology</em> (2018-04-16) <a href="https://doi.org/gdgbtq">https://doi.org/gdgbtq</a> <br />
DOI: <a href="https://doi.org/10.15252/msb.20178046">10.15252/msb.20178046</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29661792">29661792</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5900446">PMC5900446</a></p>
</div>
<div id="ref-3QdXjbeH">
<p>9. <strong>Reprogramming the Methylome: Erasing Memory and Creating Diversity</strong> <br />
Heather J. Lee, Timothy A. Hore, Wolf Reik<br />
<em>Cell Stem Cell</em> (2014-06) <a href="https://doi.org/f6f83c">https://doi.org/f6f83c</a> <br />
DOI: <a href="https://doi.org/10.1016/j.stem.2014.05.008">10.1016/j.stem.2014.05.008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24905162">24905162</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4051243">PMC4051243</a></p>
</div>
<div id="ref-1FWgnoNlO">
<p>10. <strong>scNMT-seq enables joint profiling of chromatin accessibility DNA methylation and transcription in single cells</strong> <br />
Stephen J. Clark, Ricard Argelaguet, Chantriolnt-Andreas Kapourani, Thomas M. Stubbs, Heather J. Lee, Celia Alda-Catalinas, Felix Krueger, Guido Sanguinetti, Gavin Kelsey, John C. Marioni, … Wolf Reik<br />
<em>Nature Communications</em> (2018-02-22) <a href="https://doi.org/gc4q72">https://doi.org/gc4q72</a> <br />
DOI: <a href="https://doi.org/10.1038/s41467-018-03149-4">10.1038/s41467-018-03149-4</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29472610">29472610</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5823944">PMC5823944</a></p>
</div>
<div id="ref-1H9T8tTsB">
<p>11. <strong>Multi-omics profiling of mouse gastrulation at single-cell resolution</strong> <br />
Ricard Argelaguet, Stephen J. Clark, Hisham Mohammed, L. Carine Stapel, Christel Krueger, Chantriolnt-Andreas Kapourani, Ivan Imaz-Rosshandler, Tim Lohoff, Yunlong Xiang, Courtney W. Hanna, … Wolf Reik<br />
<em>Nature</em> (2019-12-11) <a href="https://doi.org/ggfrnn">https://doi.org/ggfrnn</a> <br />
DOI: <a href="https://doi.org/10.1038/s41586-019-1825-8">10.1038/s41586-019-1825-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31827285">31827285</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6924995">PMC6924995</a></p>
</div>
<div id="ref-cZOVX9E7">
<p>12. <strong>DIABLO: an integrative approach for identifying key molecular drivers from multi-omics assays</strong> <br />
Amrit Singh, Casey P Shannon, Benoît Gautier, Florian Rohart, Michaël Vacher, Scott J Tebbutt, Kim-Anh Lê Cao<br />
<em>Bioinformatics</em> (2019-09-01) <a href="https://doi.org/ggpt9c">https://doi.org/ggpt9c</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bty1054">10.1093/bioinformatics/bty1054</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30657866">30657866</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6735831">PMC6735831</a></p>
</div>
<div id="ref-MaZsghuS">
<p>13. <strong>Single-Cell Multi-omic Integration Compares and Contrasts Features of Brain Cell Identity</strong> <br />
Joshua D. Welch, Velina Kozareva, Ashley Ferreira, Charles Vanderburg, Carly Martin, Evan Z. Macosko<br />
<em>Cell</em> (2019-06) <a href="https://doi.org/gf3m3v">https://doi.org/gf3m3v</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2019.05.006">10.1016/j.cell.2019.05.006</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31178122">31178122</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6716797">PMC6716797</a></p>
</div>
<div id="ref-1156sEPws">
<p>14. <strong>Variance stabilization applied to microarray data calibration and to the quantification of differential expression</strong> <br />
W. Huber, A. von Heydebreck, H. Sultmann, A. Poustka, M. Vingron<br />
<em>Bioinformatics</em> (2002-07-01) <a href="https://doi.org/dbb6xx">https://doi.org/dbb6xx</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/18.suppl_1.s96">10.1093/bioinformatics/18.suppl_1.s96</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12169536">12169536</a></p>
</div>
<div id="ref-OekvE5up">
<p>15. <strong>Integrative inference of brain cell similarities and differences from single-cell genomics</strong> <br />
Joshua Welch, Velina Kozareva, Ashley Ferreira, Charles Vanderburg, Carly Martin, Evan Macosko<br />
<em>bioRxiv</em> (2018-11-02) <a href="https://doi.org/gfgr7b">https://doi.org/gfgr7b</a> <br />
DOI: <a href="https://doi.org/10.1101/459891">10.1101/459891</a></p>
</div>
<div id="ref-Ee0L8PLY">
<p>16. <strong>Variable selection for generalized canonical correlation analysis</strong> <br />
A. Tenenhaus, C. Philippe, V. Guillemot, K.-A. Le Cao, J. Grill, V. Frouin<br />
<em>Biostatistics</em> (2014-02-17) <a href="https://doi.org/gg583d">https://doi.org/gg583d</a> <br />
DOI: <a href="https://doi.org/10.1093/biostatistics/kxu001">10.1093/biostatistics/kxu001</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24550197">24550197</a></p>
</div>
<div id="ref-v4W8vQ17">
<p>17. <strong>mogsa</strong> <br />
Chen Meng<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg583f">https://doi.org/gg583f</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.mogsa">10.18129/b9.bioc.mogsa</a></p>
</div>
<div id="ref-UCIhFB5B">
<p>18. <strong>Combining the fourth-corner and the RLQ methods for assessing trait responses to environmental variation</strong> <br />
Stéphane Dray, Philippe Choler, Sylvain Dolédec, Pedro R. Peres-Neto, Wilfried Thuiller, Sandrine Pavoine, Cajo J. F. ter Braak<br />
<em>Ecology</em> (2014-01) <a href="https://doi.org/gdsf9z">https://doi.org/gdsf9z</a> <br />
DOI: <a href="https://doi.org/10.1890/13-0196.1">10.1890/13-0196.1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24649641">24649641</a></p>
</div>
<div id="ref-H4wZSl5d">
<p>19. <strong>What Is Your Conceptual Definition of “Cell Type” in the Context of a Mature Organism?</strong> <br />
Cell Systems<br />
(2017-03) <a href="https://doi.org/d38b">https://doi.org/d38b</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cels.2017.03.006">10.1016/j.cels.2017.03.006</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28334573">28334573</a></p>
</div>
<div id="ref-q9SIZrho">
<p>20. <strong>Multiple factor analysis.</strong> <br />
L. L. Thurstone<br />
<em>Psychological Review</em> (1931) <a href="https://doi.org/dq4k9p">https://doi.org/dq4k9p</a> <br />
DOI: <a href="https://doi.org/10.1037/h0069792">10.1037/h0069792</a></p>
</div>
<div id="ref-4fOW94wl">
<p>21. <strong>The ACT (STATIS method)</strong> <br />
Christine Lavit, Yves Escoufier, Robert Sabatier, Pierre Traissac<br />
<em>Computational Statistics &amp; Data Analysis</em> (1994-08) <a href="https://doi.org/c8xttz">https://doi.org/c8xttz</a> <br />
DOI: <a href="https://doi.org/10.1016/0167-9473(94)90134-1">10.1016/0167-9473(94)90134-1</a></p>
</div>
<div id="ref-18b0ymB7t">
<p>22. <strong>Multivariate data analysis: The French way</strong> <br />
Susan Holmes<br />
<em>Institute of Mathematical Statistics</em> (2008) <a href="https://doi.org/cmnf7j">https://doi.org/cmnf7j</a> <br />
DOI: <a href="https://doi.org/10.1214/193940307000000455">10.1214/193940307000000455</a></p>
</div>
<div id="ref-nhuT45y5">
<p>23. <strong>Multitable Methods for Microbiome Data Integration</strong> <br />
Kris Sankaran, Susan P. Holmes<br />
<em>Frontiers in Genetics</em> (2019-08-28) <a href="https://doi.org/gf8dqn">https://doi.org/gf8dqn</a> <br />
DOI: <a href="https://doi.org/10.3389/fgene.2019.00627">10.3389/fgene.2019.00627</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31555316">31555316</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6724662">PMC6724662</a></p>
</div>
<div id="ref-1ABBBCpyT">
<p>24. <strong>Quantitative, Architectural Analysis of Immune Cell Subsets in Tumor-Draining Lymph Nodes from Breast Cancer Patients and Healthy Lymph Nodes</strong> <br />
A. Francesca Setiadi, Nelson C. Ray, Holbrook E. Kohrt, Adam Kapelner, Valeria Carcamo-Cavazos, Edina B. Levic, Sina Yadegarynia, Chris M. van der Loos, Erich J. Schwartz, Susan Holmes, Peter P. Lee<br />
<em>PLoS ONE</em> (2010-08-25) <a href="https://doi.org/bp4qj5">https://doi.org/bp4qj5</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pone.0012420">10.1371/journal.pone.0012420</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20811638">20811638</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2928294">PMC2928294</a></p>
</div>
<div id="ref-XkAC715J">
<p>25. <strong>Mapping identifiers for the integration of genomic datasets with the R/Bioconductor package biomaRt</strong> <br />
Steffen Durinck, Paul T Spellman, Ewan Birney, Wolfgang Huber<br />
<em>Nature Protocols</em> (2009-07-23) <a href="https://doi.org/c4b7dd">https://doi.org/c4b7dd</a> <br />
DOI: <a href="https://doi.org/10.1038/nprot.2009.97">10.1038/nprot.2009.97</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19617889">19617889</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3159387">PMC3159387</a></p>
</div>
<div id="ref-1GblcsF7">
<p>26. <strong>Characterization of the Impact of Daclizumab Beta on Circulating Natural Killer Cells by Mass Cytometry</strong> <br />
Thanmayi Ranganath, Laura J. Simpson, Anne-Maud Ferreira, Christof Seiler, Elena Vendrame, Nancy Zhao, Jason D. Fontenot, Susan Holmes, Catherine A. Blish<br />
<em>Frontiers in Immunology</em> (2020-04-24) <a href="https://doi.org/gg5jcr">https://doi.org/gg5jcr</a> <br />
DOI: <a href="https://doi.org/10.3389/fimmu.2020.00714">10.3389/fimmu.2020.00714</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32391016">32391016</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7194113">PMC7194113</a></p>
</div>
<div id="ref-aSqxpadK">
<p>27. <strong>Machine learning: a probabilistic perspective</strong> <br />
Kevin P. Murphy<br />
<em>MIT Press</em> (2012) <br />
ISBN: <a href="https://worldcat.org/isbn/9780262018029">9780262018029</a></p>
</div>
<div id="ref-172t1QM5n">
<p>28. <strong>Dimensionality reduction for visualizing single-cell data using UMAP</strong> <br />
Etienne Becht, Leland McInnes, John Healy, Charles-Antoine Dutertre, Immanuel WH Kwok, Lai Guan Ng, Florent Ginhoux, Evan W Newell<br />
<em>Nature Biotechnology</em> (2018-12-03) <a href="https://doi.org/gfkwzq">https://doi.org/gfkwzq</a> <br />
DOI: <a href="https://doi.org/10.1038/nbt.4314">10.1038/nbt.4314</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30531897">30531897</a></p>
</div>
<div id="ref-chgaiKOU">
<p>29. <strong>Sparse canonical methods for biological data integration: application to a cross-platform study</strong> <br />
Kim-Anh Lê Cao, Pascal GP Martin, Christèle Robert-Granié, Philippe Besse<br />
<em>BMC Bioinformatics</em> (2009-01-26) <a href="https://doi.org/frn49f">https://doi.org/frn49f</a> <br />
DOI: <a href="https://doi.org/10.1186/1471-2105-10-34">10.1186/1471-2105-10-34</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19171069">19171069</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2640358">PMC2640358</a></p>
</div>
<div id="ref-vJJXeGCv">
<p>30.<strong>:{unav)</strong> <br />
Aedín C Culhane, Guy Perrière, Desmond G Higgins<br />
<em>BMC Bioinformatics</em> (2003) <a href="https://doi.org/fckzmd">https://doi.org/fckzmd</a> <br />
DOI: <a href="https://doi.org/10.1186/1471-2105-4-59">10.1186/1471-2105-4-59</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14633289">14633289</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC317282">PMC317282</a></p>
</div>
<div id="ref-MYhQ5fRN">
<p>31. <strong>Extensions of Sparse Canonical Correlation Analysis with Applications to Genomic Data</strong> <br />
Daniela M Witten, Robert J. Tibshirani<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2009-01-09) <a href="https://doi.org/b45jtg">https://doi.org/b45jtg</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1470">10.2202/1544-6115.1470</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19572827">19572827</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2861323">PMC2861323</a></p>
</div>
<div id="ref-NSuq56O9">
<p>32. <strong>MOGSA: Integrative Single Sample Gene-set Analysis of Multiple Omics Data</strong> <br />
Chen Meng, Azfar Basunia, Bjoern Peters, Amin Moghaddas Gholami, Bernhard Kuster, Aedín C. Culhane<br />
<em>Molecular &amp; Cellular Proteomics</em> (2019-08-09) <a href="https://doi.org/ggf3j3">https://doi.org/ggf3j3</a> <br />
DOI: <a href="https://doi.org/10.1074/mcp.tir118.001251">10.1074/mcp.tir118.001251</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31243065">31243065</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6692785">PMC6692785</a></p>
</div>
<div id="ref-13ibOJcF0">
<p>33. <strong>A Sparse PLS for Variable Selection when Integrating Omics Data</strong> <br />
Kim-Anh Lê Cao, Debra Rossouw, Christèle Robert-Granié, Philippe Besse<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2008-01-18) <a href="https://doi.org/cw7zft">https://doi.org/cw7zft</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1390">10.2202/1544-6115.1390</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19049491">19049491</a></p>
</div>
<div id="ref-maAEgLQK">
<p>34. <strong>Sparse principal component analysis via regularized low rank matrix approximation</strong> <br />
Haipeng Shen, Jianhua Z. Huang<br />
<em>Journal of Multivariate Analysis</em> (2008-07) <a href="https://doi.org/b7x3cc">https://doi.org/b7x3cc</a> <br />
DOI: <a href="https://doi.org/10.1016/j.jmva.2007.06.007">10.1016/j.jmva.2007.06.007</a></p>
</div>
<div id="ref-yVYfg2ZK">
<p>35. <strong>Quantifying the Association between Gene Expressions and DNA-Markers by Penalized Canonical Correlation Analysis</strong> <br />
Sandra Waaijenborg, Philip C. Verselewel de Witt Hamer, Aeilko H Zwinderman<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2008-01-23) <a href="https://doi.org/bpzb68">https://doi.org/bpzb68</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1329">10.2202/1544-6115.1329</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18241193">18241193</a></p>
</div>
<div id="ref-YY25QUrX">
<p>36. <strong><span style="font-weight:normal;">CCA</span> : An <em>R</em> Package to Extend Canonical Correlation Analysis</strong> <br />
Ignacio Gonzalez, Sébastien Déjean, Pascal Martin, Alain Baccini<br />
<em>Journal of Statistical Software</em> (2008) <a href="https://doi.org/gf4f5m">https://doi.org/gf4f5m</a> <br />
DOI: <a href="https://doi.org/10.18637/jss.v023.i12">10.18637/jss.v023.i12</a></p>
</div>
<div id="ref-5B54vifR">
<p>37. <strong>HIGHLIGHTING RELATIONSHIPS BETWEEN HETEROGENEOUS BIOLOGICAL DATA THROUGH GRAPHICAL DISPLAYS BASED ON REGULARIZED CANONICAL CORRELATION ANALYSIS</strong> <br />
I. GONZÁLEZ, S. DÉJEAN, P. G. P. MARTIN, O. GONÇALVES, P. BESSE, A. BACCINI<br />
<em>Journal of Biological Systems</em> (2011-11-21) <a href="https://doi.org/bmbjf5">https://doi.org/bmbjf5</a> <br />
DOI: <a href="https://doi.org/10.1142/s0218339009002831">10.1142/s0218339009002831</a></p>
</div>
<div id="ref-tOD4Gkgt">
<p>38. <strong>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</strong> <br />
D. M. Witten, R. Tibshirani, T. Hastie<br />
<em>Biostatistics</em> (2009-04-17) <a href="https://doi.org/fd4g54">https://doi.org/fd4g54</a> <br />
DOI: <a href="https://doi.org/10.1093/biostatistics/kxp008">10.1093/biostatistics/kxp008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19377034">19377034</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2697346">PMC2697346</a></p>
</div>
<div id="ref-AQWTNms4">
<p>39. <strong>Sparse Canonical Correlation Analysis with Application to Genomic Data Integration</strong> <br />
Elena Parkhomenko, David Tritchler, Joseph Beyene<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2009-01-06) <a href="https://doi.org/b7x4jb">https://doi.org/b7x4jb</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1406">10.2202/1544-6115.1406</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19222376">19222376</a></p>
</div>
<div id="ref-bFa7ptnr">
<p>40. <strong>Integrative analysis of gene expression and copy number alterations using canonical correlation analysis</strong> <br />
Charlotte Soneson, Henrik Lilljebjörn, Thoas Fioretos, Magnus Fontes<br />
<em>BMC Bioinformatics</em> (2010-04-15) <a href="https://doi.org/dtxhsx">https://doi.org/dtxhsx</a> <br />
DOI: <a href="https://doi.org/10.1186/1471-2105-11-191">10.1186/1471-2105-11-191</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20398334">20398334</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2873536">PMC2873536</a></p>
</div>
<div id="ref-wkhRfjyx">
<p>41. <strong>Gene expression signatures modulated by epidermal growth factor receptor activation and their relationship to cetuximab resistance in head and neck squamous cell carcinoma</strong> <br />
Elana J Fertig, Qing Ren, Haixia Cheng, Hiromitsu Hatakeyama, Adam P Dicker, Ulrich Rodeck, Michael Considine, Michael F Ochs, Christine H Chung<br />
<em>BMC Genomics</em> (2012) <a href="https://doi.org/gb3fgp">https://doi.org/gb3fgp</a> <br />
DOI: <a href="https://doi.org/10.1186/1471-2164-13-160">10.1186/1471-2164-13-160</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22549044">22549044</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3460736">PMC3460736</a></p>
</div>
<div id="ref-wP2BgpVi">
<p>42. <strong>Identifying multi-layer gene regulatory modules from multi-dimensional genomic data</strong> <br />
W. Li, S. Zhang, C.-C. Liu, X. J. Zhou<br />
<em>Bioinformatics</em> (2012-08-03) <a href="https://doi.org/f4d488">https://doi.org/f4d488</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bts476">10.1093/bioinformatics/bts476</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22863767">22863767</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3463121">PMC3463121</a></p>
</div>
<div id="ref-QSXGprag">
<p>43. <strong>mixOmics: An R package for ‘omics feature selection and multiple data integration</strong> <br />
Florian Rohart, Benoît Gautier, Amrit Singh, Kim-Anh Lê Cao<br />
<em>PLOS Computational Biology</em> (2017-11-03) <a href="https://doi.org/gcj84s">https://doi.org/gcj84s</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1005752">10.1371/journal.pcbi.1005752</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29099853">29099853</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5687754">PMC5687754</a></p>
</div>
<div id="ref-IZfv7up4">
<p>44. <strong>Consistency and overfitting of multi-omics methods on experimental data</strong> <br />
Sean D McCabe, Dan-Yu Lin, Michael I Love<br />
<em>Briefings in Bioinformatics</em> (2020-07) <a href="https://doi.org/gghpmf">https://doi.org/gghpmf</a> <br />
DOI: <a href="https://doi.org/10.1093/bib/bbz070">10.1093/bib/bbz070</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31281919">31281919</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7373174">PMC7373174</a></p>
</div>
<div id="ref-4CvJHFCU">
<p>45. <strong>Bootstrapping cluster analysis: Assessing the reliability of conclusions from microarray experiments</strong> <br />
M. K. Kerr, G. A. Churchill<br />
<em>Proceedings of the National Academy of Sciences</em> (2001-07-24) <a href="https://doi.org/cgpp6p">https://doi.org/cgpp6p</a> <br />
DOI: <a href="https://doi.org/10.1073/pnas.161273698">10.1073/pnas.161273698</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11470909">11470909</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC55356">PMC55356</a></p>
</div>
<div id="ref-QfQVcW0v">
<p>46.<strong>:{unav)</strong> <br />
Sandrine Dudoit, Jane Fridlyand<br />
<em>Genome Biology</em> (2002) <a href="https://doi.org/drffcb">https://doi.org/drffcb</a> <br />
DOI: <a href="https://doi.org/10.1186/gb-2002-3-7-research0036">10.1186/gb-2002-3-7-research0036</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12184810">12184810</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC126241">PMC126241</a></p>
</div>
<div id="ref-I1iOQSFC">
<p>47. <strong>A Three-Gene Model to Robustly Identify Breast Cancer Molecular Subtypes</strong> <br />
Benjamin Haibe-Kains, Christine Desmedt, Sherene Loi, Aedin C. Culhane, Gianluca Bontempi, John Quackenbush, Christos Sotiriou<br />
<em>JNCI: Journal of the National Cancer Institute</em> (2012-02-22) <a href="https://doi.org/fzb27r">https://doi.org/fzb27r</a> <br />
DOI: <a href="https://doi.org/10.1093/jnci/djr545">10.1093/jnci/djr545</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22262870">22262870</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3283537">PMC3283537</a></p>
</div>
<div id="ref-dwXJ9SC4">
<p>48. <strong>A federated ecosystem for sharing genomic, clinical data</strong> <br />
The Global Alliance for Genomics and Health<br />
<em>Science</em> (2016-06-09) <a href="https://doi.org/ggctm3">https://doi.org/ggctm3</a> <br />
DOI: <a href="https://doi.org/10.1126/science.aaf6162">10.1126/science.aaf6162</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27284183">27284183</a></p>
</div>
<div id="ref-102RKxFFz">
<p>49. <strong>GrimoireLab - Software Development and Community Analytics platform</strong> <a href="https://chaoss.github.io/grimoirelab/">https://chaoss.github.io/grimoirelab/</a></p>
</div>
<div id="ref-14np73aSU">
<p>50. <a href="http://ceur-ws.org/Vol-987/3.pdf">http://ceur-ws.org/Vol-987/3.pdf</a></p>
</div>
<div id="ref-E7tdylV2">
<p>51. <strong>Bioconductor - Home</strong> <a href="https://bioconductor.org/">https://bioconductor.org/</a></p>
</div>
<div id="ref-10Moc29vA">
<p>52. <strong>On System Scalability</strong> <br />
Charles B. Weinstock, John Goodenough<br />
<em>Figshare</em> (2018) <a href="https://doi.org/gg47cw">https://doi.org/gg47cw</a> <br />
DOI: <a href="https://doi.org/10.1184/r1/6575879.v1">10.1184/r1/6575879.v1</a></p>
</div>
<div id="ref-DxMfDYNc">
<p>53. <strong>BiocParallel: Bioconductor facilities for parallel evaluation</strong> <br />
Bioconductor Package Maintainer, Martin Morgan, Valerie Obenchain, Michel Lang, Ryan Thompson, Nitesh Turaga<br />
<em>Bioconductor version: Release (3.11)</em> (2020) <a href="https://bioconductor.org/packages/BiocParallel/">https://bioconductor.org/packages/BiocParallel/</a></p>
</div>
<div id="ref-oRTa5zGU">
<p>54. <strong>Bioconductor build/check results</strong> <a href="https://bioconductor.org/checkResults/">https://bioconductor.org/checkResults/</a></p>
</div>
<div id="ref-SkTqlnmn">
<p>55. <a href="https://bioconductor.org/support">https://bioconductor.org/support</a></p>
</div>
<div id="ref-gdnUpsQo">
<p>56. <strong>Software for the Integration of Multiomics Experiments in Bioconductor</strong> <br />
Marcel Ramos, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez, Tiffany Chan, Phil Chapman, Sean R. Davis, David Gomez-Cabrero, … Levi Waldron<br />
<em>Cancer Research</em> (2017-10-31) <a href="https://doi.org/gcj278">https://doi.org/gcj278</a> <br />
DOI: <a href="https://doi.org/10.1158/0008-5472.can-17-0344">10.1158/0008-5472.can-17-0344</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29092936">29092936</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5679241">PMC5679241</a></p>
</div>
<div id="ref-oDiClyTE">
<p>57. <strong>Ensembl 2020</strong> <br />
Andrew D Yates, Premanand Achuthan, Wasiu Akanni, James Allen, Jamie Allen, Jorge Alvarez-Jarreta, M Ridwan Amode, Irina M Armean, Andrey G Azov, Ruth Bennett, … Paul Flicek<br />
<em>Nucleic Acids Research</em> (2019-11-06) <a href="https://doi.org/ggqp72">https://doi.org/ggqp72</a> <br />
DOI: <a href="https://doi.org/10.1093/nar/gkz966">10.1093/nar/gkz966</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31691826">31691826</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7145704">PMC7145704</a></p>
</div>
<div id="ref-14d6Jzwus">
<p>58. <strong>Software for Computing and Annotating Genomic Ranges</strong> <br />
Michael Lawrence, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T. Morgan, Vincent J. Carey<br />
<em>PLoS Computational Biology</em> (2013-08-08) <a href="https://doi.org/f5cmfg">https://doi.org/f5cmfg</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1003118">10.1371/journal.pcbi.1003118</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23950696">23950696</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3738458">PMC3738458</a></p>
</div>
<div id="ref-R7sfk7Aq">
<p>59. <strong>SingleCellExperiment</strong> <br />
Aaron Lun [Aut, Cph], Davide Risso [Aut, Cre, Cph]<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg5wfr">https://doi.org/gg5wfr</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.singlecellexperiment">10.18129/b9.bioc.singlecellexperiment</a></p>
</div>
<div id="ref-KhbsUBNe">
<p>60. <strong>DelayedArray</strong> <br />
Hervé Pagès<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg5tw4">https://doi.org/gg5tw4</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.delayedarray">10.18129/b9.bioc.delayedarray</a></p>
</div>
<div id="ref-mOp2pMsC">
<p>61. <strong>rhdf5</strong> <br />
Bernd Fischer [Aut], Gregoire Pau [Aut], Mike Smith [Aut, Cre]<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg5tw6">https://doi.org/gg5tw6</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.rhdf5">10.18129/b9.bioc.rhdf5</a></p>
</div>
<div id="ref-g9O7LIML">
<p>62. <strong>mbkmeans: fast clustering for single cell data using mini-batch <em>k</em> -means</strong> <br />
Stephanie C. Hicks, Ruoxi Liu, Yuwei Ni, Elizabeth Purdom, Davide Risso<br />
<em>bioRxiv</em> (2020-05-27) <a href="https://doi.org/gg5tw3">https://doi.org/gg5tw3</a> <br />
DOI: <a href="https://doi.org/10.1101/2020.05.27.119438">10.1101/2020.05.27.119438</a></p>
</div>
<div id="ref-19jAJjD6o">
<p>63. <strong>mbkmeans</strong> <br />
Yuwei Ni, Davide Risso, Stephanie Hicks, Elizabeth Purdom<br />
<em>Bioconductor</em> <a href="https://doi.org/gg5tw5">https://doi.org/gg5tw5</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.mbkmeans">10.18129/b9.bioc.mbkmeans</a></p>
</div>
<div id="ref-qIZTS1II">
<p>64. <strong>SCANPY: large-scale single-cell gene expression data analysis</strong> <br />
F. Alexander Wolf, Philipp Angerer, Fabian J. Theis<br />
<em>Genome Biology</em> (2018-02-06) <a href="https://doi.org/gc22s9">https://doi.org/gc22s9</a> <br />
DOI: <a href="https://doi.org/10.1186/s13059-017-1382-0">10.1186/s13059-017-1382-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29409532">29409532</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5802054">PMC5802054</a></p>
</div>
<div id="ref-x7pNDE94">
<p>65. <a href="https://tinyurl.com/y4emdyvr">https://tinyurl.com/y4emdyvr</a></p>
</div>
<div id="ref-11uDSb0Nf">
<p>66. <strong>Points of view: Color blindness</strong> <br />
Bang Wong<br />
<em>Nature Methods</em> (2011-06-01) <a href="https://www.nature.com/articles/nmeth.1618">https://www.nature.com/articles/nmeth.1618</a> <br />
DOI: <a href="https://doi.org/10.1038/nmeth.1618">10.1038/nmeth.1618</a></p>
</div>
<div id="ref-Ecm3XS4">
<p>67. <strong>Color coding</strong> <br />
Bang Wong<br />
<em>Nature Methods</em> (2010-08) <a href="https://doi.org/dhm3mz">https://doi.org/dhm3mz</a> <br />
DOI: <a href="https://doi.org/10.1038/nmeth0810-573">10.1038/nmeth0810-573</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20704014">20704014</a></p>
</div>
<div id="ref-lLv68Zzx">
<p>68. <strong>The viridis color palettes</strong> <a href="https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html">https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html</a></p>
</div>
<div id="ref-19usrpNlS">
<p>69. <strong>dtm2451/dittoSeq</strong> <br />
Daniel Bunis<br />
(2020-07-29) <a href="https://github.com/dtm2451/dittoSeq">https://github.com/dtm2451/dittoSeq</a></p>
</div>
<div id="ref-18fTyQGoG">
<p>70. <strong>Multivariate analysis of multiblock and multigroup data</strong> <br />
A. Eslami, E. M. Qannari, A. Kohler, S. Bougeard<br />
<em>Chemometrics and Intelligent Laboratory Systems</em> (2014-04) <a href="https://doi.org/f52wrr">https://doi.org/f52wrr</a> <br />
DOI: <a href="https://doi.org/10.1016/j.chemolab.2014.01.016">10.1016/j.chemolab.2014.01.016</a></p>
</div>
<div id="ref-2SDWXiwB">
<p>71. <strong>Dimension reduction techniques for the integrative analysis of multi-omics data</strong> <br />
Chen Meng, Oana A. Zeleznik, Gerhard G. Thallinger, Bernhard Kuster, Amin M. Gholami, Aedín C. Culhane<br />
<em>Briefings in Bioinformatics</em> (2016-07) <a href="https://doi.org/f83qvd">https://doi.org/f83qvd</a> <br />
DOI: <a href="https://doi.org/10.1093/bib/bbv108">10.1093/bib/bbv108</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26969681">26969681</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4945831">PMC4945831</a></p>
</div>
<div id="ref-UqaGRGDg">
<p>72. <strong>Robust meta-analysis of gene expression using the elastic net</strong> <br />
Jacob J. Hughey, Atul J. Butte<br />
<em>Nucleic Acids Research</em> (2015-07-13) <a href="https://doi.org/f7nnbm">https://doi.org/f7nnbm</a> <br />
DOI: <a href="https://doi.org/10.1093/nar/gkv229">10.1093/nar/gkv229</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25829177">25829177</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4499117">PMC4499117</a></p>
</div>
<div id="ref-AtapBaNb">
<p>73. <strong>Biomarker definitions and their applications</strong> <br />
Robert M Califf<br />
<em>Experimental Biology and Medicine</em> (2018-02-06) <a href="https://doi.org/gcxh8n">https://doi.org/gcxh8n</a> <br />
DOI: <a href="https://doi.org/10.1177/1535370217750088">10.1177/1535370217750088</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29405771">29405771</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5813875">PMC5813875</a></p>
</div>
<div id="ref-17aD4MFPS">
<p>74. <strong>Biomarker signatures of aging</strong> <br />
Paola Sebastiani, Bharat Thyagarajan, Fangui Sun, Nicole Schupf, Anne B. Newman, Monty Montano, Thomas T. Perls<br />
<em>Aging Cell</em> (2017-04) <a href="https://doi.org/d2cm">https://doi.org/d2cm</a> <br />
DOI: <a href="https://doi.org/10.1111/acel.12557">10.1111/acel.12557</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28058805">28058805</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5334528">PMC5334528</a></p>
</div>
<div id="ref-XWx8RAwW">
<p>75. <strong>Biomarker Panels in Critical Care</strong> <br />
Susan R. Conway, Hector R. Wong<br />
<em>Critical Care Clinics</em> (2020-01) <a href="https://doi.org/d2cn">https://doi.org/d2cn</a> <br />
DOI: <a href="https://doi.org/10.1016/j.ccc.2019.08.007">10.1016/j.ccc.2019.08.007</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31733684">31733684</a></p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Supposes a thesis (e.g. the guilt of an accused man) is supported by a great deal of circumstantial evidence of different forms, but in agreement with each other; then even if each piece of evidence is in itself insufficient to produce any strong belief, the thesis is decisively strengthened by their joint effect.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!-- default theme -->

<style>
    /* import google fonts */
    @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
    @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

    /* -------------------------------------------------- */
    /* global */
    /* -------------------------------------------------- */

    /* all elements */
    * {
        /* force sans-serif font unless specified otherwise */
        font-family: "Open Sans", "Helvetica", sans-serif;

        /* prevent text inflation on some mobile browsers */
        -webkit-text-size-adjust: none !important;
        -moz-text-size-adjust: none !important;
        -o-text-size-adjust: none !important;
        text-size-adjust: none !important;
    }

    @media only screen {
        /* "page" element */
        body {
            position: relative;
            box-sizing: border-box;
            font-size: 12pt;
            line-height: 1.5;
            max-width: 8.5in;
            margin: 20px auto;
            padding: 40px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* "page" element */
        body {
            padding: 20px;
            margin: 0;
            border-radius: 0;
            border: none;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
            background: none;
        }
    }

    /* -------------------------------------------------- */
    /* headings */
    /* -------------------------------------------------- */

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 20px 0;
        padding: 0;
        font-weight: bold;
    }

    /* biggest heading */
    h1 {
        margin: 40px 0;
        text-align: center;
    }

    /* second biggest heading */
    h2 {
        margin-top: 30px;
        padding-bottom: 5px;
        border-bottom: solid 1px #bdbdbd;
    }

    /* heading font sizes */
    h1 {
        font-size: 2em;
    }
    h2 {
        font-size: 1.5em;
    }
    h3{
        font-size: 1.35em;
    }
    h4 {
        font-size: 1.25em;
    }
    h5 {
        font-size: 1.15em;
    }
    h6 {
        font-size: 1em;
    }

    /* -------------------------------------------------- */
    /* manuscript header */
    /* -------------------------------------------------- */

    /* manuscript title */
    header > h1 {
        margin: 0;
    }

    /* manuscript title caption text (ie "automatically generated on") */
    header + p {
        text-align: center;
        margin-top: 10px;
    }

    /* -------------------------------------------------- */
    /* text elements */
    /* -------------------------------------------------- */

    /* links */
    a {
        color: #2196f3;
        overflow-wrap: break-word;
    }

    /* normal links (not empty, not button link, not syntax highlighting link) */
    a:not(:empty):not(.button):not(.sourceLine) {
        padding-left: 1px;
        padding-right: 1px;
    }

    /* superscripts and subscripts */
    sub,
    sup {
        /* prevent from affecting line height */
        line-height: 0;
    }

    /* unordered and ordered lists*/
    ul,
    ol {
        padding-left: 20px;
    }

    /* class for styling text semibold */
    .semibold {
        font-weight: 600;
    }

    /* class for styling elements horizontally left aligned */
    .left {
        display: block;
        text-align: left;
        margin-left: auto;
        margin-right: 0;
        justify-content: left;
    }

    /* class for styling elements horizontally centered */
    .center {
        display: block;
        text-align: center;
        margin-left: auto;
        margin-right: auto;
        justify-content: center;
    }

    /* class for styling elements horizontally right aligned */
    .right {
        display: block;
        text-align: right;
        margin-left: 0;
        margin-right: auto;
        justify-content: right;
    }

    /* -------------------------------------------------- */
    /* section elements */
    /* -------------------------------------------------- */

    /* horizontal divider line */
    hr {
        border: none;
        height: 1px;
        background: #bdbdbd;
    }

    /* paragraphs, horizontal dividers, figures, tables, code */
    p,
    hr,
    figure,
    table,
    pre {
        /* treat all as "paragraphs", with consistent vertical margins */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* figures */
    /* -------------------------------------------------- */

    /* figure */
    figure {
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure caption */
    figcaption {
        padding: 0;
        padding-top: 10px;
    }

    /* figure image element */
    figure img {
        max-width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure auto-number */
    img + figcaption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* tables */
    /* -------------------------------------------------- */

    /* table */
    table {
        border-collapse: collapse;
        border-spacing: 0;
        width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* table cells */
    th,
    td {
        border: solid 1px #bdbdbd;
        padding: 10px;
        /* squash table if too wide for page by forcing line breaks */
        overflow-wrap: break-word;
        word-break: break-word;
    }

    /* header row and even rows */
    th,
    tr:nth-child(2n) {
        background-color: #fafafa;
    }

    /* odd rows */
    tr:nth-child(2n + 1) {
        background-color: #ffffff;
    }

    /* table caption */
    caption {
        text-align: left;
        padding: 0;
        padding-bottom: 10px;
    }

    /* table auto-number */
    table > caption > span:first-of-type,
    div.table_wrapper > table > caption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* code */
    /* -------------------------------------------------- */

    /* multi-line code block */
    pre {
        padding: 10px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
        break-inside: avoid;
        text-align: left;
    }

    /* inline code, ie code within normal text */
    :not(pre) > code {
        padding: 0 4px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
    }

    /* code text */
    /* apply all children, to reach syntax highlighting sub-elements */
    code,
    code * {
        /* force monospace font */
        font-family: "Source Code Pro", "Courier New", monospace;
    }

    /* -------------------------------------------------- */
    /* quotes */
    /* -------------------------------------------------- */

    /* quoted text */
    blockquote {
        margin: 0;
        padding: 0;
        border-left: 4px solid #bdbdbd;
        padding-left: 16px;
        break-inside: avoid;
    }

    /* -------------------------------------------------- */
    /* banners */
    /* -------------------------------------------------- */

    /* info banners */
    .banner {
        box-sizing: border-box;
        display: block;
        position: relative;
        width: 100%;
        margin-top: 20px;
        margin-bottom: 20px;
        padding: 20px;
        text-align: center;
    }

    /* paragraph in banner */
    .banner > p {
        margin: 0;
    }

    /* -------------------------------------------------- */
    /* highlight colors */
    /* -------------------------------------------------- */

    .white {
        background: #ffffff;
    }
    .lightgrey {
        background: #eeeeee;
    }
    .grey {
        background: #757575;
    }
    .darkgrey {
        background: #424242;
    }
    .black {
        background: #000000;
    }
    .lightred {
        background: #ffcdd2;
    }
    .lightyellow {
        background: #ffecb3;
    }
    .lightgreen {
        background: #dcedc8;
    }
    .lightblue {
        background: #e3f2fd;
    }
    .lightpurple {
        background: #f3e5f5;
    }
    .red {
        background: #f44336;
    }
    .orange {
        background: #ff9800;
    }
    .yellow {
        background: #ffeb3b;
    }
    .green {
        background: #4caf50;
    }
    .blue {
        background: #2196f3;
    }
    .purple {
        background: #9c27b0;
    }
    .white,
    .lightgrey,
    .lightred,
    .lightyellow,
    .lightgreen,
    .lightblue,
    .lightpurple,
    .orange,
    .yellow,
    .white a,
    .lightgrey a,
    .lightred a,
    .lightyellow a,
    .lightgreen a,
    .lightblue a,
    .lightpurple a,
    .orange a,
    .yellow a {
        color: #000000;
    }
    .grey,
    .darkgrey,
    .black,
    .red,
    .green,
    .blue,
    .purple,
    .grey a,
    .darkgrey a,
    .black a,
    .red a,
    .green a,
    .blue a,
    .purple a {
        color: #ffffff;
    }

    /* -------------------------------------------------- */
    /* buttons */
    /* -------------------------------------------------- */

    /* class for styling links like buttons */
    .button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        margin: 5px;
        padding: 10px 20px;
        font-size: 0.75em;
        font-weight: 600;
        text-transform: uppercase;
        text-decoration: none;
        letter-spacing: 1px;
        background: none;
        color: #2196f3;
        border: solid 1px #bdbdbd;
        border-radius: 5px;
    }

    /* buttons when hovered */
    .button:hover:not([disabled]),
    .icon_button:hover:not([disabled]) {
        cursor: pointer;
        background: #f5f5f5;
    }

    /* buttons when disabled */
    .button[disabled],
    .icon_button[disabled] {
        opacity: 0.35;
        pointer-events: none;
    }

    /* class for styling buttons containg only single icon */
    .icon_button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        text-decoration: none;
        margin: 0;
        padding: 0;
        background: none;
        border-radius: 5px;
        border: none;
        width: 20px;
        height: 20px;
        min-width: 20px;
        min-height: 20px;
    }

    /* icon button inner svg image */
    .icon_button > svg {
        height: 16px;
    }

    /* -------------------------------------------------- */
    /* icons */
    /* -------------------------------------------------- */

    /* class for styling icons inline with text */
    .inline_icon {
        height: 1em;
        position: relative;
        top: 0.125em;
    }

    /* -------------------------------------------------- */
    /* print control */
    /* -------------------------------------------------- */

    @media print {
        @page {
            /* suggested printing margin */
            margin: 0.5in;
        }

        /* document and "page" elements */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
        }

        /* "page" element */
        body {
            font-size: 11pt !important;
            line-height: 1.35;
        }

        /* all headings */
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            margin: 15px 0;
        }

        /* figures and tables */
        figure, table {
            font-size: 0.85em;
        }

        /* table cells */
        th,
        td {
            padding: 5px;
        }

        /* shrink font awesome icons */
        i.fas,
        i.fab,
        i.far,
        i.fal {
            transform: scale(0.85);
        }

        /* decrease banner margins */
        .banner {
            margin-top: 15px;
            margin-bottom: 15px;
            padding: 15px;
        }

        /* class for centering an element vertically on its own page */
        .page_center {
            margin: auto;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            vertical-align: middle;
            break-before: page;
            break-after: page;
        }

        /* always insert a page break before the element */
        .page_break_before {
            break-before: page;
        }

        /* always insert a page break after the element */
        .page_break_after {
            break-after: page;
        }

        /* avoid page break before the element */
        .page_break_before_avoid {
            break-before: avoid;
        }

        /* avoid page break after the element */
        .page_break_after_avoid {
            break-after: avoid;
        }

        /* avoid page break inside the element */
        .page_break_inside_avoid {
            break-inside: avoid;
        }
    }

    /* -------------------------------------------------- */
    /* override pandoc css quirks */
    /* -------------------------------------------------- */

    .sourceCode {
        /* prevent unsightly overflow in wide code blocks */
        overflow: auto !important;
    }

    div.sourceCode {
        /* prevent background fill on top-most code block  container */
        background: none !important;
    }

    .sourceCode * {
        /* force consistent line spacing */
        line-height: 1.5 !important;
    }

    div.sourceCode {
        /* style code block margins same as <pre> element */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* tablenos */
    /* -------------------------------------------------- */

    /* tablenos wrapper */
    .tablenos {
        /* show scrollbar on tables if necessary to prevent overflow */
        width: 100%;
        margin: 20px 0;
    }

    .tablenos > table {
        /* move margins from table to table_wrapper to allow margin collapsing */
        margin: 0;
    }

    @media only screen {
        /* tablenos wrapper */
        .tablenos {
            /* show scrollbar on tables if necessary to prevent overflow */
            overflow-x: auto !important;
        }

        .tablenos th,
        .tablenos td {
            overflow-wrap: unset !important;
            word-break: unset !important;
        }

        /* table in wrapper */
        .tablenos table,
        .tablenos table * {
            /* don't break table words */
            overflow-wrap: normal !important;
        }
    }

    /* -------------------------------------------------- */
    /* mathjax */
    /* -------------------------------------------------- */

    /* mathjax containers */
    .math.display > span:not(.MathJax_Preview) {
        /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
        display: flex !important;
        overflow-x: auto !important;
        overflow-y: hidden !important;
        justify-content: center;
        align-items: center;
        margin: 0 !important;
    }

    /* right click menu */
    .MathJax_Menu {
        border-radius: 5px !important;
        border: solid 1px #bdbdbd !important;
        box-shadow: none !important;
    }

    /* equation auto-number */
    span[id^="eq:"] > span.math.display + span {
        font-weight: 600;
    }

    /* equation */
    span[id^="eq:"] > span.math.display > span {
        /* nudge to make room for equation auto-number and anchor */
        margin-right: 60px !important;
    }

    /* -------------------------------------------------- */
    /* anchors plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anchor button */
        .anchor {
            opacity: 0;
            margin-left: 5px;
        }

        /* anchor buttons within <h2>'s */
        h2 .anchor {
            margin-left: 10px;
        }

        /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
        *:hover > .anchor,
        .anchor:hover,
        .anchor:focus {
            opacity: 1;
        }

        /* anchor button when hovered */
        .anchor:hover {
            cursor: pointer;
        }
    }

    /* always show anchor button on devices with no mouse/hover ability */
    @media (hover: none) {
        .anchor {
            opacity: 1;
        }
    }

    /* always hide anchor button on print */
    @media only print {
        .anchor {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* accordion plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* accordion arrow button */
        .accordion_arrow {
            margin-right: 10px;
        }

        /* arrow icon when <h2> data-collapsed attribute true */
        h2[data-collapsed="true"] > .accordion_arrow > svg {
            transform: rotate(-90deg);
        }

        /* all elements (except <h2>'s) when data-collapsed attribute true */
        *:not(h2)[data-collapsed="true"] {
            display: none;
        }

        /* accordion arrow button when hovered and <h2>'s when hovered */
        .accordion_arrow:hover,
        h2[data-collapsed="true"]:hover,
        h2[data-collapsed="false"]:hover {
            cursor: pointer;
        }
    }

    /* always hide accordion arrow button on print */
    @media only print {
        .accordion_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* tooltips plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* tooltip container */
        #tooltip {
            position: absolute;
            width: 50%;
            min-width: 240px;
            max-width: 75%;
            z-index: 1;
        }

        /* tooltip content */
        #tooltip_content {
            margin-bottom: 5px;
            padding: 20px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
            overflow-wrap: break-word;
        }

        /* tooltip copy of paragraphs and figures */
        #tooltip_content > p,
        #tooltip_content > figure {
            margin: 0;
            max-height: 320px;
            overflow-y: auto;
        }

        /* tooltip copy of <img> */
        #tooltip_content > figure > img {
            max-height: 260px;
        }

        /* navigation bar */
        #tooltip_nav_bar {
            margin-top: 10px;
            text-align: center;
        }

        /* navigation bar previous/next buton */
        #tooltip_nav_bar > .icon_button {
            position: relative;
            top: 3px;
        }

        /* navigation bar previous button */
        #tooltip_nav_bar > .icon_button:first-of-type {
            margin-right: 5px;
        }

        /* navigation bar next button */
        #tooltip_nav_bar > .icon_button:last-of-type {
            margin-left: 5px;
        }
    }

    /* always hide tooltip on print */
    @media only print {
        #tooltip {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* jump to first plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* jump button */
        .jump_arrow {
            position: relative;
            top: 0.125em;
            margin-right: 5px;
        }
    }

    /* always hide jump button on print */
    @media only print {
        .jump_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* link highlight plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anything with data-highlighted attribute true */
        [data-highlighted="true"] {
            background: #ffeb3b;
        }

        /* anything with data-selected attribute true */
        [data-selected="true"] {
            background: #ff8a65 !important;
        }

        /* animation definition for glow */
        @keyframes highlight_glow {
            0% {
                background: none;
            }
            10% {
                background: #bbdefb;
            }
            100% {
                background: none;
            }
        }

        /* anything with data-glow attribute true */
        [data-glow="true"] {
            animation: highlight_glow 2s;
        }
    }

    /* -------------------------------------------------- */
    /* table of contents plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* toc panel */
        #toc_panel {
            box-sizing: border-box;
            position: fixed;
            top: 0;
            left: 0;
            background: #ffffff;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            z-index: 2;
        }

        /* toc panel when closed */
        #toc_panel[data-open="false"] {
            min-width: 60px;
            width: 60px;
            height: 60px;
            border-right: solid 1px #bdbdbd;
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc panel when open */
        #toc_panel[data-open="true"] {
            min-width: 260px;
            max-width: 480px;
            /* keep panel edge consistent distance away from "page" edge */
            width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
            bottom: 0;
            border-right: solid 1px #bdbdbd;
        }

        /* toc panel header */
        #toc_header {
            box-sizing: border-box;
            display: flex;
            flex-direction: row;
            align-items: center;
            height: 60px;
            margin: 0;
            padding: 20px;
        }

        /* toc panel header when hovered */
        #toc_header:hover {
            cursor: pointer;
        }

        /* toc panel header when panel open */
        #toc_panel[data-open="true"] > #toc_header {
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc open/close header button */
        #toc_button {
            margin-right: 20px;
        }

        /* hide toc list and header text when closed */
        #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
        #toc_panel[data-open="false"] > #toc_list {
            display: none;
        }

        /* toc list of entries */
        #toc_list {
            box-sizing: border-box;
            width: 100%;
            padding: 20px;
            position: absolute;
            top: calc(60px + 1px);
            bottom: 0;
            overflow: auto;
        }

        /* toc entry, link to section in document */
        .toc_link {
            display: block;
            padding: 5px;
            position: relative;
            font-weight: 600;
            text-decoration: none;
        }

        /* toc entry when hovered or when "viewed" */
        .toc_link:hover,
        .toc_link[data-viewing="true"] {
            background: #f5f5f5;
        }

        /* toc entry, level 1 indentation */
        .toc_link[data-level="1"] {
            margin-left: 0;
        }

        /* toc entry, level 2 indentation */
        .toc_link[data-level="2"] {
            margin-left: 20px;
        }

        /* toc entry, level 3 indentation */
        .toc_link[data-level="3"] {
            margin-left: 40px;
        }

        /* toc entry, level 4 indentation */
        .toc_link[data-level="4"] {
            margin-left: 60px;
        }

        /* toc entry bullets */
        #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
            position: absolute;
            left: -15px;
            top: -1px;
            font-size: 1.5em;
        }

        /* toc entry, level 2 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
            content: "\2022";
        }

        /* toc entry, level 3 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
            content: "\25AB";
        }

        /* toc entry, level 4 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
            content: "-";
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* push <body> ("page") element down to make room for toc icon */
        .toc_body_nudge {
            padding-top: 60px;
        }

        /* toc icon when panel closed and not hovered */
        #toc_panel[data-open="false"]:not(:hover) {
            background: rgba(255, 255, 255, 0.75);
        }
    }

    /* always hide toc panel on print */
    @media only print {
        #toc_panel {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* lightbox plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* regular <img> in document when hovered */
        .lightbox_document_img:hover {
            cursor: pointer;
        }

        .body_no_scroll {
            overflow: hidden !important;
        }

        /* screen overlay */
        #lightbox_overlay {
            display: flex;
            flex-direction: column;
            position: fixed;
            left: 0;
            top: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.75);
            z-index: 3;
        }

        /* middle area containing lightbox image */
        #lightbox_image_container {
            flex-grow: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            position: relative;
            padding: 20px;
        }

        /* bottom area containing caption */
        #lightbox_bottom_container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100px;
            min-height: 100px;
            max-height: 100px;
            background: rgba(0, 0, 0, 0.5);
        }

        /* image number info text box */
        #lightbox_number_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            left: 2px;
            top: 0;
            z-index: 4;
        }

        /* zoom info text box */
        #lightbox_zoom_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            right: 2px;
            top: 0;
            z-index: 4;
        }

        /* copy of image caption */
        #lightbox_caption {
            box-sizing: border-box;
            display: inline-block;
            width: 100%;
            max-height: 100%;
            padding: 10px 0;
            text-align: center;
            overflow-y: auto;
            color: #ffffff;
        }

        /* navigation previous/next button */
        .lightbox_button {
            width: 100px;
            height: 100%;
            min-width: 100px;
            min-height: 100%;
            color: #ffffff;
        }

        /* navigation previous/next button when hovered */
        .lightbox_button:hover {
            background: none !important;
        }

        /* navigation button icon */
        .lightbox_button > svg {
            height: 25px;
        }

        /* figure auto-number */
        #lightbox_caption > span:first-of-type {
            font-weight: bold;
            margin-right: 5px;
        }

        /* lightbox image when hovered */
        #lightbox_img:hover {
            cursor: grab;
        }

        /* lightbox image when grabbed */
        #lightbox_img:active {
            cursor: grabbing;
        }
    }

    /* when on screen < 480px wide */
    @media only screen and (max-width: 480px) {
        /* make navigation buttons skinnier on small screens to make more room for caption text */
        .lightbox_button {
            width: 50px;
            min-width: 50px;
        }
    }

    /* always hide lightbox on print */
    @media only print {
        #lightbox_overlay {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* hypothesis (annotations) plugin */
    /* -------------------------------------------------- */

    /* hypothesis activation button */
    #hypothesis_button {
        box-sizing: border-box;
        position: fixed;
        top: 0;
        right: 0;
        width: 60px;
        height: 60px;
        background: #ffffff;
        border-radius: 0;
        border-left: solid 1px #bdbdbd;
        border-bottom: solid 1px #bdbdbd;
        box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
        z-index: 2;
    }

    /* hypothesis button svg */
    #hypothesis_button > svg {
        position: relative;
        top: -4px;
    }

    /* hypothesis annotation count */
    #hypothesis_count {
        position: absolute;
        left: 0;
        right: 0;
        bottom: 5px;
    }

    /* side panel */
    .annotator-frame {
        width: 280px !important;
    }

    /* match highlight color to rest of theme */
    .annotator-highlights-always-on .annotator-hl {
        background-color: #ffeb3b !important;
    }

    /* match focused color to rest of theme */
    .annotator-hl.annotator-hl-focused {
        background-color: #ff8a65 !important;
    }

    /* match bucket bar color to rest of theme */
    .annotator-bucket-bar {
        background: #f5f5f5 !important;
    }

    /* always hide button, toolbar, and tooltip on print */
    @media only print {
        #hypothesis_button {
            display: none;
        }

        .annotator-frame {
            display: none !important;
        }

        hypothesis-adder {
            display: none !important;
        }
    }
</style>
<!-- anchors plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds an anchor next to each of a certain type
        // of element that provides a human-readable url to that specific
        // item/position in the document (eg "manuscript.html#abstract"). It
        // also makes it such that scrolling out of view of a target removes
        // its identifier from the url.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'anchors';

        // default plugin options
        const options = {
            // which types of elements to add anchors next to, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3, [id^="fig:"], [id^="tbl:"], [id^="eq:"]',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // add anchor to each element of specified types
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements)
                addAnchor(element);

            // attach scroll listener to window
            window.addEventListener('scroll', onScroll);
        }

        // when window is scrolled
        function onScroll() {
            // if url has hash and user has scrolled out of view of hash
            // target, remove hash from url
            const tolerance = 100;
            const target = getHashTarget();
            if (target) {
                if (
                    target.getBoundingClientRect().top >
                        window.innerHeight + tolerance ||
                    target.getBoundingClientRect().bottom < 0 - tolerance
                )
                    history.pushState(null, null, ' ');
            }
        }

        // add anchor to element
        function addAnchor(element) {
            let addTo; // element to add anchor button to

            // if figure or table, modify withId and addTo to get expected
            // elements
            if (element.id.indexOf('fig:') === 0) {
                addTo = element.querySelector('figcaption');
            } else if (element.id.indexOf('tbl:') === 0) {
                addTo = element.querySelector('caption');
            } else if (element.id.indexOf('eq:') === 0) {
                addTo = element.querySelector('.eqnos-number');
            }

            addTo = addTo || element;
            const id = element.id || null;

            // do not add anchor if element doesn't have assigned id.
            // id is generated by pandoc and is assumed to be unique and
            // human-readable
            if (!id)
                return;

            // create anchor button
            const anchor = document.createElement('a');
            anchor.innerHTML = document.querySelector('.icon_link').innerHTML;
            anchor.title = 'Link to this part of the document';
            anchor.classList.add('icon_button', 'anchor');
            anchor.dataset.ignore = 'true';
            anchor.href = '#' + id;
            addTo.appendChild(anchor);
        }

        // get element that is target of link or url hash
        function getHashTarget() {
            const hash = window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- link icon -->

<template class="icon_link">
    <!-- modified from: https://fontawesome.com/icons/link -->
    <svg width="16" height="16" viewBox="0 0 512 512">
        <path
            fill="currentColor"
            d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
        ></path>
    </svg>
</template>
<!-- accordion plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows sections of content under <h2> headings
        // to be collapsible.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'accordion';

        // default plugin options
        const options = {
            // whether to always start expanded ('false'), always start
            // collapsed ('true'), or start collapsed when screen small ('auto')
            startCollapsed: 'auto',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <h2> heading
            const headings = document.querySelectorAll('h2');
            for (const heading of headings) {
                addArrow(heading);

                // start expanded/collapsed based on option
                if (
                    options.startCollapsed === 'true' ||
                    (options.startCollapsed === 'auto' && isSmallScreen())
                )
                    collapseHeading(heading);
                else
                    expandHeading(heading);
            }

            // attach hash change listener to window
            window.addEventListener('hashchange', onHashChange);
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                goToElement(target);
        }

        // add arrow to heading
        function addArrow(heading) {
            // add arrow button
            const arrow = document.createElement('button');
            arrow.innerHTML = document.querySelector(
                '.icon_angle_down'
            ).innerHTML;
            arrow.classList.add('icon_button', 'accordion_arrow');
            heading.insertBefore(arrow, heading.firstChild);

            // attach click listener to heading and button
            heading.addEventListener('click', onHeadingClick);
            arrow.addEventListener('click', onArrowClick);
        }

        // determine if on mobile-like device with small screen
        function isSmallScreen() {
            return Math.min(window.innerWidth, window.innerHeight) < 480;
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get element that is target of hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // when <h2> heading is clicked
        function onHeadingClick(event) {
            // only collapse if <h2> itself is target of click (eg, user did
            // not click on anchor within <h2>)
            if (event.target === this)
                toggleCollapse(this);
        }

        // when arrow button is clicked
        function onArrowClick() {
            toggleCollapse(this.parentNode);
        }

        // collapse section if expanded, expand if collapsed
        function toggleCollapse(heading) {
            if (heading.dataset.collapsed === 'false')
                collapseHeading(heading);
            else
                expandHeading(heading);
        }

        // elements to exclude from collapse, such as table of contents panel,
        // hypothesis panel, etc
        const exclude = '#toc_panel, div.annotator-frame, #lightbox_overlay';

        // collapse section
        function collapseHeading(heading) {
            heading.setAttribute('data-collapsed', 'true');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'true');
        }

        // expand section
        function expandHeading(heading) {
            heading.setAttribute('data-collapsed', 'false');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'false');
        }

        // get list of elements between this <h2> and next <h2> or <h1>
        // ("children" of the <h2> section)
        function getChildren(heading) {
            return nextUntil(heading, 'h2, h1', exclude);
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get list of elements after a start element up to element matching
        // query
        function nextUntil(element, query, exclude) {
            const elements = [];
            while (element = element.nextElementSibling, element) {
                if (element.matches(query))
                    break;
                if (!element.matches(exclude))
                    elements.push(element);
            }
            return elements;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
    <!-- modified from: https://fontawesome.com/icons/angle-down -->
    <svg width="16" height="16" viewBox="0 0 448 512">
        <path
            fill="currentColor"
            d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
        ></path>
    </svg>
</template>
<!-- tooltips plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when the user hovers or
        // focuses a link to a citation or figure, a tooltip appears with a
        // preview of the reference content, along with arrows to navigate
        // between instances of the same reference in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tooltips';

        // default plugin options
        const options = {
            // whether user must click off to close tooltip instead of just
            // un-hovering
            clickClose: 'false',
            // delay (in ms) between opening and closing tooltip
            delay: '100',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach hover and focus listeners to link
                link.addEventListener('mouseover', onLinkHover);
                link.addEventListener('mouseleave', onLinkUnhover);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('touchend', onLinkTouch);
            }

            // attach mouse, key, and resize listeners to window
            window.addEventListener('mousedown', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('keyup', onKeyUp);
            window.addEventListener('resize', onResize);
        }

        // when link is hovered
        function onLinkHover() {
            // function to open tooltip
            const delayOpenTooltip = function() {
                openTooltip(this);
            }.bind(this);

            // run open function after delay
            this.openTooltipTimer = window.setTimeout(
                delayOpenTooltip,
                options.delay
            );
        }

        // when mouse leaves link
        function onLinkUnhover() {
            // cancel opening tooltip
            window.clearTimeout(this.openTooltipTimer);

            // don't close on unhover if option specifies
            if (options.clickClose === 'true')
                return;

            // function to close tooltip
            const delayCloseTooltip = function() {
                // if tooltip open and if mouse isn't over tooltip, close
                const tooltip = document.getElementById('tooltip');
                if (tooltip && !tooltip.matches(':hover'))
                    closeTooltip();
            };

            // run close function after delay
            this.closeTooltipTimer = window.setTimeout(
                delayCloseTooltip,
                options.delay
            );
        }

        // when link is focused (tabbed to)
        function onLinkFocus(event) {
            openTooltip(this);
        }

        // when link is touched on touch screen
        function onLinkTouch(event) {
            // attempt to force hover state on first tap always, and trigger
            // regular link click (and navigation) on second tap
            if (event.target === document.activeElement)
                event.target.click();
            else {
                document.activeElement.blur();
                event.target.focus();
            }
            if (event.cancelable)
                event.preventDefault();
            event.stopPropagation();
            return false;
        }

        // when mouse is clicked anywhere in window
        function onClick(event) {
            closeTooltip();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'tooltip_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'tooltip_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeTooltip();
                    break;
            }
        }

        // when window is resized or zoomed
        function onResize() {
            closeTooltip();
        }

        // get all links of types we wish to handle
        function getLinks() {
            const queries = [];
            // exclude buttons, anchor links, toc links, etc
            const exclude =
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            queries.push('a[href^="#ref-"]' + exclude); // citation links
            queries.push('a[href^="#fig:"]' + exclude); // figure links
            const query = queries.join(', ');
            return document.querySelectorAll(query);
        }

        // get links with same target, get index of link in set, get total
        // same links
        function getSameLinks(link) {
            const sameLinks = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    sameLinks.push(otherLink);
            }

            return {
                elements: sameLinks,
                index: sameLinks.indexOf(link),
                total: sameLinks.length
            };
        }

        // open tooltip
        function openTooltip(link) {
            // delete tooltip if it exists, start fresh
            closeTooltip();

            // make tooltip element
            const tooltip = makeTooltip(link);

            // if source couldn't be found and tooltip not made, exit
            if (!tooltip)
                return;

            // make navbar elements
            const navBar = makeNavBar(link);
            if (navBar)
                tooltip.firstElementChild.appendChild(navBar);

            // attach tooltip to page
            document.body.appendChild(tooltip);

            // position tooltip
            const position = function() {
                positionTooltip(link);
            };
            position();

            // if tooltip contains images, position again after they've loaded
            const imgs = tooltip.querySelectorAll('img');
            for (const img of imgs)
                img.addEventListener('load', position);
        }

        // close (delete) tooltip
        function closeTooltip() {
            const tooltip = document.getElementById('tooltip');
            if (tooltip)
                tooltip.remove();
        }

        // make tooltip
        function makeTooltip(link) {
            // get target element that link points to
            const source = getSource(link);

            // if source can't be found, exit
            if (!source)
                return;

            // create new tooltip
            const tooltip = document.createElement('div');
            tooltip.id = 'tooltip';
            const tooltipContent = document.createElement('div');
            tooltipContent.id = 'tooltip_content';
            tooltip.appendChild(tooltipContent);

            // make copy of source node and put in tooltip
            const sourceCopy = makeCopy(source);
            tooltipContent.appendChild(sourceCopy);

            // attach mouse event listeners
            tooltip.addEventListener('click', onTooltipClick);
            tooltip.addEventListener('mousedown', onTooltipClick);
            tooltip.addEventListener('touchstart', onTooltipClick);
            tooltip.addEventListener('mouseleave', onTooltipUnhover);

            // (for interaction with lightbox plugin)
            // transfer click on tooltip copied img to original img
            const sourceImg = source.querySelector('img');
            const sourceCopyImg = sourceCopy.querySelector('img');
            if (sourceImg && sourceCopyImg) {
                const clickImg = function() {
                    sourceImg.click();
                    closeTooltip();
                };
                sourceCopyImg.addEventListener('click', clickImg);
            }

            return tooltip;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // when tooltip is clicked
        function onTooltipClick(event) {
            // when user clicks on tooltip, stop click from transferring
            // outside of tooltip (eg, click off to close tooltip, or eg click
            // off to unhighlight same refs)
            event.stopPropagation();
        }

        // when tooltip is unhovered
        function onTooltipUnhover(event) {
            if (options.clickClose === 'true')
                return;

            // make sure new mouse/touch/focus no longer over tooltip or any
            // element within it
            const tooltip = document.getElementById('tooltip');
            if (!tooltip)
                return;
            if (this.contains(event.relatedTarget))
                return;

            closeTooltip();
        }

        // make nav bar to go betwen prev/next instances of same reference
        function makeNavBar(link) {
            // find other links to the same source
            const sameLinks = getSameLinks(link);

            // don't show nav bar when singular reference
            if (sameLinks.total <= 1)
                return;

            // find prev/next links with same target
            const prevLink = getPrevLink(link, sameLinks);
            const nextLink = getNextLink(link, sameLinks);

            // create nav bar
            const navBar = document.createElement('div');
            navBar.id = 'tooltip_nav_bar';
            const text = sameLinks.index + 1 + ' of ' + sameLinks.total;

            // create nav bar prev/next buttons
            const prevButton = document.createElement('button');
            const nextButton = document.createElement('button');
            prevButton.id = 'tooltip_prev_button';
            nextButton.id = 'tooltip_next_button';
            prevButton.title =
                'Jump to the previous occurence of this item in the document [←]';
            nextButton.title =
                'Jump to the next occurence of this item in the document [→]';
            prevButton.classList.add('icon_button');
            nextButton.classList.add('icon_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;
            navBar.appendChild(prevButton);
            navBar.appendChild(document.createTextNode(text));
            navBar.appendChild(nextButton);

            // attach click listeners to buttons
            prevButton.addEventListener('click', function() {
                onPrevNextClick(link, prevLink);
            });
            nextButton.addEventListener('click', function() {
                onPrevNextClick(link, nextLink);
            });

            return navBar;
        }

        // get previous link with same target
        function getPrevLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if < 1
            let index;
            if (sameLinks.index - 1 >= 0)
                index = sameLinks.index - 1;
            else
                index = sameLinks.total - 1;
            return sameLinks.elements[index];
        }

        // get next link with same target
        function getNextLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if > total
            let index;
            if (sameLinks.index + 1 <= sameLinks.total - 1)
                index = sameLinks.index + 1;
            else
                index = 0;
            return sameLinks.elements[index];
        }

        // get element that is target of link or url hash
        function getSource(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if ref or figure, modify target to get expected element
            if (id.indexOf('ref-') === 0)
                target = target.querySelector('p');
            else if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');

            return target;
        }

        // when prev/next arrow button is clicked
        function onPrevNextClick(link, prevNextLink) {
            if (link && prevNextLink)
                goToElement(prevNextLink, window.innerHeight * 0.5);
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // determine position to place tooltip based on link position in
        // viewport and tooltip size
        function positionTooltip(link, left, top) {
            const tooltipElement = document.getElementById('tooltip');
            if (!tooltipElement)
                return;

            // get convenient vars for position/dimensions of
            // link/tooltip/page/view
            link = getRectInPage(link);
            const tooltip = getRectInPage(tooltipElement);
            const view = getRectInPage();

            // horizontal positioning
            if (left)
                // use explicit value
                left = left;
            else if (link.left + tooltip.width < view.right)
                // fit tooltip to right of link
                left = link.left;
            else if (link.right - tooltip.width > view.left)
                // fit tooltip to left of link
                left = link.right - tooltip.width;
            // center tooltip in view
            else
                left = (view.right - view.left) / 2 - tooltip.width / 2;

            // vertical positioning
            if (top)
                // use explicit value
                top = top;
            else if (link.top - tooltip.height > view.top)
                // fit tooltip above link
                top = link.top - tooltip.height;
            else if (link.bottom + tooltip.height < view.bottom)
                // fit tooltip below link
                top = link.bottom;
            else {
                // center tooltip in view
                top = view.top + view.height / 2 - tooltip.height / 2;
                // nudge off of link to left/right if possible
                if (link.right + tooltip.width < view.right)
                    left = link.right;
                else if (link.left - tooltip.width > view.left)
                    left = link.left - tooltip.width;
            }

            tooltipElement.style.left = left + 'px';
            tooltipElement.style.top = top + 'px';
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get position of element relative to page
        function getRectInPage(element) {
            const rect = getRectInView(element);
            const body = getRectInView(document.body);

            const newRect = {};
            newRect.left = rect.left - body.left;
            newRect.top = rect.top - body.top;
            newRect.right = rect.right - body.left;
            newRect.bottom = rect.bottom - body.top;
            newRect.width = rect.width;
            newRect.height = rect.height;

            return newRect;
        }

        // (for interaction with accordion plugin)
        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // (for interaction with accordion plugin)
        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- jump to first plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds a button next to each reference entry,
        // figure, and table that jumps the page to the first occurrence of a
        // link to that item in the manuscript.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'jumpToFirst';

        // default plugin options
        const options = {
            // whether to add buttons next to reference entries
            references: 'true',
            // whether to add buttons next to figures
            figures: 'true',
            // whether to add buttons next to tables
            tables: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            if (options.references !== 'false')
                makeReferenceButtons();
            if (options.figures !== 'false')
                makeFigureButtons();
            if (options.tables !== 'false')
                makeTableButtons();
        }

        // when jump button clicked
        function onButtonClick() {
            const first = getFirstOccurrence(this.dataset.id);
            if (!first)
                return;

            // update url hash so navigating "back" in history will return
            // user to jump button
            window.location.hash = this.dataset.id;
            // scroll to link
            window.setTimeout(function() {
                goToElement(first, window.innerHeight * 0.5);
            }, 0);
        }

        // get first occurence of link to item in document
        function getFirstOccurrence(id) {
            let query = 'a';
            query += '[href="#' + id + '"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelector(query);
        }

        // add button next to each reference entry
        function makeReferenceButtons() {
            const references = document.querySelectorAll('div[id^="ref-"]');
            for (const reference of references) {
                // get reference id and element to add button to
                const id = reference.id;
                const container = reference.firstElementChild;
                const first = getFirstOccurrence(id);

                // if can't find link to reference, ignore
                if (!first)
                    continue;

                // make jump button
                let button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this reference in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.innerHTML = button.outerHTML + container.innerHTML;
                button = container.firstElementChild;
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeFigureButtons() {
            const figures = document.querySelectorAll('[id^="fig:"]');
            for (const figure of figures) {
                // get figure id and element to add button to
                const id = figure.id;
                const container = figure.querySelector('figcaption') || figure;
                const first = getFirstOccurrence(id);

                // if can't find link to figure, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this figure in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeTableButtons() {
            const tables = document.querySelectorAll('[id^="tbl:"]');
            for (const table of tables) {
                // get ref id and element to add button to
                const id = table.id;
                const container = table.querySelector('caption') || table;
                const first = getFirstOccurrence(id);

                // if can't find link to table, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this table in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
    <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
    <svg width="16" height="16" viewBox="0 0 320 512">
        <path
            fill="currentColor"
            d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
        ></path>
    </svg>
</template>
<!-- link highlight plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user hovers or
        // focuses a link, other links that have the same target will be
        // highlighted. It also makes it such that when clicking a link, the
        // target of the link (eg reference, figure, table) is briefly
        // highlighted.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'linkHighlight';

        // default plugin options
        const options = {
            // whether to also highlight links that go to external urls
            externalLinks: 'false',
            // whether user must click off to unhighlight instead of just
            // un-hovering
            clickUnhighlight: 'false',
            // whether to also highlight links that are unique
            highlightUnique: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach mouse and focus listeners to link
                link.addEventListener('mouseenter', onLinkFocus);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('mouseleave', onLinkUnhover);
            }

            // attach click and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('hashchange', onHashChange);

            // run hash change on window load in case user has navigated
            // directly to hash
            onHashChange();
        }

        // when link is focused (tabbed to) or hovered
        function onLinkFocus() {
            highlight(this);
        }

        // when link is unhovered
        function onLinkUnhover() {
            if (options.clickUnhighlight !== 'true')
                unhighlightAll();
        }

        // when the mouse is clicked anywhere in window
        function onClick(event) {
            unhighlightAll();
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                glowElement(target);
        }

        // get element that is target of link or url hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            return target;
        }

        // start glow sequence on an element
        function glowElement(element) {
            const startGlow = function() {
                onGlowEnd();
                element.dataset.glow = 'true';
                element.addEventListener('animationend', onGlowEnd);
            };
            const onGlowEnd = function() {
                element.removeAttribute('data-glow');
                element.removeEventListener('animationend', onGlowEnd);
            };
            startGlow();
        }

        // highlight link and all others with same target
        function highlight(link) {
            // force unhighlight all to start fresh
            unhighlightAll();

            // get links with same target
            if (!link)
                return;
            const sameLinks = getSameLinks(link);

            // if link unique and option is off, exit and don't highlight
            if (sameLinks.length <= 1 && options.highlightUnique !== 'true')
                return;

            // highlight all same links, and "select" (special highlight) this
            // one
            for (const sameLink of sameLinks) {
                if (sameLink === link)
                    sameLink.setAttribute('data-selected', 'true');
                else
                    sameLink.setAttribute('data-highlighted', 'true');
            }
        }

        // unhighlight all links
        function unhighlightAll() {
            const links = getLinks();
            for (const link of links) {
                link.setAttribute('data-selected', 'false');
                link.setAttribute('data-highlighted', 'false');
            }
        }

        // get links with same target
        function getSameLinks(link) {
            const results = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    results.push(otherLink);
            }
            return results;
        }

        // get all links of types we wish to handle
        function getLinks() {
            let query = 'a';
            if (options.externalLinks !== 'true')
                query += '[href^="#"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelectorAll(query);
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- table of contents plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin provides a "table of contents" (toc) panel on
        // the side of the document that allows the user to conveniently
        // navigate between sections of the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tableOfContents';

        // default plugin options
        const options = {
            // which types of elements to add links for, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3',
            // whether default behavior is to be closed ('false'), open
            // ('true'), or only open when screen wide enough to fit panel
            // ('auto'). note: still always starts closed when page loads.
            open: 'auto',
            // if list item is more than this many characters, text will be
            // truncated
            charLimit: '50',
            // whether or not to show bullets next to each toc item
            bullets: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // make toc panel and populate with entries (links to document
            // sections)
            const panel = makePanel();
            if (!panel)
                return;
            makeEntries(panel);
            document.body.insertBefore(panel, document.body.firstChild);

            closePanel();

            // attach click, scroll, and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('scroll', onScroll);
            window.addEventListener('hashchange', onScroll);
            window.addEventListener('keyup', onKeyUp);
            onScroll();

            // add class to push document body down out of way of toc button
            document.body.classList.add('toc_body_nudge');
        }

        // determine if screen wide enough to fit toc panel
        function isSmallScreen() {
            // in default theme:
            // 816px = 8.5in = width of "page" (<body>) element
            // 260px = min width of toc panel (*2 for both sides of <body>)
            return window.innerWidth < 816 + 260 * 2;
        }

        // open/close panel based on option and screen size
        function openOrClosePanel() {
            if (
                options.open === 'true' ||
                (options.open === 'auto' && !isSmallScreen())
            )
                openPanel();
            else
                closePanel();
        }

        // when mouse is clicked anywhere in window
        function onClick() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                openOrClosePanel();
        }

        // when window is scrolled or hash changed
        function onScroll() {
            highlightViewed();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            // close on esc
            if (event.key === 'Escape')
                closePanel();
        }

        // find entry of currently viewed document section in toc and highlight
        function highlightViewed() {
            const firstId = getFirstInView(options.typesQuery);

            // get toc entries (links), unhighlight all, then highlight viewed
            const list = document.getElementById('toc_list');
            if (!firstId || !list)
                return;
            const links = list.querySelectorAll('a');
            for (const link of links)
                link.dataset.viewing = 'false';
            const link = list.querySelector('a[href="#' + firstId + '"]');
            if (!link)
                return;
            link.dataset.viewing = 'true';
        }

        // get first or previous toc listed element in top half of view
        function getFirstInView(query) {
            // get all elements matching query and with id
            const elements = document.querySelectorAll(query);
            const elementsWithIds = [];
            for (const element of elements) {
                if (element.id)
                    elementsWithIds.push(element);
            }


            // get first or previous element in top half of view
            for (let i = 0; i < elementsWithIds.length; i++) {
                const element = elementsWithIds[i];
                const prevElement = elementsWithIds[Math.max(0, i - 1)];
                if (element.getBoundingClientRect().top >= 0) {
                    if (
                        element.getBoundingClientRect().top <
                        window.innerHeight / 2
                    )
                        return element.id;
                    else
                        return prevElement.id;
                }
            }
        }

        // make panel
        function makePanel() {
            // create panel
            const panel = document.createElement('div');
            panel.id = 'toc_panel';
            if (options.bullets === 'true')
                panel.dataset.bullets = 'true';

            // create header
            const header = document.createElement('div');
            header.id = 'toc_header';

            // create toc button
            const button = document.createElement('button');
            button.id = 'toc_button';
            button.innerHTML = document.querySelector('.icon_th_list').innerHTML;
            button.title = 'Table of Contents';
            button.classList.add('icon_button');

            // create header text
            const text = document.createElement('h3');
            text.innerHTML = 'View Table of Contents';

            // create container for toc list
            const list = document.createElement('div');
            list.id = 'toc_list';

            // attach click listeners
            panel.addEventListener('click', onPanelClick);
            header.addEventListener('click', onHeaderClick);
            button.addEventListener('click', onButtonClick);

            // attach elements
            header.appendChild(button);
            header.appendChild(text);
            panel.appendChild(header);
            panel.appendChild(list);

            return panel;
        }

        // create toc entries (links) to each element of the specified types
        function makeEntries(panel) {
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements) {
                // do not add link if element doesn't have assigned id
                if (!element.id)
                    continue;

                // create link/list item
                const link = document.createElement('a');
                link.classList.add('toc_link');
                switch (element.tagName.toLowerCase()) {
                    case 'h1':
                        link.dataset.level = '1';
                        break;
                    case 'h2':
                        link.dataset.level = '2';
                        break;
                    case 'h3':
                        link.dataset.level = '3';
                        break;
                    case 'h4':
                        link.dataset.level = '4';
                        break;
                }
                link.title = element.innerText;
                let text = element.innerText;
                if (text.length > options.charLimit)
                    text = text.slice(0, options.charLimit) + '...';
                link.innerHTML = text;
                link.href = '#' + element.id;
                link.addEventListener('click', onLinkClick);

                // attach link
                panel.querySelector('#toc_list').appendChild(link);
            }
        }

        // when panel is clicked
        function onPanelClick(event) {
            // stop click from propagating to window/document and closing panel
            event.stopPropagation();
        }

        // when header itself is clicked
        function onHeaderClick(event) {
            togglePanel();
        }

        // when button is clicked
        function onButtonClick(event) {
            togglePanel();
            // stop header underneath button from also being clicked
            event.stopPropagation();
        }

        // when link is clicked
        function onLinkClick() {
            openOrClosePanel();
        }

        // open panel if closed, close if opened
        function togglePanel() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                closePanel();
            else
                openPanel();
        }

        // open panel
        function openPanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'true';
        }

        // close panel
        function closePanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'false';
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- th list icon -->

<template class="icon_th_list">
    <!-- modified from: https://fontawesome.com/icons/th-list -->
    <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
        <path
            fill="currentColor"
            d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- lightbox plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user clicks on an
        // image, the image fills the screen and the user can pan/drag/zoom
        // the image and navigate between other images in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'lightbox';

        // default plugin options
        const options = {
            // list of possible zoom/scale factors
            zoomSteps:
                '0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1,' +
                '1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8',
            // whether to fit image to view ('fit'), display at 100% and shrink
            // if necessary ('shrink'), or always display at 100% ('100')
            defaultZoom: 'fit',
            // whether to zoom in/out toward center of view ('true') or mouse
            // ('false')
            centerZoom: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <img> element
            const imgs = document.querySelectorAll('figure > img');
            let count = 1;
            for (const img of imgs) {
                img.classList.add('lightbox_document_img');
                img.dataset.number = count;
                img.dataset.total = imgs.length;
                img.addEventListener('click', openLightbox);
                count++;
            }

            // attach mouse and key listeners to window
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('keyup', onKeyUp);
        }

        // when mouse is moved anywhere in window
        function onWindowMouseMove(event) {
            window.mouseX = event.clientX;
            window.mouseY = event.clientY;
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'lightbox_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'lightbox_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeLightbox();
                    break;
            }
        }

        // open lightbox
        function openLightbox() {
            const lightbox = makeLightbox(this);
            if (!lightbox)
                return;

            blurBody(lightbox);
            document.body.appendChild(lightbox);
        }

        // make lightbox
        function makeLightbox(img) {
            // delete lightbox if it exists, start fresh
            closeLightbox();

            // create screen overlay containing lightbox
            const overlay = document.createElement('div');
            overlay.id = 'lightbox_overlay';

            // create image info boxes
            const numberInfo = document.createElement('div');
            const zoomInfo = document.createElement('div');
            numberInfo.id = 'lightbox_number_info';
            zoomInfo.id = 'lightbox_zoom_info';

            // create container for image
            const imageContainer = document.createElement('div');
            imageContainer.id = 'lightbox_image_container';
            const lightboxImg = makeLightboxImg(
                img,
                imageContainer,
                numberInfo,
                zoomInfo
            );
            imageContainer.appendChild(lightboxImg);

            // create bottom container for caption and navigation buttons
            const bottomContainer = document.createElement('div');
            bottomContainer.id = 'lightbox_bottom_container';
            const caption = makeCaption(img);
            const prevButton = makePrevButton(img);
            const nextButton = makeNextButton(img);
            bottomContainer.appendChild(prevButton);
            bottomContainer.appendChild(caption);
            bottomContainer.appendChild(nextButton);

            // attach top middle and bottom to overlay
            overlay.appendChild(numberInfo);
            overlay.appendChild(zoomInfo);
            overlay.appendChild(imageContainer);
            overlay.appendChild(bottomContainer);

            return overlay;
        }

        // make <img> object that is intuitively draggable and zoomable
        function makeLightboxImg(
            sourceImg,
            container,
            numberInfoBox,
            zoomInfoBox
        ) {
            // create copy of source <img>
            const img = sourceImg.cloneNode(true);
            img.classList.remove('lightbox_document_img');
            img.removeAttribute('id');
            img.removeAttribute('width');
            img.removeAttribute('height');
            img.style.position = 'unset';
            img.style.margin = '0';
            img.style.padding = '0';
            img.style.width = '';
            img.style.height = '';
            img.style.minWidth = '';
            img.style.minHeight = '';
            img.style.maxWidth = '';
            img.style.maxHeight = '';
            img.id = 'lightbox_img';

            // build sorted list of unique zoomSteps, always including a 100%
            let zoomSteps = [];
            const optionsZooms = options.zoomSteps.split(/[^0-9.]/);
            for (const optionZoom of optionsZooms) {
                const newZoom = parseFloat(optionZoom);
                if (newZoom && !zoomSteps.includes(newZoom))
                    zoomSteps.push(newZoom);
            }
            if (!zoomSteps.includes(1))
                zoomSteps.push(1);
            zoomSteps = zoomSteps.sort(function sortNumber(a, b) {
                return a - b;
            });

            // <img> object property variables
            let zoom = 1;
            let translateX = 0;
            let translateY = 0;
            let clickMouseX = undefined;
            let clickMouseY = undefined;
            let clickTranslateX = undefined;
            let clickTranslateY = undefined;

            updateNumberInfo();

            // update image numbers displayed in info box
            function updateNumberInfo() {
                numberInfoBox.innerHTML =
                    sourceImg.dataset.number + ' of ' + sourceImg.dataset.total;
            }

            // update zoom displayed in info box
            function updateZoomInfo() {
                let zoomInfo = zoom * 100;
                if (!Number.isInteger(zoomInfo))
                    zoomInfo = zoomInfo.toFixed(2);
                zoomInfoBox.innerHTML = zoomInfo + '%';
            }

            // move to closest zoom step above current zoom
            const zoomIn = function() {
                for (const zoomStep of zoomSteps) {
                    if (zoomStep > zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                updateTransform();
            };

            // move to closest zoom step above current zoom
            const zoomOut = function() {
                zoomSteps.reverse();
                for (const zoomStep of zoomSteps) {
                    if (zoomStep < zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                zoomSteps.reverse();

                updateTransform();
            };

            // update display of <img> based on scale/translate properties
            const updateTransform = function() {
                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                // get new width/height after scale
                const rect = img.getBoundingClientRect();
                // limit translate
                translateX = Math.max(translateX, -rect.width / 2);
                translateX = Math.min(translateX, rect.width / 2);
                translateY = Math.max(translateY, -rect.height / 2);
                translateY = Math.min(translateY, rect.height / 2);

                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                updateZoomInfo();
            };

            // fit <img> to container
            const fit = function() {
                // no x/y offset, 100% zoom by default
                translateX = 0;
                translateY = 0;
                zoom = 1;

                // widths of <img> and container
                const imgWidth = img.naturalWidth;
                const imgHeight = img.naturalHeight;
                const containerWidth = parseFloat(
                    window.getComputedStyle(container).width
                );
                const containerHeight = parseFloat(
                    window.getComputedStyle(container).height
                );

                // how much zooming is needed to fit <img> to container
                const xRatio = imgWidth / containerWidth;
                const yRatio = imgHeight / containerHeight;
                const maxRatio = Math.max(xRatio, yRatio);
                const newZoom = 1 / maxRatio;

                // fit <img> to container according to option
                if (options.defaultZoom === 'shrink') {
                    if (maxRatio > 1)
                        zoom = newZoom;
                } else if (options.defaultZoom === 'fit')
                    zoom = newZoom;

                updateTransform();
            };

            // when mouse wheel is rolled anywhere in container
            const onContainerWheel = function(event) {
                if (!event)
                    return;

                // let ctrl + mouse wheel to zoom behave as normal
                if (event.ctrlKey)
                    return;

                // prevent normal scroll behavior
                event.preventDefault();
                event.stopPropagation();

                // point around which to scale img
                const viewRect = container.getBoundingClientRect();
                const viewX = (viewRect.left + viewRect.right) / 2;
                const viewY = (viewRect.top + viewRect.bottom) / 2;
                const originX = options.centerZoom === 'true' ? viewX : mouseX;
                const originY = options.centerZoom === 'true' ? viewY : mouseY;

                // get point on image under origin
                const oldRect = img.getBoundingClientRect();
                const oldPercentX = (originX - oldRect.left) / oldRect.width;
                const oldPercentY = (originY - oldRect.top) / oldRect.height;

                // increment/decrement zoom
                if (event.deltaY < 0)
                    zoomIn();
                if (event.deltaY > 0)
                    zoomOut();

                // get offset between previous image point and origin
                const newRect = img.getBoundingClientRect();
                const offsetX =
                    originX - (newRect.left + newRect.width * oldPercentX);
                const offsetY =
                    originY - (newRect.top + newRect.height * oldPercentY);

                // translate image to keep image point under origin
                translateX += offsetX;
                translateY += offsetY;

                // perform translate
                updateTransform();
            };

            // when container is clicked
            function onContainerClick(event) {
                // if container itself is target of click, and not other
                // element above it
                if (event.target === this)
                    closeLightbox();
            }

            // when mouse button is pressed on image
            const onImageMouseDown = function(event) {
                // store original mouse position relative to image
                clickMouseX = window.mouseX;
                clickMouseY = window.mouseY;
                clickTranslateX = translateX;
                clickTranslateY = translateY;
                event.stopPropagation();
                event.preventDefault();
            };

            // when mouse button is released anywhere in window
            const onWindowMouseUp = function(event) {
                // reset original mouse position
                clickMouseX = undefined;
                clickMouseY = undefined;
                clickTranslateX = undefined;
                clickTranslateY = undefined;

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mouseup', onWindowMouseUp);
            };

            // when mouse is moved anywhere in window
            const onWindowMouseMove = function(event) {
                if (
                    clickMouseX === undefined ||
                    clickMouseY === undefined ||
                    clickTranslateX === undefined ||
                    clickTranslateY === undefined
                )
                    return;

                // offset image based on original and current mouse position
                translateX = clickTranslateX + window.mouseX - clickMouseX;
                translateY = clickTranslateY + window.mouseY - clickMouseY;
                updateTransform();
                event.preventDefault();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mousemove', onWindowMouseMove);
            };

            // when window is resized
            const onWindowResize = function(event) {
                fit();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('resize', onWindowResize);
            };

            // attach the necessary event listeners
            img.addEventListener('dblclick', fit);
            img.addEventListener('mousedown', onImageMouseDown);
            container.addEventListener('wheel', onContainerWheel);
            container.addEventListener('mousedown', onContainerClick);
            container.addEventListener('touchstart', onContainerClick);
            window.addEventListener('mouseup', onWindowMouseUp);
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('resize', onWindowResize);

            // run fit() after lightbox atttached to document and <img> Loaded
            // so needed container and img dimensions available
            img.addEventListener('load', fit);

            return img;
        }

        // make caption
        function makeCaption(img) {
            const caption = document.createElement('div');
            caption.id = 'lightbox_caption';
            const captionSource = img.nextElementSibling;
            if (captionSource.tagName.toLowerCase() === 'figcaption') {
                const captionCopy = makeCopy(captionSource);
                caption.innerHTML = captionCopy.innerHTML;
            }

            caption.addEventListener('touchstart', function(event) {
                event.stopPropagation();
            });

            return caption;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // make button to jump to previous image in document
        function makePrevButton(img) {
            const prevButton = document.createElement('button');
            prevButton.id = 'lightbox_prev_button';
            prevButton.title = 'Jump to the previous image in the document [←]';
            prevButton.classList.add('icon_button', 'lightbox_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;

            // attach click listeners to button
            prevButton.addEventListener('click', function() {
                getPrevImg(img).click();
            });

            return prevButton;
        }

        // make button to jump to next image in document
        function makeNextButton(img) {
            const nextButton = document.createElement('button');
            nextButton.id = 'lightbox_next_button';
            nextButton.title = 'Jump to the next image in the document [→]';
            nextButton.classList.add('icon_button', 'lightbox_button');
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;

            // attach click listeners to button
            nextButton.addEventListener('click', function() {
                getNextImg(img).click();
            });

            return nextButton;
        }

        // get previous image in document
        function getPrevImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if < 1
            if (index - 1 >= 0)
                index--;
            else
                index = imgs.length - 1;
            return imgs[index];
        }

        // get next image in document
        function getNextImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if > total
            if (index + 1 <= imgs.length - 1)
                index++;
            else
                index = 0;
            return imgs[index];
        }

        // close lightbox
        function closeLightbox() {
            focusBody();

            const lightbox = document.getElementById('lightbox_overlay');
            if (lightbox)
                lightbox.remove();
        }

        // make all elements behind lightbox non-focusable
        function blurBody(overlay) {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.tabIndex = -1;
            document.body.classList.add('body_no_scroll');
        }

        // make all elements focusable again
        function focusBody() {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.removeAttribute('tabIndex');
            document.body.classList.remove('body_no_scroll');
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- attributes plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows arbitrary HTML attributes to be attached
        // to (almost) any element. Place an HTML comment inside or next to the
        // desired element in the format <!-- $attribute="value" -->

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'attributes';

        // default plugin options
        const options = {
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // get list of comments in document
            const comments = findComments();

            for(const comment of comments)
                if (comment.parentElement)
                    addAttributes(
                        comment.parentElement,
                        comment.nodeValue.trim()
                    );
        }

        // add html attributes to specified element based on string of 
        // html attributes and values
        function addAttributes(element, text) {
            // regex's for finding attribute/value pairs in the format of
            // attribute="value" or attribute='value
            const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
            const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

            // loop through attribute/value pairs
            let match;
            while(match = text.match(regex2) || text.match(regex1)) {
                // get attribute and value from regex capture groups
                let attribute = match[1];
                let value = match[2];

                // remove from string
                text = text.substring(match.index + match[0].length);

                if (!attribute || !value)
                    break;

                // set attribute of parent element
                try {
                    element.setAttribute(attribute, value);
                } catch(error) {
                    console.log(error);
                }

                // special case for colspan
                if (attribute === 'colspan')
                    removeTableCells(element, value);
            }
        }

        // get list of comment elements in document
        function findComments() {
            const comments = [];

            // iterate over comment nodes in document
            function acceptNode(node) {
                return NodeFilter.FILTER_ACCEPT;
            }
            const iterator = document.createNodeIterator(
                document.body,
                NodeFilter.SHOW_COMMENT,
                acceptNode
            );
            let node;
            while(node = iterator.nextNode())
                comments.push(node);

            return comments;
        }

        // remove certain number of cells after specified cell
        function removeTableCells(cell, number) {
            number = parseInt(number);
            if (!number)
                return;

            // remove elements
            for(; number > 1; number--) {
                if (cell.nextElementSibling)
                    cell.nextElementSibling.remove();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- math plugin configuration -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "CommonHTML": { linebreaks: { automatic: true } },
        "HTML-CSS": { linebreaks: { automatic: true } },
        "SVG": { linebreaks: { automatic: true } },
        "fast-preview": { disabled: true }
    });
</script>

<!-- math plugin -->

<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML'>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'MathJax' allows the proper rendering of
    // math/equations written in LaTeX.

    // https://www.mathjax.org/
</script>
<!-- annotations plugin -->

<script>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'Hypothesis' allows public annotation of the
    // manuscript.

    // https://web.hypothes.is/

    // plugin configuration
    window.hypothesisConfig = function() {
        return {
            branding: {
                accentColor: '#2196f3',
                appBackgroundColor: '#f8f8f8',
                ctaBackgroundColor: '#f8f8f8',
                ctaTextColor: '#000000',
                selectionFontFamily: 'Open Sans, Helvetica, sans serif',
                annotationFontFamily: 'Open Sans, Helvetica, sans serif'
            }
        };
    };

    // hypothesis client script
    const embed = 'https://hypothes.is/embed.js';
    // hypothesis annotation count query url
    const query = 'https://api.hypothes.is/api/search?limit=0&url='

    
    // start script
    function start() {
        const button = makeButton();
        document.body.insertBefore(button, document.body.firstChild);
        insertCount(button);
    }

    // make button
    function makeButton() {
        // create button
        const button = document.createElement('button');
        button.id = 'hypothesis_button';
        button.innerHTML = document.querySelector('.icon_hypothesis').innerHTML;
        button.title = 'Hypothesis annotations';
        button.classList.add('icon_button');

        function onClick(event) {
            onButtonClick(event, button);
        }

        // attach click listeners
        button.addEventListener('click', onClick);

        return button;
    }

    // insert annotations count
    async function insertCount(button) {
        // get annotation count from Hypothesis based on url
        let count = '-';
        try {
            const canonical = document.querySelector('link[rel="canonical"]');
            const location = window.location;
            const url = encodeURIComponent((canonical || location).href);
            const response = await fetch(query + url);
            const json = await response.json();
            count = json.total || '-';
        } catch(error) {
            console.log(error);
        }
        
        // put count into button
        const counter = document.createElement('span');
        counter.id = 'hypothesis_count';
        counter.innerHTML = count;
        button.title = 'View ' + count + ' Hypothesis annotations';
        button.append(counter);
    }

    // when button is clicked
    function onButtonClick(event, button) {
        const script = document.createElement('script');
        script.src = embed;
        document.body.append(script);
        button.remove();
    }

    window.addEventListener('load', start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
    <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
    <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
        <path
            fill="currentColor"
            d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- analytics plugin -->

<!-- copy and paste code from Google Analytics or similar service here -->
</body>
</html>
