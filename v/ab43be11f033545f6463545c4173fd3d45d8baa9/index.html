<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Kim-Anh Lê Cao" />
  <meta name="author" content="Aedin C Culhane" />
  <meta name="author" content="Elana Fertig" />
  <meta name="author" content="Vincent J. Carey" />
  <meta name="author" content="Ricard Argelaguet" />
  <meta name="author" content="Susan Holmes" />
  <meta name="author" content="Michael I. Love" />
  <meta name="author" content="Guo-Cheng Yuan" />
  <meta name="author" content="Al J Abadi" />
  <meta name="author" content="Casey S. Greene" />
  <meta name="author" content="Ayshwarya Subramanian" />
  <meta name="author" content="Amrit Singh" />
  <meta name="author" content="Alexis Coullomb" />
  <meta name="author" content="Arshi Arora" />
  <meta name="author" content="Joshua S. Sodicoff" />
  <meta name="author" content="Joshua D. Welch" />
  <meta name="author" content="Emily F. Davis-Marcisak" />
  <meta name="author" content="Jane Roe" />
  <meta name="dcterms.date" content="2020-09-03" />
  <meta name="keywords" content="single cell, data integration, hackathons" />
  <title>Community-wide hackathons establish foundations for emerging single cell data integration</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta name="citation_title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta property="og:title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta property="twitter:title" content="Community-wide hackathons establish foundations for emerging single cell data integration" />
  <meta name="dc.date" content="2020-09-03" />
  <meta name="citation_publication_date" content="2020-09-03" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="Kim-Anh Lê Cao" />
  <meta name="citation_author_institution" content="Melbourne Integrative Genomics, School of Mathematics and Statistics, University of Melbourne, Australia" />
  <meta name="citation_author_orcid" content="0000-0003-3923-1116" />
  <meta name="twitter:creator" content="@mixOmicsTeam" />
  <meta name="citation_author" content="Aedin C Culhane" />
  <meta name="citation_author_institution" content="Data Sciences, Dana-Farber Cancer Institute, Boston, MA, USA" />
  <meta name="citation_author_institution" content="Biostatsitics, Harvard TH Chan School of Public Health, Boston, MA, USA" />
  <meta name="citation_author_orcid" content="0000-0002-1395-9734" />
  <meta name="twitter:creator" content="@AedinCulhane" />
  <meta name="citation_author" content="Elana Fertig" />
  <meta name="citation_author_institution" content="Department of Oncology, Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University School of Medicine, Baltimore, MD, USA" />
  <meta name="citation_author_institution" content="Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, MD, USA" />
  <meta name="citation_author_institution" content="Department of Applied Mathematics and Statistics, Johns Hopkins University Whiting School of Engineering, Baltimore, MD, USA" />
  <meta name="citation_author_orcid" content="0000-0003-3204-342X" />
  <meta name="twitter:creator" content="@FertigLab" />
  <meta name="citation_author" content="Vincent J. Carey" />
  <meta name="citation_author_institution" content="Channing Division of Network Medicine, Brigham and Women&#39;s Hospital, Harvard Medical School" />
  <meta name="citation_author_orcid" content="0000-0003-4046-0063" />
  <meta name="citation_author" content="Ricard Argelaguet" />
  <meta name="citation_author_institution" content="European Bioinformatics Institute (EMBL-EBI)" />
  <meta name="citation_author_orcid" content="0000-0003-3199-3722" />
  <meta name="twitter:creator" content="@RArgelaguet" />
  <meta name="citation_author" content="Susan Holmes" />
  <meta name="citation_author_institution" content="Department of Statistics, Stanford University, USA" />
  <meta name="citation_author_orcid" content="0000-0002-2208-8168" />
  <meta name="twitter:creator" content="@SherlockpHolmes" />
  <meta name="citation_author" content="Michael I. Love" />
  <meta name="citation_author_institution" content="Department of Biostatistics, UNC-Chapel Hill" />
  <meta name="citation_author_institution" content="Department of Genetics, UNC-Chapel Hill" />
  <meta name="citation_author_orcid" content="0000-0001-8401-0545" />
  <meta name="twitter:creator" content="@mikelove" />
  <meta name="citation_author" content="Guo-Cheng Yuan" />
  <meta name="citation_author_institution" content="Department of Pediatric Oncology, Dana-Farber Cancer Institute" />
  <meta name="citation_author_institution" content="Department of Pediatrics, Harvard Medical School" />
  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />
  <meta name="twitter:creator" content="@gc_yuan" />
  <meta name="citation_author" content="Al J Abadi" />
  <meta name="citation_author_institution" content="Melbourne Integrative Genomics, School of Mathematics and Statistics, University of Melbourne, Australia" />
  <meta name="citation_author_orcid" content="0000-0002-4146-2848" />
  <meta name="twitter:creator" content="@aljabadi" />
  <meta name="citation_author" content="Casey S. Greene" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA" />
  <meta name="citation_author_orcid" content="0000-0001-8713-9213" />
  <meta name="twitter:creator" content="@greenescientist" />
  <meta name="citation_author" content="Ayshwarya Subramanian" />
  <meta name="citation_author_institution" content="Klarman Cell Observatory, Broad Institute" />
  <meta name="citation_author_institution" content="Kidney Disease Initiative, Broad Institute" />
  <meta name="citation_author_orcid" content="0000-0002-4134-7612" />
  <meta name="twitter:creator" content="@ayshwaryas" />
  <meta name="citation_author" content="Amrit Singh" />
  <meta name="citation_author_institution" content="Department of Pathology and Laboratory Medicine, University of British Columbia" />
  <meta name="citation_author_institution" content="PROOF Centre of Excellence" />
  <meta name="citation_author_orcid" content="0000-0002-7475-1646" />
  <meta name="twitter:creator" content="@asingh_22g" />
  <meta name="citation_author" content="Alexis Coullomb" />
  <meta name="citation_author_institution" content="Toulouse Cancer Research Center (CRCT), INSERM" />
  <meta name="citation_author_orcid" content="0000-0003-3164-6640" />
  <meta name="twitter:creator" content="@AlexisCoullomb" />
  <meta name="citation_author" content="Arshi Arora" />
  <meta name="citation_author_institution" content="Department of Epidemiology and Biostatistics, Memorial Sloan Ketterign Cancer Center" />
  <meta name="citation_author_orcid" content="0000-0002-4040-1787" />
  <meta name="twitter:creator" content="@arorarshi" />
  <meta name="citation_author" content="Joshua S. Sodicoff" />
  <meta name="citation_author_institution" content="Department of Computational Medicine and Bioinformatics, University of Michigan" />
  <meta name="citation_author_institution" content="Department of Biomedical Engineering, University of Michigan" />
  <meta name="citation_author_orcid" content="0000-0001-5182-960X" />
  <meta name="citation_author" content="Joshua D. Welch" />
  <meta name="citation_author_institution" content="Department of Computational Medicine and Bioinformatics, University of Michigan" />
  <meta name="citation_author_institution" content="Department of Computer Science and Engineering, University of Michigan" />
  <meta name="citation_author_orcid" content="0000-0002-5869-2391" />
  <meta name="twitter:creator" content="@LabWelch" />
  <meta name="citation_author" content="Emily F. Davis-Marcisak" />
  <meta name="citation_author_institution" content="McKusick-Nathans Institute of the Department of Genetic Medicine, Johns Hopkins School of Medicine, Baltimore, MD, USA" />
  <meta name="citation_author_orcid" content="0000-0001-8624-1013" />
  <meta name="twitter:creator" content="@efaithd" />
  <meta name="citation_author" content="Jane Roe" />
  <meta name="citation_author_institution" content="Department of Something, University of Whatever" />
  <meta name="citation_author_institution" content="Department of Whatever, University of Something" />
  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />
  <meta name="twitter:creator" content="@XXX" />
  <link rel="canonical" href="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta property="og:url" content="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta property="twitter:url" content="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta name="citation_fulltext_html_url" content="https://BIRSBiointegration.github.io/whitePaper/" />
  <meta name="citation_pdf_url" content="https://BIRSBiointegration.github.io/whitePaper/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://BIRSBiointegration.github.io/whitePaper/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://BIRSBiointegration.github.io/whitePaper/v/ab43be11f033545f6463545c4173fd3d45d8baa9/" />
  <meta name="manubot_html_url_versioned" content="https://BIRSBiointegration.github.io/whitePaper/v/ab43be11f033545f6463545c4173fd3d45d8baa9/" />
  <meta name="manubot_pdf_url_versioned" content="https://BIRSBiointegration.github.io/whitePaper/v/ab43be11f033545f6463545c4173fd3d45d8baa9/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Community-wide hackathons establish foundations for emerging single cell data integration</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://BIRSBiointegration.github.io/whitePaper/v/ab43be11f033545f6463545c4173fd3d45d8baa9/">permalink</a>)
was automatically generated
from <a href="https://github.com/BIRSBiointegration/whitePaper/tree/ab43be11f033545f6463545c4173fd3d45d8baa9">BIRSBiointegration/whitePaper@ab43be1</a>
on September 3, 2020.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Kim-Anh Lê Cao</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3923-1116">0000-0003-3923-1116</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/mixOmicsTeam">mixOmicsTeam</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/mixOmicsTeam">mixOmicsTeam</a><br>
<small>
Melbourne Integrative Genomics, School of Mathematics and Statistics, University of Melbourne, Australia
· Funded by Grant National Health and Medical Research Council Career Development fellowship (GNT1159458)
</small></p></li>
<li><p><strong>Aedin C Culhane</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-1395-9734">0000-0002-1395-9734</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/aedin">aedin</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/AedinCulhane">AedinCulhane</a><br>
<small>
Data Sciences, Dana-Farber Cancer Institute, Boston, MA, USA; Biostatsitics, Harvard TH Chan School of Public Health, Boston, MA, USA
· Funded by Chan Zuckerberg Initative, NIH, DoD (need to get grant IDs)
</small></p></li>
<li><p><strong>Elana Fertig</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3204-342X">0000-0003-3204-342X</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/ejfertig">ejfertig</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/FertigLab">FertigLab</a><br>
<small>
Department of Oncology, Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University School of Medicine, Baltimore, MD, USA; Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, MD, USA; Department of Applied Mathematics and Statistics, Johns Hopkins University Whiting School of Engineering, Baltimore, MD, USA
· Funded by National Institute of Health, National Cancer Institute; National Institute of Health, National Institute of Dental and Craniofacial Research; Lustgarten Foundation; Emerson Foundation; Allegheny Health Network
</small></p></li>
<li><p><strong>Vincent J. Carey</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-4046-0063">0000-0003-4046-0063</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/vjcitn">vjcitn</a><br>
<small>
Channing Division of Network Medicine, Brigham and Women’s Hospital, Harvard Medical School
· Funded by National Institutes of Health, National Human Genome Research Institute; National Institutes of Health, National Cancer Institute; Chan-Zuckerberg Initiative
</small></p></li>
<li><p><strong>Ricard Argelaguet</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3199-3722">0000-0003-3199-3722</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/rargelaguet">rargelaguet</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/RArgelaguet">RArgelaguet</a><br>
<small>
European Bioinformatics Institute (EMBL-EBI)
· Funded by EMBL PhD programme
</small></p></li>
<li><p><strong>Susan Holmes</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-2208-8168">0000-0002-2208-8168</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/spholmes">spholmes</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/SherlockpHolmes">SherlockpHolmes</a><br>
<small>
Department of Statistics, Stanford University, USA
· Funded by National Institute of Health, NIAID
</small></p></li>
<li><p><strong>Michael I. Love</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8401-0545">0000-0001-8401-0545</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/mikelove">mikelove</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/mikelove">mikelove</a><br>
<small>
Department of Biostatistics, UNC-Chapel Hill; Department of Genetics, UNC-Chapel Hill
· Funded by National Institutes of Health, National Human Genome Research Institute; National Institutes of Health, National Institute of Mental Health
</small></p></li>
<li><p><strong>Guo-Cheng Yuan</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/XXXX-XXXX-XXXX-XXXX">XXXX-XXXX-XXXX-XXXX</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/gcyuan">gcyuan</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/gc_yuan">gc_yuan</a><br>
<small>
Department of Pediatric Oncology, Dana-Farber Cancer Institute; Department of Pediatrics, Harvard Medical School
· Funded by National Institutes of Health, National Cancer Institute; National Institutes of Health, National Institute on Aging
</small></p></li>
<li><p><strong>Al J Abadi</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-4146-2848">0000-0002-4146-2848</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/ajabadi">ajabadi</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/aljabadi">aljabadi</a><br>
<small>
Melbourne Integrative Genomics, School of Mathematics and Statistics, University of Melbourne, Australia
· Funded by Chan Zuckerberg initiative (HCA2-A-1708-02277); Australian Research Council (DP200102903)
</small></p></li>
<li><p><strong>Casey S. Greene</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8713-9213">0000-0001-8713-9213</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/cgreene">cgreene</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/greenescientist">greenescientist</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA
· Funded by National Institutes of Health, National Cancer Institute (R01 CA237170); National Institutes of Health, National Human Genome Research Institute (R01 HG010067)
</small></p></li>
<li><p><strong>Ayshwarya Subramanian</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-4134-7612">0000-0002-4134-7612</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/ayshwaryas">ayshwaryas</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/ayshwaryas">ayshwaryas</a><br>
<small>
Klarman Cell Observatory, Broad Institute; Kidney Disease Initiative, Broad Institute
</small></p></li>
<li><p><strong>Amrit Singh</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-7475-1646">0000-0002-7475-1646</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/singha53">singha53</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/asingh_22g">asingh_22g</a><br>
<small>
Department of Pathology and Laboratory Medicine, University of British Columbia; PROOF Centre of Excellence
· Funded by Michael Smith Foudation for Health Research; Mitacs
</small></p></li>
<li><p><strong>Alexis Coullomb</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3164-6640">0000-0003-3164-6640</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/alexcoul">alexcoul</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/AlexisCoullomb">AlexisCoullomb</a><br>
<small>
Toulouse Cancer Research Center (CRCT), INSERM
· Funded by Pierre Fabre
</small></p></li>
<li><p><strong>Arshi Arora</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-4040-1787">0000-0002-4040-1787</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/arorarshi">arorarshi</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/arorarshi">arorarshi</a><br>
<small>
Department of Epidemiology and Biostatistics, Memorial Sloan Ketterign Cancer Center
</small></p></li>
<li><p><strong>Joshua S. Sodicoff</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-5182-960X">0000-0001-5182-960X</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jsodicoff">jsodicoff</a><br>
<small>
Department of Computational Medicine and Bioinformatics, University of Michigan; Department of Biomedical Engineering, University of Michigan
</small></p></li>
<li><p><strong>Joshua D. Welch</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-5869-2391">0000-0002-5869-2391</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jw156605">jw156605</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/LabWelch">LabWelch</a><br>
<small>
Department of Computational Medicine and Bioinformatics, University of Michigan; Department of Computer Science and Engineering, University of Michigan
· Funded by National Human Genome Research Institute, NIH; National Institute of Allergy and Infectious Diseases, NIH; National Institute of Mental Health, NIH
</small></p></li>
<li><p><strong>Emily F. Davis-Marcisak</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8624-1013">0000-0001-8624-1013</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/edavis71">edavis71</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/efaithd">efaithd</a><br>
<small>
McKusick-Nathans Institute of the Department of Genetic Medicine, Johns Hopkins School of Medicine, Baltimore, MD, USA
· Funded by National Institute of Health, National Cancer Institute
</small></p></li>
<li><p><strong>Jane Roe</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/XXXX-XXXX-XXXX-XXXX">XXXX-XXXX-XXXX-XXXX</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/janeroe%20(PLEASE%20COPY/PASTE%20DO%20NOT%20EDIT%20THIS%20ONE)">janeroe (PLEASE COPY/PASTE DO NOT EDIT THIS ONE)</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/XXX">XXX</a><br>
<small>
Department of Something, University of Whatever; Department of Whatever, University of Something
· Funded by XX
</small></p></li>
</ul>
<h2 id="list-of-figures-tables-and-online-resources">List of Figures, Tables and online resources</h2>
<h3 id="figures">Figures</h3>
<ul>
<li>Figure 1: spatial transcriptomics hackathon</li>
<li>Figure 2: spatial proteomics single cell hackathon</li>
<li>Figure 3: scNMT-seq hackathon</li>
<li>Figure 5: Common challenges across hackathons</li>
<li>Figure 6: Interpretation challenges</li>
<li>Figure 6: Benchmarking strategies</li>
<li>Figure 7: Software infrastructure for multi modal single cell</li>
</ul>
<h3 id="tables">Tables</h3>
<ul>
<li>Table 1: Summary of tasks and methods across all hackathons highlighting methods and common challenges</li>
<li>Table 2: Glossary of terms</li>
<li>Table 3: List of single cell analysis software</li>
<li>Table 4: Reproducible vignettes for analysis</li>
</ul>
<h3 id="online-resources-optional-as-referred-above">Online resources (optional as referred above)</h3>
<ul>
<li>Online resource 1: Three hackathon datasets (github)</li>
<li>Online resource 2: R packages with open source reproducible vignettes (12 vignettes)</li>
</ul>
<!---
# Draft outline
Full outline described in 01.outline.md as comment if you need to go back to the big picture.

![Main challenges discussed during our brainstorming sessions from the hackathons.](images/Outline.png){#fig:outline}


## Introduction [Figure 1 outline]

### Comprehensive characterization of biological systems with multi-omics
 - Single cell community has advanced technologies to enable concurrent processing of biological systems at multiple molecular resolutions
 - The lack of prior knowledge and gold standard benchmark naturally leads to a data-driven approach

### New single cell multi omics initiatives:
 - Human Cell Atlas (HCA): assess variation in normal tissues
 - Brain initiative and Allen Brain
 - Human Tumor Atlas Network (HTAN): Single-cell, longitudinal, and clinical outcomes atlases of cancer transitions for diverse tumor types.

### What bulk multi-omics (e.g. TCGA, ENCODE) have taught us:
 - Type of omics that can answer a specific biological question
 - The value of open resources for methodological developments
 - New hypotheses

### Using hackathons to illustrate analysis standards and challenges for capturing biological information from multi-omics technologies
 - Brief overview of our three hackathon studies highlighting state of the art challenges (e.g., spatial transcriptomics, cross-study analysis, epigenetic regulation)
 - Challenges include issues with noise and experimental design, Time lag between regulatory levels not addressed and many open questions
remain (e.g methylation / gene expression), Direction of regulation not captured
 - We present our findings from hackathon case studies that helped us obtain benchmarks and define a common language for multi-omics



## Hackathon case studies

### scRNA-seq + seqFISH as a case study for spatial transcriptomics [Figure 2 results]
#### Overview and biological question
#### Main challenges and how it was overcome by the participants
- Challenge 1: overlay of scRNA-seq onto seqFISH for resolution enhancement
- Challenge 2: determine signatures of cellular co-localization or spatial coordinates in non-spatial scRNA-seq


### Spatial proteomics and cross-study analysis [Figure 3 results]
#### Overview and biological question
#### Main challenges and how it was overcome by the participants
- Challenge 1: address the lack of overlap between proteins across studies
- Challenge 2: spatial protein expression analysis

### scNMT-seq as a case-study for epigenetic regulation [Figure 4 results], lead: Ricard Argelaguet
#### Overview and biological question
#### Main challenges and how it was overcome by the participants
- Challenge 1: defining genomic features
- Challenge 2: DNA methylation imputation
- Challenge 3: Linking epigenetic features / chromatin accessibility to gene expression


## Analytical approaches for hackathons and commonalities for multi-omics analysis illustrated by the series of hackathons [Figure 5 + Table 1]

Short introduction explaining that we focus here on the common challenges across hackathons

### Summary of hackathon study-specific methods
 - Table describes method, foundation in the context of previous bulk and single cell literature, and technology dependence
    - Attempts to tweak existing methods and challenges associated in hackathons
    - List methods that are either technology dependent (e.g. spatial) vs universal and how to choose them


### Dependence on pre-processing method and/or variable selection
- These steps are key and affect downstream analyses
  - Normalization / data transformation (seqFish), pre-processing, gene summaries (scNMT-seq) to variable selection (seqFish)
  - reproducibility difficult / no consensus. e.g. Alexis selected 19 genes whereas Zhu original paper based on 47 genes (difference in methods / processed data)
- Hackathon data pre-processed enable better comparisons across methods
- No consensus reached as those are emerging data with no ground truth nor established biological results

### Approaches for partial overlap of information (cells / features) and how to predict (cell type, dataset) using another data set
- Overlap in each study
  - seqFish: same features but not cells; scProt: same proteins, not cells but similar patients; scNMT-seq: same cells but not features
  - How it was solved (Table)
- Anchoring information across datasets or studies is needed (Figure)
- Incorporation of existing biological knowledge
  - ‘From discovery to detection’ (Meuleman + debrief), time is ripe to include more knowledge in our data driven approaches
- Challenge: Partial cell overlap (but no features matching) and No overlap were not addressed

### Managing differences in scale and size for datasets that do not match cells or features
- Hackathons datasets did not match cells or features.
  - scNMTQ-seq: MOFA limitation when # features vary (and size of datasets).
  - seqFish: greedy approach to select the best gene subset (Alexis, size); consider batch effect removal method (Amrit, scale)

- Consensus on projection based methods, even if pre-processing was applied (Table)
- Additional weighting is needed (e.g. Arora, Abadi).


## Interpretation challenges [Table 2: Glossary of terms]

### Interpretation requires a good understanding of the methods
- Glossary needed for communication
- Incorporation of contiguous information to facilitate interpretation of analytical results
- Biological knowledge and incorporation of information from databases are important, including bridges to data bases (KEGG, Gene Ontology, HCA) to validate through complementary data.

### Visualization tools for interpretation and communication
- Example: tSNE/ UMAP.

### Explaining results to biologists through generative models and simulations
- Example: factor analysis.

### Issues of over-discretization (premature-summarization) and over-simplification
- Example: notion of cell-type is insufficient (rare cell types vs. more “continuous” view on cell types).
- Problem with loss of information in the desire to simplify.
- Over interpretation / over reliance of graphical outputs


## Benchmarking in gold standard datasets [Figure 6, Table 3]

### Definition of benchmarking
- Goal 1: recovery of known cell types (processing of raw data, quantification, and clustering)
- Goal 2: benchmark methods for their ability to discover known relationships between data modalities, e.g. gene regulatory relationships observed between chromatin accessibility and gene expression (relationships are not fully known at the single cell level).

### Strategies for benchmarking
- Simulation useful for known truth, but difficult to simulate realistic covariance structure across features and across data modalities.
- Benchmarking datasets for single cell studies (Table): limited focus on sequencing depth and diversity of cell types derived from a single assay:
ground truth for the intended effect of exposure in a proposed study design.
validation for a data integration task for which a new computational method may be proposed.
- Multi-modal assays benchmarking:
- Design to address biological question (co-embedding, mapping or correlation, and inferring causal relationships).
- Design for either data integration or further downstream analyses (e.g. differential analysis)
- Study design should take into account:
  - Biological and technical variability via replicates, block design, and randomization.
  - Power analysis for the intended effect or data integration task.
  - Dependencies between modalities.
- Challenge: No universal benchmark data scheme suits every combination of modality, benchmark datasets may be established for commonly used combinations of modalities or technologies, towards specific data integration tasks.

### Hackathons
- Cross-validation within study can be performed via Hackathons, e.g. cross-validation analysis of the scNMT-seq dataset using MOFA+
- Assess if relationships discovered in one dataset present in other datasets, potentially looking across single cell and bulk.
- Challenge: how to match dimensions of latent space across folds. (examples: permutation or cross-validation to assess model performance)

## Software infrastructure [Figure 7, Table 4]

### Key questions

- Q1: How should multimodal single cell data be managed for interactive and batch analyses?
- Q2: What methods will help software developers create scalable solutions for multimodal single cell analysis?
- Q3: How can we ensure that visualization methods that are central to multimodal single cell analysis are usable by researchers with visual impairments?

### Data management strategies

- Abstract data type with “multiassay experiment”:
  - each mode =  different collection of features on possibly non-overlapping collections of samples;  
  - metadata on features conventionally defined
  - metadata on samples include all relevant information on experimental conditions.
- Data container for a multi assay analysis:  
  - assays from the same cells, or measurements from distinct cells.
  - Assay slots containing variables or features from multiple modalities (e.g. gene expression units from scRNA-seq and protein units from sc-proteomics), feature may be multidimensional (e.g. spatial coordinates, locations of eQTLs).
- Map between the different assays to enable analysis

### Scalability strategies

- Reducing barriers to interpretable visualizations
- Color is a powerful data visualization tool to represent complex and rich scientific data.
- Color vision deficiencies affect a substantial portion of the population. Include colorblind friendly visualizations [1] as a default setting in our visualizations


## Future directions

### What do we need for the future computation of multi omics single cell

### Upcoming cell atlases technologies

- What is coming?
- how they provide contexts for experimental perturbations
- How they provide context for novel datasets

### Unifying analysis goals for new computational methods

### Moving towards spatiotemporal omics and integration with mathematical models.

--->
<h2 class="page_break_before" id="abstract">Abstract</h2>
<!--
## Introduction
### Comprehensive characterization of biological systems with multi-omics
 - Single cell community has advanced technologies to enable concurrent processing of biological systems at multiple molecular resolutions
 - The lack of prior knowledge and gold standard benchmark naturally leads to a data-driven approach
<!--
### New single cell multi omics initiatives:
 - Human Cell Atlas (HCA): assess variation in normal tissues
 - Brain initiative and Allen Brain
 - Human Tumor Atlas Network (HTAN): Single-cell, longitudinal, and clinical outcomes atlases of cancer transitions for diverse tumor types.
<!--
### What bulk multi-omics (e.g. TCGA, ENCODE) have taught us:
 - Type of omics that can answer a specific biological question
 - The value of open resources for methodological developments
 - New hypotheses
<!--
### Using hackathons to illustrate analysis standards and challenges for capturing biological information from multi-omics technologies
 - Brief overview of our three hackathon studies highlighting state of the art challenges (e.g., spatial transcriptomics, cross-study analysis, epigenetic regulation)
 - Challenges include issues with noise and experimental design, Time lag between regulatory levels not addressed and many open questions
remain (e.g methylation / gene expression), Direction of regulation not captured
 - We present our findings from hackathon case studies that helped us obtain benchmarks and define a common language for multi-omics
<!--
- **Objectives of this paper**
    - Provide guidelines on tools / data / technologies / methods and needs to model the multi-scale regulatory processes in biological systems for a computational biologist audience
<!--
- **Outline and messages**
    - Cellular and molecular regulation is fundamentally multi-scale and captured by distinct data modalities
    - Traditional hypothesis-driven multi-omics/view studies only consider one facet of these technologies, but more can be learned through a holistic approach extending into atlases
    - We present our findings from hackathon case studies that helped us obtain a broader picture and language
-->
<h2 id="multi-omics-hackathon-studies-illustrate-standards-and-computational-challenges-in-cell-biology">Multi-omics hackathon studies illustrate standards and computational challenges in cell biology</h2>
<p>Single-cell multimodal omics has claimed the title of method of the year only six years after single-cell sequencing <span class="citation" data-cites="14mVWQABt">[<a href="#ref-14mVWQABt" role="doc-biblioref">1</a>]</span>, demonstrating the rapid pace of technological development in biology. Multi-omics technologies provide a unique opportunity to characterize cellular systems at both the spatial and molecular level. While each high-throughput measurement technology can resolve specific biological scales, complementary data integration techniques can reveal multi-scale interactions between modalities. While advances in multi-omics have coincided with the formation of tremendous new data resources and atlas-based initiatives to characterize biological systems, computational techniques and benchmarking strategies to integrate these datasets remains an active area of research.</p>
<p>To determine the optimal methods and new developments required to analyze multi-modal data effectively, we selected hackathon studies focused on data integration for the Mathematical Frameworks for Integrative Analysis of Emerging Biological Data Workshop. The first challenge included spatial molecular profiling. While this technology is rapidly emerging, it often provides lower molecular resolution than its non-spatial counterparts. Integration strategies that merge spatial and omics datasets have the promise to enhance the molecular resolution of spatially resolved profiling. Thus, we designed a hackathon using spatially resolved transcriptional data from seqFISH with corresponding non-spatial single-cell profiling data from the mouse visual cortex <span class="citation" data-cites="14LoEihpl">[<a href="#ref-14LoEihpl" role="doc-biblioref">2</a>]</span>. The second challenge dealt with the limited availability of tissue to obtain multiple measurements in samples from identical conditions, raising the question as to whether information can be transferred from datasets between distinct sample cohorts. Therefore, we designed the second hackathon to contain two triple-negative breast cancer cohorts profiled with single-cell proteomics profiling from mass cytometry (CyTOF) <span class="citation" data-cites="bJBIpCn7">[<a href="#ref-bJBIpCn7" role="doc-biblioref">4</a>]</span> and spatial in-situ proteomics from Multiplexed Ion Beam Imaging (MIBI) <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">5</a>]</span>. In contrast to the previous challenges, the third challenge presented data at different molecular scales but from the same cells to investigate how genetic and epigenetic alterations to DNA drive the transcriptional regulation underlying cellular state transitions. Our third hackathon was designed with scNMT-seq data to obtain concurrent DNA methylation, chromatin accessibility, and RNA expression from the same cells to delineate the regulatory networks that underlie mouse gastrulation <span class="citation" data-cites="wFwe0y4i">[<a href="#ref-wFwe0y4i" role="doc-biblioref">6</a>]</span>.</p>
<p>Altogether, the analysis approaches employed to address these hackathons provide a unique opportunity to identify technology-specific challenges and unifying themes across disparate biological contexts, which are essential to effectively leverage multi-omics datasets for new biological knowledge. This article presents the study-specific and common challenges faced during this workshop. We provide guidelines and articulate the needs of technologies, data, tools, and computational methods to model the multi-scale regulatory processes of biological systems.</p>
<!--
![Main challenges discussed during our brainstorming sessions from the hackathons.](images/Outline.png){#fig:outline width = 50%}
-->
<p><a name="spatial-section"></a></p>
<h2 id="scrna-seq-seqfish-as-a-case-study-for-spatial-transcriptomics">scRNA-seq + seqFISH as a case study for spatial transcriptomics</h2>
<h3 id="overview-and-biological-question">Overview and biological question</h3>
<p>The first hackathon aimed to leverage the complementary strengths of sequencing and imaging-based single-cell transcriptomic profiling by using computational techniques to integrate scRNA-seq and seqFISH data in the mouse visual cortex. While single cells are considered the smallest units and building blocks of each tissue, they still require proper spatial and structural three-dimensional organization in order to assemble into a functional tissue that can exert its physiological function. In the last decade, single-cell RNA-seq (scRNA-seq) has played a key role in capturing single-cell gene expression profiles, allowing us to map different cell types and states in whole organisms. Despite this remarkable achievement, this technology is based on cellular dissociation and hence does not maintain spatial relationships between single cells. Emerging technologies can now profile the transcriptome of single cells within their original environment, offering the possibility to examine how gene expression is influenced by cell-to-cell interactions and how it is spatially organized. One such approach is sequential single-molecule fluorescence in situ hybridization (seqFISH <span class="citation" data-cites="8Hx7hvP9">[<a href="#ref-8Hx7hvP9" role="doc-biblioref">7</a>]</span>), which can identify single molecules at (sub)cellular resolution with high sensitivity.</p>
<p>In contrast with scRNA-seq, seqFISH and many other spatial transcriptomic technologies often pose significant technological challenges, resulting in a small number of profiled genes per cell (10-100s). The newer generation of seqFISH technology (called seqFISH+ <span class="citation" data-cites="dx9o8qYU">[<a href="#ref-dx9o8qYU" role="doc-biblioref">9</a>]</span>) has dramatically enhanced its capacity to profile up to 10,000 genes, but this technology is more complex and costly than seqFISH.</p>
<p>New computational approaches are needed to integrate scRNA-seq and seqFISH data effectively. This first hackathon provided seqFISH and scRNA-seq data corresponding to the mouse visual cortex (<span class="citation" data-cites="13v18bjoF">[<a href="#ref-13v18bjoF" role="doc-biblioref">3</a>]</span>, <span class="citation" data-cites="14LoEihpl">[<a href="#ref-14LoEihpl" role="doc-biblioref">2</a>]</span>) and our participants were challenged to accurately identify cell types. The scRNA-seq data included transcriptional profiles at a high molecular resolution whereas the seqFISH data provided spatial characterization at a lower molecular resolution. Two key computational challenges were identified to enable high-resolution spatial molecular resolution. First, we explored several strategies to identify the most likely cell types in the seqFISH dataset based on information obtained from the scRNA-seq dataset. Second, we sought to transfer spatial information obtained from the seqFISH dataset to that of the scRNA-seq dataset. Cell type labels were derived from scRNA-seq analysis <span class="citation" data-cites="14LoEihpl">[<a href="#ref-14LoEihpl" role="doc-biblioref">2</a>]</span> and previous seqFISH/scRNA-seq integration <span class="citation" data-cites="13v18bjoF">[<a href="#ref-13v18bjoF" role="doc-biblioref">3</a>]</span> were also provided as reference.
<strong>Could we have a more detailed description of the data chracteristics here please (number of cells, genes per data set, any filtering applied in the hackathon, is applicable</strong></p>
<div id="fig:spatial" class="fignos">
<figure>
<img src="images/seqFish_mockup.png" alt="" /><figcaption><span>Figure 1:</span> </figcaption>
</figure>
</div>
<p>Caption Figure: <strong>Overview of seqFISH and scRNA-seq integration analysis</strong>.
<strong>A</strong> Assessment of cell type prediction using different data normalizations and classifiers. Normalization strategies included none (raw), counts per million (cpm), ComBat batch correction applied to cpm (cpm_combat), scRNA-seq and seqFISH scaled using the first eigenvalue (cpm_eigen), latent variables retained for both datasets after applying Partial Least Squares regression to cpm_eigen normalized data (cpm_pls). Classifiers approaches included a supervised multinomial classifier with elastic net penalty (enet), a semi-supervised multinomial classifier with elastic net penalty (ssenet) and Support Vector Machine (SVM, supervised). Each classifier was trained using the scRNA-seq data and the known (provided) cell type labels, then predicted the cell type labels in the seqFISH data; for the SVM we used the predictions from the original study (Challenge 1). The Gower distance between each method-normalization pair was computed and depicted on a multidimensional scaling plot. The first dimension (x-axis) separates methods that normalize the scRNA-seq and seqFISH data together (dashed) and separately (solid), showing that normalization had a stronger impact on cell type predictions than the classification method used.
<strong>B</strong> SVM classification models with different C parameters were trained with different number of genes in scRNA-seq data using Recursive Feature Elimination (RFE) to evaluate the minimal number of genes required for data integration. The results show that a smaller gene list than what the original study proposed was sufficeint to identify cell types in both data types (Challenge 1).
<strong>C</strong> LIGER was applied to combine spatial and single cell transcriptomic datasets. From the separate and integrative analyses, plots of identified and known clusters were generated and metrics of integration performance were compared, showing some loss of information as a result of the integration (Challenge 1).
<strong>D</strong> Construction of a spatial network from cells’ positions using Voronoi tessellation, where cell types were inferred from SVM trained on scRNA-seq data. Left: A neighbors aggregation method computes aggregation statistics on the seqFISH gene expression data for each node and its first order neighbors to address Challenge 2. Right: Identification of spatially coherent areas that can contain one or several cell types and can be used to detect genes whose expression is modulated by spatial factors rather than cell type.</p>
<h3 id="computational-challenges">Computational challenges</h3>
<h4 id="challenge-1-overlay-of-scrna-seq-onto-seqfish-for-resolution-enhancement">Challenge 1: overlay of scRNA-seq onto seqFISH for resolution enhancement</h4>
<!--
**[suggestion 1]**  
Sequencing and imaging based single-cell transcriptomic profiling have complementary strengths.
Whereas single-cell RNAseq generates transcriptome-wide information, it does not have spatial information.
On the other hand, seqFISH (Lubeck 2014; Shah 2016) provides single-cell resolution spatial information, but typically profiles the expression level of only 100-300 genes.
Although the newer generation of seqFISH technology (called seqFISH+) has greatly enhanced its capacity which can now be used to profile 10,000 genes (Eng 2019), the technology is significantly more complex and costly.
As such, it is desirable to develop computational approaches to effectively integrate scRNA-seq and seqFISH data analyses.
In this hackathon, the participants were provided with seqFISH (Zhu 2018) and scRNA-seq (Tasic 2016) data corresponding to the mouse visual cortex and challenged to accurately identify cell-types by integrating both datasets.
Cell type labels, derived from scRNA-seq analysis (Tasic 2016) and previous seqFISH/scRNA-seq integration (Zhu 2018) were also provided as reference.
-->
<!-- A variety of computational approaches were applied to achieve this goal, including: supervised classification with support vector machines (Coullomb, Xu), supervised and semi-supervised (self-training) elastic net classifiers (Singh), and unsupervised matrix factorization methods (Sodicoff) (Figure {@fig:spatial}).
While the methodologies are different, a number of themes recur, such as the importance of gene selection and batch effect correction.
As expected, the ability to identify refined cell-type structure relies on the selection of cell-type specific marker genes in seqFISH data, suggesting a potential benefit of using single-cell RNAseq data to guide seqFISH experimental design.
Batch effect is another important factor affecting the accuracy of data integration.
While a number of batch effect correction methods have been developed (COMBAT, Seurat, Scanorama, etc), it remains challenging to distinguish technical from biological variations if the biological samples do not match exactly.
-->
<p>The mouse visual cortex consists of multiple complex cell types. However, the seqFISH dataset was limited to 125 profiled genes, which were not prioritized based on their ability to discriminate between cell types. Assigning the correct cell identity presents an important challenge. In contrast, the scRNA-seq dataset is transcriptome-wide and includes the 125 genes profiled by seqFISH.
This challenge proposed to use all genes to identify the cell type labels for each cell in the scRNA-seq data with high certainty. Next, we leveraged the cell type information to build a classifier based on a subset of the 125 genes shared between both datasets. The classifier was then applied to the seqFISH dataset to assign cell types.</p>
<p>During the hackathon, participants aimed to test various machine learning and data integration models. Preliminary analyses highlighted that normalization strategies had a significant impact on the final results (Figure <a href="#fig:spatial">1</a>A). In addition, although unique molecular identifier (UMI) based scRNA-seq and seqFISH can both be considered as count data, we observed dataset specific biases that could be attributed to either platform (imaging vs. sequencing batch effects) or sample specific sources of variation. We opted to apply a quantile normalization approach that forces a similar expression distribution for each shared gene.</p>
<p>Two classification approaches were considered: supervised and semi-supervised generalized linear model regularized with elastic net penalty (enet and ssenet) and supervised support vector machines (SVM). The ssenet approach builds a model iteratively: it combines both datasets and initially only retains the highest confidence labels, then gradually adds more cell type labels until all cells are classified (Figure <a href="#fig:spatial">1</a>A). This type of self-training approach might be promising to generalize information to other datasets. To improve the SVM model, several combinations of kernels and optimal hyperparameters were assessed using a combination of randomized and zoomed search. In addition, different flavors of gene selection using recursive feature elimination were considered to identify the optimal or minimal number of genes needed to correctly classify the majority of the cells (Figure <a href="#fig:spatial">1</a>A). Finally, different classification accuracy metrics were considered to alleviate the major class imbalance in the dataset. More than 90% of cells were excitatory or inhibitory neurons, using balanced classification error rates. We applied LIGER, an approach based on integrative non-negative matrix factorization (NMF) to integrate both datasets in a subspace based on shared factors. This enabled the transfer of cell type labels using a nearest neighbor approach (Figure <a href="#fig:spatial">1</a>D).</p>
<!-- Mention limitation in the biological relevance of the genes seelcted in RFE? , but the lack of goad standard hinders our ability to evaluate the relevance of such genes -->
<p><strong>could we have some elements of conclusion here?</strong></p>
<h4 id="challenge-2-identifying-spatial-expression-patterns-at-the-tissue-level-through-the-integration-of-gene-expression-and-spatial-cellular-coordinates">Challenge 2: Identifying spatial expression patterns at the tissue level through the integration of gene expression and spatial cellular coordinates</h4>
<p>While most tools originally developed for scRNA-seq data can be adapted for spatial transcriptomic datasets (see <a href="#common-challenges-section">common challenges</a> section), methods to extract sources of variation from spatial factors are still lacking. Novel methods that can integrate the information obtained from gene expression with that of the spatial coordinates from each cell or transcript (for sub-cellular resolution) within a tissue of interest are needed.</p>
<p>To identify spatial expression patterns in the seqFISH dataset, the participants first formed a spatial network based on Voronoi tessellation (<span class="citation" data-cites="1HWhMi97j">[<a href="#ref-1HWhMi97j" role="doc-biblioref">10</a>]</span>). The gene expression of each cell was spatially smoothed by calculating the average gene expression of all neighboring cells. UMAP was applied to the smoothed and aggregated data matrix to identify cell clusters with a density-based clustering approach (Figure <a href="#fig:spatial">1</a>D). Interestingly, these results showed that the obtained clusters themselves are spatially separated and do not necessarily overlap with specific cell types, suggesting that the spatial dimension cannot be captured from the expression data only.</p>
<p>An unanswered question is whether the identified combinatorial spatial patterns can be extracted directly from scRNA-seq data, as previous studies have shown cellular mapping between gene expression profiles and known spatial locations (<span class="citation" data-cites="124247ZE6">[<a href="#ref-124247ZE6" role="doc-biblioref">11</a>]</span>, <span class="citation" data-cites="doi.org/10.1016/j.cell.2019.05.006">[<span class="citeproc-not-found" data-reference-id="doi.org/10.1016/j.cell.2019.05.006"><strong>???</strong></span>]</span>). However, this still constitutes both a technological and analytical challenge that will require careful benchmarking in the near future (see <a href="#benchmarking-section">benchmarking</a> section).</p>
<!-- integrating different datasets and extrapolating observed trends is challenging and will require more work and careful benchmarking in the future. -->
<!--
**[suggestion 1]**  
How could one identify spatial patterns in the seqFISH data? This broad question can be divided into a number of specific tasks, such as detecting genes whose expression is spatially coherent, cell types whose spatial distribution is confined to distinct regions, recurrent multi-cell-type interaction clusters, etc, and the spatial scale may vary from subcellular all the way to tissue-wide organizations.
While there have been abundant studies in the geo-spatial analysis domain, computational tools targeting specific spatial transcriptomic questions are still lacking.
In this hackathon, one group tackled this challenge by aggregating gene expression data from neighboring cells followed by spatial clustering (Coullomb).
Much more work in the future is need to further explore such information.
-->
<!--
**[suggestion 2]**  
Most analyses that were originally developed for scRNA-seq data can be immediately applied to spatial transcriptomic datasets, however methods to extract sources of variation that originate from spatial factors are still sparse.
To incorporate spatial information the cells from the seqFISH dataset were first connected through a spatial network based on Voronoi tessellation and then the expression of each individual cell was spatially smoothed by calculating the average gene expression levels over all the neighboring cells.
This smoothened and aggregated data matrix was subsequently used to create a 2 dimensional UMAP from which clusters were identified through a density based clustering approach.
The obtained cluster labels can then be mapped back to the original spatial locations  for further visual inspection and analysis.
-->
<!--
**[suggestion 2 detailed]**  
Most analyses that were originally developed for scRNA-seq data can be adapted for spatial transcriptomic datasets, however methods to extract sources of variation that originate from spatial factors are still sparse. The latter requires the development of novel methods which can integrate the information obtained from gene expression with that of the spatial coordinates from each individual cell or transcript (for sub-cellular resolution) within a tissue of interest.
For this hackaton we aimed to incorporate the spatial information by connecting the cells from the seqFISH dataset through a spatial network based on Voronoi tessellation. Then, for each node, its RNA count data was aggregated with its first order neighbors' count data. The mean and standard deviation were computed for each gene in the gathered data in order to capture the global tendency as well as the variability in the area arround each node.
Thus, each node has `nb_genes x nb_statistics (here 2)` variables.
These "aggregation statistics" can be visualized on a 2D UMAP projection.
These data were clustered in UMAP reduced spaces of dimensionality between 2 and 9, higher dimensions allowing to define more fine-grained clusters.
The clustering was performed with HDBSCAN, a noise-aware density-based algorithm that can define arbitrary-shaped clusters.
These clusters can then be visualized on the 2D UMAP projection and on the 2D spatial map of seqFISH data.
The clusters are spatially coherent, some of them contain several cell types, and a given cell type is not necessarily limited to one specific cluster.
During the exploratory phase consisting in varying the number of dimensions and the minium cluster size, a specific spot area was found clustered for several parameters combinations, suggesting it wasn't an artifact of the choice of parameters.
"Differential expression" analysis was performed between this spot and the other areas, although we don't look at differences in gene data but in aggregation metrics.
This area seems to correspond to a "regeneration hub", but this analysis has to be considered carefully and further analyzes is required to confirm this hypothesis.
This "neighbors  aggregation" method has been extended to aggregate RNA counts (or other node attributes) to higher orders of neighbors in order to define aggregation metrics on wider areas, which could be useful for analyzes of bigger tissues.
One interesting extension would be to substract phenotypes contributions to RNA counts for each cell before performing the neighbors aggregation analysis in order to highlight genes that are modulated by spatial factors.
But if we want to retrieve the mean expression of a cluster for cells belonging to it, we should first check cluster's convexity and be sure that no other cluster lies within it. 
-->
<h2 id="spatial-proteomics-as-a-case-for-cross-study-and-cross-platform-analysis">Spatial proteomics as a case for cross-study and cross-platform analysis</h2>
<h3 id="overview-and-biological-question-1">Overview and biological question</h3>
<p>Whereas the first hackathon with seqFISH and scRNA-seq data included samples from the same biological conditions, our second hackathon challenged participants to analyze two datasets obtained from different single cell targeted proteomics (antibody-based) technologies, applied to breast cancer tissue of different patient cohorts, from different laboratories. Both studies examined the tumor-immune microenvironment in primary breast cancer: Wagner, et al. used Mass Cytometry (CyTOF) to assay 73 proteins across two panels (tumor and immune) in 194 tissue samples from 143 subjects, of which 6 patients had triple-negative negative breast cancer <span class="citation" data-cites="bJBIpCn7">[<a href="#ref-bJBIpCn7" role="doc-biblioref">4</a>]</span>, while Keren, et al. applied Multiplexed Ion Beam Imaging (MIBI) to quantify spatial in-situ expression of 36 proteins in 41 triple-negative breast cancer patients <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">5</a>]</span> (Figure ??AB).</p>
<p>This hackathon focused on integrative data analysis across studies and platforms, given limited overlap in features (Section @ref{sec:common}). Three main challenges emerged. The first challenge was whether analytical methods could integrate partially-overlapping proteomic data collected on different patients with similar phenotypes, and whether measurements from one technology (MIBI spatial location and expression of proteins) could be transferred and used to predict information in the second technology (e.g., spatial expression patterns of proteins measured on CyTOF). The second challenge pertained to the added value of spatial technologies and whether integrated analyses of spatial single cell data could uncover additional information about immune cell populations in breast cancer beyond cell composition. The third challenge was whether data from patients with heterogeneous phenotypes could still be integrated, given few common features and no overlap in biological samples.</p>
<p><img src="images/scProt_mockup.png" id="fig:proteomics" />
Caption figure:
<strong>A</strong> Overview of spatial proteomics cross-study and cross-platform integration analysis.
<strong>B</strong> The datasets selected for this hackathon had limited overlap in features (MIBI-TOF, CyTOF immune-centric panel, and CyTOF tumor-centric panel; illustrating <strong>Challenge 1</strong>)
<strong>C</strong> Spatial analysis with Moran’s index computed on Gabriel graph shown in boxplot according to tumor/immune status showing a significant difference between groups (Red asterisks indicate significance of an ANOVA of each group with all others with p-value from an overall ANOVA across the three groups reported; exploring <strong>Challenge 2</strong>).
<!-- NOTE: figure will need to be updated, still in discussion with Lauren + Kris, see comment below for B (KA) --></p>
<h3 id="computational-challenges-1">Computational challenges</h3>
<h4 id="challenge-1-limited-overlap-between-protein-features-across-studies">Challenge 1: Limited overlap between protein features across studies</h4>
<p>There were only 20 proteins that were assayed in both the CyTOF <span class="citation" data-cites="bJBIpCn7">[<a href="#ref-bJBIpCn7" role="doc-biblioref">4</a>]</span> and MIBI-TOF <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">5</a>]</span> studies (Figure ??B), which precluded integration of features at the level of gene set or pathways and required the use of surrogate measures for cross-study association. The majority of proteins were cell-type markers or biomarkers targets of breast cancer therapeutic intervention, providing the opportunity to perform cross-study integration of cell type proportions in tumor tissue samples.
<!-- there are more than 20 proteins indicated in the Figure, what is going on here? (KA)--></p>
<p>Several semi-supervised and supervised algorithms were applied to transfer cell labels and cell compositions from one dataset to the second (see <a href="#vignette-table">Vignettes</a>). Random forest was considered to capture the hierarchical structure of cell lineage and perform feature transfer learning of cell type labels, using an adaptation of the prediction strength approach <span class="citation" data-cites="gbdea2Ea">[<a href="#ref-gbdea2Ea" role="doc-biblioref">12</a>]</span> to assess model robustness: first, a model was trained on the labeled dataset, then used to predict labels in the unlabeled dataset; next, a second model was trained based on the second dataset with the newly predicted labels; finally, the ability of the second model to recover the correct original labels when making predictions on the labeled dataset was assessed.
Mapping cells from CyTOF to imaging with spatial information was handled by solving an entropic regularization optimal transport problem <span class="citation" data-cites="yWwOzARC">[<a href="#ref-yWwOzARC" role="doc-biblioref">13</a>]</span> <span class="citation" data-cites="15aSce9Vm">[<a href="#ref-15aSce9Vm" role="doc-biblioref">14</a>]</span>, using the cosine distance of the common proteins between the two datasets as transport cost. The constructed optimal transport plan can be considered as likelihood of cells from one modality mapped to cells from the other modality, which allows the prediction of protein expression measured only in CyTOF on imaging data. After cluster analysis of the resulting imputed expression matrix, sub tumour cell type could be identified that was not revealed in the original matrix.</p>
<p>Another issue encountered with this challenge was that the different scales of protein expression across technologies meant that cell compositions could not be integrated using correlation of the expression of protein markers, as some cell markers were expected on a range of cell types (e.g. CD45), while others were more specialized and appeared in only a subset of those cells (e.g. CD4). Other challenges associated with cell composition analysis of proteomics data included uncertainty about antibody specificity and consistency between studies; specific sensitivity and specificity of protein markers for cell types and tissues; and disease heterogeneity. Cell type assignment was also a significant challenge, as it relied on manually curated protein annotation, and was therefore dependent on domain-specific knowledge (e.g. CD4 is expressed by T-cells). To date, methods for cell type assignment, classification or extraction of differentially expressed proteins cannot easily be applied to targeted proteomics. There is thus an urgent need for a unifying map between cells present in different datasets, and for annotation resources to provide quality metric or priors of protein cell type markers. The construction of protein expression atlases would support cell type classification, even if antibodies used and their performances might vary between labs.</p>
<h4 id="challenge-2-spatial-analysis-of-protein-expression">Challenge 2: spatial analysis of protein expression</h4>
<p>CyTOF mass spectrometry data provided protein expression and counts/composition of cells in breast tumor-immune environment, while the MIBI-TOF data provided spatial information that quantified cell attributes (shape, size, spatial coordinates) in addition to expression levels. These two data sets thus provide the opportunity to examine protein expression, cell microenvironment, and predict cell-cell interactions and the cellular community ecosystem.</p>
<p>Spatial information can be encoded as a set of XY coordinates (cell centroid), a line (e.g. tumor-immune boundary), or a polygon, which is a closed plane defined by a number of lines and can define complex shapes such as a cell or a community of cells. Spatial protein expression can be summarized using spatial descriptive statistics, such as the autocorrelation of the expression of a protein within a neighborhood of polygons, using techniques developed in geographical information science or ecology to assess whether a spatially measured variable has a random, dispersed or clustered pattern <span class="citation" data-cites="yCBL1fje">[<a href="#ref-yCBL1fje" role="doc-biblioref">15</a>]</span>.</p>
<p>We investigated whether expression data could be used to predict spatial properties of tissue samples using a variety of approaches (see <a href="#vignette-table">Vignettes</a>). A K-nearest neighbor graph was used to build spatial response variables and random forest model trained from expression data to predict spatial features. A topic model was trained on protein expression and cell compositions in the CyTOF data to predict cell co-locations in a fraction of MIBI-TOF considered as test data (10%), or vice versa. Among the five topics identified, the first topic was dominated in most of the immune cells from CyTOF data and the other four dominated in all other cells. Prognostic performance of different higher level spatial metrics was also examined using Moran’s Index with a sphere distance, cell type localisation using nearest neighbour correlation, or cell type interaction composition with Ripley’s L-function. Cox models with fused lasso penalty and random forest survival models were then fitted based on clinical features such as tumor stage, tumor grade, age and tumor size, as well as cell type composition. The spatial metrics were found to be predictive, especially in triple negative breast cancer where clinical features such as grade are often poor prognostics. Further investigation of Moran’s Index using a graph-based neighborhood measure (Gabriel graph, based on Delaunay triangulation; as opposed to sphere distance) found the values of this metric differed significantly between the three prognostic tumor scores described by <span class="citation" data-cites="18RF7h7kj">[<a href="#ref-18RF7h7kj" role="doc-biblioref">5</a>]</span>(Figure ??C). This challenge demonstrated the prognostic potential of spatial single cell proteomics data and underscores the need to develop new spatial measures specifically for these data.</p>
<h4 id="challenge-3-fourth-corner-integration-of-data-at-the-level-of-phenotype">Challenge 3: Fourth corner Integration of data at the level of phenotype</h4>
<p>Cross-study integration also raises the challenge of non-overlapping biological samples but with similar phenotypes. Here the aim was to identify biomarkers from the different data types to predict phenotype, and, more importantly, to explore concordance among markers selected across multiple studies and datasets. Depending upon how well these markers can be transferred across datasets, as well as the amount of distinctive information encoded by different markers, integrating datasets with only some overlap in markers could potentially provide more biological insight than from individual ‘omics studies. To consider this third challenge, phenotypic data (such as the cell attributes) were the critical factors that should be used to link the two datasets (Figure <a href="#fig:common">3</a>D).</p>
<p>Integrating patient phenotype measures such as grade, stage and overall survival is one first step that we were able to achieve. However, integrating proteins from data sets that used different approaches to cell type annotation and had 13 proteins in common was extremely challenging. Borrowing from ecology and the French school of ordination, this problem can be described as a case of the fourth corner problem (or RLQ, Figure <a href="#fig:common">3</a>D). Briefly, given two ’omics data where both features and samples are non overlapping, and phenotypical data are available for each omics data, multiplying the two phenotypical factors should derive a bridging matrix that links the features of two omics data. This requires the two phenotypical matrices to be multiplicable, i.e. describing the same phenotypical factors. The fourth corner RLQ can be solved using matrix decomposition [<span class="citation" data-cites="KsY7PFJ8"><a href="#ref-KsY7PFJ8" role="doc-biblioref">16</a></span>; doi:10.1111/ecog.02302]. However, this approach was not attempted in this hackathon.</p>
<!-- line 47: mentions 13 proteins and those numbers dont match with Figure B (KA)-->
<!-- would be good to justify why this approach was not attempted (KA) -->
<p><a name="scnmt-section"></a></p>
<h2 id="scnmt-seq-as-a-case-study-for-epigenetic-regulation">scNMT-seq as a case-study for epigenetic regulation</h2>
<h3 id="overview-and-biological-question-2">Overview and biological question</h3>
<p>In contrast to the first two hackathons, which leveraged datasets from complementary technologies to enable high molecular and spatial resolution of biological systems, the third hackathon used datasets spanning disparate molecular scales (e.g. DNA and RNA measurements) to resolve the regulatory networks that mediate cell fate decisions. While the maturation of scRNA-seq technologies has enabled the identification of transcriptional profiles associated with lineage diversification and cell fate commitment <span class="citation" data-cites="8vGho6cJ">[<a href="#ref-8vGho6cJ" role="doc-biblioref">17</a>]</span>, the accompanying epigenetic changes and the role of epigenetic layers in driving cell fate decisions remains poorly understood <span class="citation" data-cites="3QdXjbeH">[<a href="#ref-3QdXjbeH" role="doc-biblioref">18</a>]</span>. <strong>these are both very wordy, should be simplified</strong></p>
<p>scNMT-seq is one of the first experimental protocols that enable simultaneous quantification of RNA expression and epigenetic information from individual cells <span class="citation" data-cites="1FWgnoNlO">[<a href="#ref-1FWgnoNlO" role="doc-biblioref">19</a>]</span>. Briefly, cells are incubated with a GpC methyltransferase enzyme that labels accessible GpC sites via DNA methylation. Thus, GpC methylation marks can be interpreted as direct read-outs for chromatin accessibility, whereas CpG methylation marks can be interpreted as endogenous DNA methylation. By physically separating the genomic DNA from the mRNA, scNMT-seq can profile RNA expression, DNA methylation and chromatin accessibility read-outs from the same cell. This third hackathon focused on data integration strategies to detect global covariation between RNA expression and DNA methylation variation from scNMT-seq data in a mouse gastrulation study <span class="citation" data-cites="1H9T8tTsB">[<a href="#ref-1H9T8tTsB" role="doc-biblioref">20</a>]</span>.</p>
<p>Mouse gastrulation is a major lineage specification event in mammalian embryos that is accompanied by profound transcriptional rewiring and epigenetic remodeling <span class="citation" data-cites="wFwe0y4i">[<a href="#ref-wFwe0y4i" role="doc-biblioref">6</a>]</span>. In this study, four developmental stages were profiled, spanning exit from pluripotency to germ layer commitment (E4.5 to E7.5). For simplicity in this hackathon, we focused on the integration of RNA expression and DNA methylation, quantified over the following genomic contexts: gene bodies, promoters, CpG islands, and DHS open sites. A total of 799 cells passed quality control (Figure <a href="#fig:scnmtseq">2</a>A). Preliminary analyses using dimensionality reduction methods confirmed that all four embryonic stages could be separated on the basis of RNA expression (Figure <a href="#fig:scnmtseq">2</a>B). The main challenge was to leverage the multi-faceted nature of measurements to better resolve the single-cell subpopulations from distinct embyonic stages.</p>
<h3 id="computational-challenges-2">Computational challenges</h3>
<p>Our participants considered 3 computational strategies: MOSAIC, LIGER, and Multi-block sparse Projection to Latent Structures. MOSAIC is a Multi-Omics Supervised Integrative Clustering algorithm inspired by <code>survClust</code><span class="citation" data-cites="TvcYLBQI">[<a href="#ref-TvcYLBQI" role="doc-biblioref">21</a>]</span> that classifies samples by creating weighted distance matrices of effect sizes across data modalities with an outcome of interest. The weights are defined as the maximum of the ratio of cluster specifc vs population log likelihoods. To facilitate integration, weighted distance matrices are standardized and Multidimensional scaling (MDS) is then used to map the subjects into an n-dimensional space that preserves between-subject distances for clustering. (Figure <a href="#fig:scnmtseq">2</a>C). LIGER is an unsupervised non-negative matrix factorization model for manifold alignment that assumes a common feature space by aggregating DNA methylation over gene-centric elements (promoters or gene bodies) but allows cells to vary between data modalities <span class="citation" data-cites="MaZsghuS">[<a href="#ref-MaZsghuS" role="doc-biblioref">22</a>]</span> (Figure <a href="#fig:scnmtseq">2</a>D). Multi-block sparse Projection to Latent Structures (multiblock sPLS), is a sparse generalization of canonical correlation analysis that maximizes paired covariances between the RNA data set and each of the other genomic context data sets [<span class="citation" data-cites="Ee0L8PLY QSXGprag"><a href="#ref-Ee0L8PLY" role="doc-biblioref">23</a> [<a href="#ref-QSXGprag" role="doc-biblioref">24</a>]</span> (Figure <a href="#fig:scnmtseq">2</a>E). <strong>this paragraph could be rewritten for clarity</strong></p>
<div id="fig:scnmtseq" class="fignos">
<figure>
<img src="images/scNMTseq.png" style="width:60.0%" alt="" /><figcaption><span>Figure 2:</span> </figcaption>
</figure>
</div>
<p>Caption Figure: <strong>Overview of hackathon analyses for the scNMT-seq challenge.</strong>
<strong>A</strong> Summary of the data modalities analyzed, including different putative regulatory regions.
<strong>B</strong> UMAP of RNA measurements using 671 highly variable genes shows separation of the four embryonic stages.<br />
<strong>C</strong> Supervised analysis using view-specific and integrative distance measures with MOSAIC: The integration identifies five clusters of cell populations based on Adjusted Mutual Information and Standardized Pooled Within Sum of Squares that outperforms individual (single omics) analyses.<br />
<strong>D</strong> LIGER joint alignment using gene body methylation and RNA expression: cells are colored by stage (left) or original data modality (right).
<strong>E</strong> Unsupervised integration using multiblock sPLS: cells are projected into the space spanned by each data view components that are maximally correlated. For performance assessment, two types of analyses were considered, either by omitting the missing DNA methylation values or incorporating imputed values. K-means clustering analysis based on the multiblock sPLS components was used to calculate balanced accuracy measures.</p>
<h4 id="challenge-1-defining-genomic-features">Challenge 1: defining genomic features</h4>
<p>The first challenge presented in this hackathon concerns the definition of the input data. The output of single-cell bisulfite sequencing are binary DNA methylation measurements for individual CpG sites. Integrative analysis at the CpG level is extremely challenging due to the sparsity levels, the binary nature of the read-outs, and the intricacy in interpretation of individual dinucleotides. To address these problems, DNA methylation measurements are typically aggregated over pre-defined sets of genomic elements (i.e. promoters, enhancers, etc.). This preprocessing step reduces sparsity, permits the calculation of binomial rates that are approximately continuous and can also improve interpretability of the model output.</p>
<!-- There are two common strategies to define genomic elements. The first one is to use a running window approach across the entire genome. This strategy has been successful to distinguish heterogeneous cell types, but it does not improve interpretability and it typically leads to an enormously large feature set. The alternative strategy is to adopt a biologically-informed approach where genic annotations (e.g. gene body, exon, or promoter regions) as well as ChIP-seq data or chromatin accessibility information is employed to restrict the feature space to genomic regions of regulatory potential. -->
<p>We observed remarkable differences between genomic contexts on the integration performance. In MOSAIC, stages are better separated when using DNA methylation measurements on promoter regions and at least four clusters (AMI=0.45). Interestingly, this setting performed better than using RNA expression alone (AMI=0.40). Notably, when using an integrated solution across data modalities, stages were better classified (AMI = 0.68) (Figure <a href="#fig:scnmtseq">2</a>C). LIGER, that was also applied in the <a href="#spatial-section">first hackathon</a> requires a common feature space to perform alignment of cells when profiled for different data modalities. This hackathon provides unambiguous cell matching between the data modalities and thus represents a gold standard for testing this approach. LIGER was applied to gene expression and gene body methylation: the poor alignment suggested a complex coupling of gene expression and gene body methylation during gastrulation (Figure <a href="#fig:scnmtseq">2</a>D). Finally, multiblock sPLS identified covarying components between RNA expression and DNA methylation that separated cell stages in all putative regulatory contexts considered (Figure <a href="#fig:scnmtseq">2</a>E). Taken altogether, these results confirmed that the appropriate selection of the feature space is critical for a successful integration with RNA expression.</p>
<h4 id="challenge-2-missing-values-in-dna-methylation">Challenge 2: Missing values in DNA methylation</h4>
<p>Single-cell bisulfite sequencing protocols are limited by incomplete CpG coverage because of the low amounts of starting material. Nonetheless, in contrast to scRNA-seq, missing data can be distinguished from dropouts. Integrative methods can be divided into approaches that can handle missing values (e.g. MOSAIC, multiblock sPLS which omit the missing values during inference), or approaches that require <em>a priori</em> imputation (e.g. LIGER). In this hackathon, missing values were imputed using nearest neighbor averaging (as implemented in the <code>impute</code> package <span class="citation" data-cites="GngCJZvg">[<a href="#ref-GngCJZvg" role="doc-biblioref">25</a>]</span>) in the methylation data.</p>
<p>We compared the integration performance of multiblock sPLS either with original or with imputed data. The missing values were inferred using nearest neighbor averaging (as implemented in the <code>impute</code> package <span class="citation" data-cites="GngCJZvg">[<a href="#ref-GngCJZvg" role="doc-biblioref">25</a>]</span>) in the methylation data. The components associated to each data set showed varying degree of separation of the embryonic stages, depending on the genomic contexts (Figure <a href="#fig:scnmtseq">2</a>E). Accuracy measures based on k-means clustering analysis on the multiblock sPLS components showed that gene body methylation components were better at characterizing embryonic stage after imputation (from 70% with original data to 86% after imputation).</p>
<p>Missing values in regulatory context data represent a topical challenge in data analysis, and further methodological developments are needed to either handle and accurately estimate missing values.</p>
<h4 id="challenge-3-linking-epigenetic-features-to-gene-expression">Challenge 3: Linking epigenetic features to gene expression</h4>
<p>One of the main advantages of scNMT-seq is the ability to unbiasedly link epigenetic variation with gene expression. Transcriptional activation is associated with specific chromatin states near the gene of interest. This includes deposition of activatory histone marks such as H3K27ac, H3K4me3 and H3K36me3, binding of transcription factors, promoter and/or enhancer demethylation and chromatin remodeling. All these events are closely interconnected and leave a footprint across multiple molecular layers that can only be (partially) recovered by performing an association analysis between a specific chromatin read-out and mRNA expression. However, given the large amount of genes and regulatory regions, this task can become prohibitively large, with the associated multiple testing burden. In addition, some of our analyses have shown that the correlations between epigenetic layers and RNA expression calculated from individual genomic features can be generally weak or spurious.</p>
<p>A practical and straightforward approach from a computational perspective involves considering only putative regulatory elements within each gene’s genomic neighborhood. Nonetheless, this might miss important links with regulatory elements located far away from the neighborhood.</p>
<p>In recent years, chromosome conformation capture experiments, have uncovered a complex network of chromatin interactions inside the nucleus connecting regions separated by multiple megabases along the genome and potentially involved in gene regulation. Early genome-wide contact maps generated by HiC uncovered domains spanning on the order of 1 Mb (in humans) within which genes would be coordinately regulated. Thus, a second strategy to associate putative regulatory elements and genes is to build on existing promoter-centered chromatin contact networks to restrict the association analysis to putative regulatory elements that are in 3D contact with genes.
Although this is a promising strategy to reduce the complexity of the association analysis, most of our 3D interaction datasets are produced in bulk samples and it is so far unclear how much of these structures are preserved across individual cells. While single-cell conformation capture experiments remain limited by data sparsity and high levels of technical noise, we envision that technological advances in this area will deepen our understanding of the regulatory roles of chromatin states.</p>
<p><a name="common-challenges-section"></a></p>
<h2 id="sec:common">Commonalities between analytical multi-omics approaches for hackathons</h2>
<p>Each hackathon study highlighted disparate challenges to multi-omics from different measurement technologies. Yet, these studies were unified by the underlying problem of data integration. We summarize the common problems faced across all hackathons and shared approaches adopted by participants. These commonalities highlight the critical computational issues in multi-omics single-cell data analysis.</p>
<p>The choice of methods mostly relied on the biological question to address: data integration was conducted using projection approaches, cell prediction required machine or statistical learning methods (SVM, Enet), and spatial analysis was conducted using Hidden Markov random field or Moran’s Index. As computational methodologies span technologies, so do the central challenges highlighted in each hackathon. For example, the accuracy of the analysis critically depended on data pre-processing (e.g. normalization, upstream feature selection), differences in scale across data sets, and overlap (or lack thereof) of features (Figure <a href="#fig:common">3</a>). In many cases, preprocessing can yield data mapping to common molecular features, such as genes, that can be the focus of the integration task. However, the spatial proteomics challenge showed that many multi-omics datasets have limited shared features between studies. In cross-study and cross-platform analyses, methods that investigate hierarchical structure and apply measures of higher order concordance among the omics, cell, and phenotype layers are critical. Even in cases with matching molecular features, such analyses can reveal novel aspects of biology.</p>
<p>Table ?? summarizes the main methods that were applied across all hackathons. A large number of computational analysis methods that were applied derive from bulk RNA-seq literature, with the exception of projection methods developed for single-cell such as tSNE, UMAP, and LIGER. In this section, we briefly highlight the three common challenges faced across all hackathons.</p>
<h3 id="common-challenge-1-dependence-on-pre-processing-method-andor-variable-selection">Common challenge 1: Dependence on pre-processing method and/or variable selection</h3>
<p>Pre-processing steps strongly affect downstream analyses. Our participants thoroughly assessed the effect of normalization and data transformation (e.g. spatial transcriptomics, Figure <a href="#fig:spatial">1</a>A), as well as preliminary feature selection (mostly on based on highly variable genes) or feature summarization (scNMT-seq study). Ease of comparisons between analyses was facilitated by providing processed input data (see <a href="#software-section">software</a> section), which still encountered reproducibility issues between the original published study and the new analyses. For example, in the spatial transcriptomics study, 19 genes were selected in [COullomb vignette to ref] (<em>in scRNA-seq? or seqFISH?</em>) whereas the original paper selected 47 genes based on the same feature selection process <span class="citation" data-cites="13v18bjoF">[<a href="#ref-13v18bjoF" role="doc-biblioref">3</a>]</span>. No consensus was reached across participants’ analyses regarding the best way to process such emerging data, as no extensive benchmark, ground truth, or established biological results are yet available, which we discuss in <a href="#benchmarking-section">benchmarking</a>. <strong>the last sentences here are unclear</strong></p>
<h3 id="common-challenge-2-managing-differences-in-scale-and-size-across-datasets">Common challenge 2: Managing differences in scale and size across datasets</h3>
<p>Various techniques were used to address the differences in scale or resolution across data sets. For spatial transcriptomics and proteomics, participants focused on a common set of genes (via feature selection in spatial transcriptomics) or proteins. The scNMT-seq study that included overlap between cells raised the issue of differences in data set size with a varying number of features per dataset ranging from 6,673 to 18,345 (Figure ??A). Some projection-based methods, such as MOFA <span class="citation" data-cites="Bf6HgBfZ">[<a href="#ref-Bf6HgBfZ" role="doc-biblioref">26</a>]</span>, require a similar number of features in each data set, while others such as PLS / sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">23</a>]</span> do not have this limitation and enable more flexible analysis (Abadi vignette). Differences in data scale may result in one data set contributing to either too much variation or noise during data integration. Techniques such as re-scaling (Jenagan vignette), batch effect removal approaches, such as Combat <span class="citation" data-cites="1HahRBkyb">[<a href="#ref-1HahRBkyb" role="doc-biblioref">27</a>]</span> (Singh vignette) or weighting specific data sets (Arora, Abadi vignettes), were considered and each offered further improvement in the analyses.</p>
<h3 id="common-challenge-3-addressing-partial-overlap-of-information-across-cells-or-features">Common challenge 3: Addressing partial overlap of information across cells or features</h3>
<p>The degree of feature or cell overlap between datasets varied dramatically within each study. Intuitively, to integrate information across modalities, at least one type of overlap (whether on the features or cells, Figure <a href="#fig:common">3</a>) is required. The field has made progress in developing methods to integrate data sets across the same (bulk) samples of single cells, mostly based on dimension reduction techniques. Amongst them, NMF (LIGER) and Projection to Latent Structures (sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">23</a>]</span>) were used for the scNMT-seq study. When there was no cell overlap, such as in the spatial studies, imputation methods were used to predict gene, protein, or spatial expression values based on nearest neighbors, latent variables, or optimal transport. These methods were also used to predict cell types (Hsu vignette). The most challenging study was the spatial proteomics, which raised the issue of no overlap between cells or features - the so called fourth corner that relies on phenotypes (Challenge 3 in <a href="#proteomics-section">proteomics</a>). We anticipate that this scenario will be avoided once technological progress and increase in data availability is achieved <span class="citation" data-cites="doi">[<span class="citeproc-not-found" data-reference-id="doi"><strong>???</strong></span> 10.1186/s13059-020-1926-6]</span>.</p>
<div id="fig:common" class="fignos">
<figure>
<img src="images/summary_fig_person.png" style="width:50.0%" alt="" /><figcaption><span>Figure 3:</span> </figcaption>
</figure>
</div>
<p>Caption figure: <strong>A.</strong> Overlap of features (genes) but not cells (e.g. spatial transcriptomics where cell type prediction for seqFISH data was performed based on scRNA-seq where cell types are known.
<strong>B.</strong> Partial overlap of features (proteins) but no overlap of cells (e.g. spatial proteomics that required data imputation or cell type prediction).
<strong>C.</strong> Overlap of cells across assays, but no overlap of features (e.g. scNMT-seq where data integration was performed).
<strong>D.</strong> Lack of overlap between cells and features (the so-called fourth corner problem <a href="#proteomics-section">proteomics</a>).</p>
<p><a name="commontable"></a>Table: Different methods were used in the hackathon. * indicates that the method was not applied on the hackathon data. For some common challenges, ‘bulk’ indicates the method was originally developed for bulk omics, ‘sc’ indicates the method was specifically developed for single-cell data <strong>table will include links to vignettes rather than name of participants TO DO</strong> {#tbl:common}</p>
<style type="text/css">
  .tg {
    border-collapse: collapse;
    border-spacing: 0;
    background-color: #ffffff;
    color: #333333;
  }
  .tg td {
    border-color: black;
    border-style: solid;
    border-width: 1px;
    overflow: hidden;
    padding: 10px 5px;
    word-break: normal;
    text-align: left;
    vertical-align: top
  }
  .tg th {
    border-color: black;
    border-style: solid;
    border-width: 1px;
    overflow: hidden;
    padding: 10px 5px;
    word-break: normal;
    text-align: left;
    vertical-align: top;
    font-weight: bold;
  }
  .tg .tg-bold {
    font-weight: bold;
  }
</style>
<table class="tg">
<thead>
<tr>
<th>
Common challenges
</th>
<th>
Tasks
</th>
<th>
sc Spatial
</th>
<th>
sc targeted proteomics
</th>
<th>
sc NMT-seq
</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tg-bold">
Pre-processing
</td>
<td class="tg-bold">
Normalization &amp; data transformation
</td>
<td>
Data distribution checks (Coullomb, Singh)<br> High Variable Genes selection (Xu)
</td>
<td>
Variance Stabilization Normalisation <span class="citation" data-cites="1156sEPws">[<a href="#ref-1156sEPws" role="doc-biblioref">28</a>]</span> (Meng)<br> Arcsinh transformation (Jeganathan).<br> Inverse transformation (Jenagan)<br> Selection of patients (Jenagan)
</td>
<td>
Summaries of DNA measurements (input data provided in hackathon)
</td>
</tr>
<tr>
<td class="tg-bold">
Managing differences in scale<br>
</td>
<td class="tg-bold">
Data integration
</td>
<td>
LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">29</a>]</span> (Sodicoff) (sc)<br> ComBat (Singh)<br> Projection methods MFA, sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">23</a>]</span> (Singh*) (bulk)<br> UMAP/tSNE (Sodicoff) (sc)
</td>
<td>
Multi-block PCA <span class="citation" data-cites="v4W8vQ17">[<a href="#ref-v4W8vQ17" role="doc-biblioref">30</a>]</span><br> Weighting matrices based on their similarities: STATIS, MFA (Chen*)(bulk)<br> Scale MIBI-TOF to the range of CyTOF values (Jenagan)
</td>
<td>
LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">29</a>]</span> (Welch) (sc)<br> Projection method sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">23</a>]</span> (Abadi) (bulk)<br> Multi Omics Supervised Integrative Clustering with weights (Arora) (bulk)
</td>
</tr>
<tr>
<td class="tg-bold" rowspan="6">
Overlap
</td>
<td>
<b>Cell overlap</b><br> (features not matching)
</td>
<td>
</td>
<td>
</td>
<td>
<b>Dimension reduction and projection methods:</b><br> LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">29</a>]</span> (Welch) (sc)<br> sGCCA <span class="citation" data-cites="Ee0L8PLY">[<a href="#ref-Ee0L8PLY" role="doc-biblioref">23</a>]</span> (Abadi) (bulk)<br>
</td>
</tr>
<tr>
<td>
<b>Partial feature overlap</b><br> (cells not matching)
</td>
<td>
</td>
<td>
<b>Imputation:</b><br> Direct inversion with latent variables (Sankaran)<br> Optimal transport to predict protein expression (Lin)<br> K Nearest Neighbor averaging (Jenathan<em>)</span><br>
<br>
<b>No imputation:</b><br> Biological Network Interaction (Foster</em>)
</td>
<td>
</td>
</tr>
<tr>
<td>
<b>Partial cell overlap</b><br> (features not matching)
</td>
<td>
</td>
<td>
Multi block PCA <span class="citation" data-cites="v4W8vQ17">[<a href="#ref-v4W8vQ17" role="doc-biblioref">30</a>]</span> (Meng*)
</td>
<td>
</td>
</tr>
<tr>
<td>
<b>No cell overlap</b><br> (complete feature overlap)
</td>
<td>
Averaging nearest neighbors in latent space to impute unmeasured expression values (Coullomb?)
</td>
<td>
Transfer cell type label with Random Forest (Hsu)
</td>
<td>
LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">29</a>]</span> (Welch)
</td>
</tr>
<tr>
<td>
<b>No cell overlap</b><br> (partial feature overlap)
</td>
<td>
</td>
<td>
Topic modeling to predict cell spatial co-location or spatial expression (Jenathan, partial feature overlap)<br>
</td>
<td>
</td>
</tr>
<tr>
<td class="tg-bold">
No overlap
</td>
<td>
</td>
<td>
RLQ <span class="citation" data-cites="UCIhFB5B">[<a href="#ref-UCIhFB5B" role="doc-biblioref">31</a>]</span> (Chen*)
</td>
<td>
</td>
</tr>
<tr>
<td class="tg-bold" rowspan="4">
Generic approaches
</td>
<td class="tg-bold">
Classification &amp; feature selection
</td>
<td>
Backward selection with SVM (Coullomb)<br> self training ENet (Singh)<br> Balanced error rate (Coullomb, Singh)<br> Recursive Feature Elimination (Xu)<br>
<br> (all bulk)
</td>
<td>
</td>
<td>
Multi Omics Supervised Integrative Clustering (Arora) (bulk)<br> Lasso penalization in regression-type models (bulk)
</td>
</tr>
<tr>
<td class="tg-bold">
Cell type prediction
</td>
<td>
Projection with LIGER <span class="citation" data-cites="OekvE5up">[<a href="#ref-OekvE5up" role="doc-biblioref">29</a>]</span> (Sodicoff)<br> SVM (Coullomb, Xu)<br> ssEnet (Singh)<br> (all bulk)
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td class="tg-bold">
Spatial analysis
</td>
<td>
Hidden Markov random field<br> Voronoi tesselation (Coullomb) (bulk)
</td>
<td>
Spatial autocorrelation with Moran’s Index (Hsu, Lin)<br>
<br> Selection of spatial discriminative features:<br> Moran’s Index, NN correlation, Cell type, interaction composition, L function (Lin)<br>
<br> (all bulk?)
</td>
<td>
</td>
</tr>
<tr>
<td class="tg-bold">
Inclusion of additional information
</td>
<td>
</td>
<td>
Survival prediction: Cox regression based on spatial features (Lin)
</td>
<td>
Include annotated hypersensitive sites index to anchor new/unseen data from DNase-seq, (sc)ATAC-seq, scNMT-seq, for <em>de novo</em> peak calling (Meuleman*) (bulk)
</td>
</tr>
</tbody>
</table>
<p><a name="challenges-interp-section"></a></p>
<h2 id="challenges-for-interpretation">Challenges for interpretation</h2>
<p>The analyses from each hackathon emphasized that regardless of the common difficulties faced by our participants, there is no one method fits all for multi-omics integration. An equally important complement to the diverse computational methods used to solve multi-omics analysis problems rests in the biological interpretation of their solutions. A notable challenge to interpretation is that the integrated data from these approaches are often higher dimensional than the input datasets. For example, even abstract lower dimensional representations of spatial coordinates are often interpreted in terms of their ability to capture higher level cellular structure or prognostics, requiring even further data than the high-throughput multi-omics data as input. These approaches also suggest that new measures of the tumor or cell ecosystems of interacting cells are needed because these interactions are fundamental to biological systems. Both the high dimensionality and biological complexity introduce further challenges in understanding and communicating the results from these analyses. Thus, efforts to interpret multi-omics data will require standardized vocabulary, benchmarked methods, and abstracted variables that can be compared between studies.</p>
<h3 id="subsec:super">Supervised versus unsupervised</h3>
<p>Interpretation hinges on the analysis method selected for a given dataset. One simple delineation between methods used throughout the hackathons and summarized in <a href="#commontable">Table 1</a>, is that some
aim to predict a clearly defined outcome at the start of the project, such as recognizing the environment of tumor cells versus that of healthy cells (see <a href="#proteomics-section">proteomics</a> section).
The supervised setting often provides easier interpretations, one can easily rank the covariates and contiguous data in terms of their predictive potential.</p>
<p>On the other hand when data are collected using multiple
different technologies the data integration needs to provide organizing patterns that enable interpretation.
Clustering is often used as one unsupervised method and is a good example of the use of a latent variable, in this case a factor or categorical variable which was not directly measured on the data but is often used to enable simple interpretations.</p>
<p>In cellular biology, a favorite such division into clusters is that involved in the definition of cell type
<span class="citation" data-cites="H4wZSl5d">[<a href="#ref-H4wZSl5d" role="doc-biblioref">32</a>]</span>.</p>
<p>Sometimes people get carried away in “clustering data” and manipulate the data, in cytometry one often sees cell gating done.
The goal there is to eliminate cells in intermediary states to give clearly delineated inventories of cell types or cells in discrete states, this is a static description and will not enable researchers down the road to predict or understand transtitions between types.</p>
<p>Although a latent factor can be a useful first approximation, keep in mind that development of cells and their fate is a dynamic process and it can often be beneficial to keep data that enable interpretation of the cell trajectories: in that case, locally the underlying latent variable of interest is continuous along a gradient of development.</p>
<p>So far, we have seen two types of latent variables: clusters and a one dimensional continuous “gradient”, (pseduo-time, disease progression are two examples of such latent gradients).
However the idea of latent variables is a rich anchor for many multimodal methods and can often be useful in highlighting what the modalities have in “common” and how they differ.
The commonalities are well understood in the case of classical multivariate factor analyses where the data are decomposed into “commonalities” and uniqueness components <span class="citation" data-cites="q9SIZrho">[<a href="#ref-q9SIZrho" role="doc-biblioref">33</a>]</span>.</p>
<p>A schematic summary of the different stages in interpretation is provided here:</p>
<div id="fig:interpretation" class="fignos">
<figure>
<img src="images/Interpretation_mockup.png" style="width:70.0%" alt="" /><figcaption><span>Figure 4:</span> </figcaption>
</figure>
</div>
<p>Caption figure: <strong>A</strong> Schematic diagram of stages of interpretaion and integration of data sources.
<strong>B</strong> Standards in Geographic Information Systems enable the integration of multiple layers of data.
<strong>C</strong> Brushing an UMAP with a covariate can illustrate the dynamics of cell changes</p>
<p>(<strong>Kris: I have this feeling this is not the type of figure Susan intended to show</strong>).</p>
<p>Multiple domains of knowledge can be combined easily if there is a common coordinate system, as in geospatial analyses.This is often a goal in multimodal or conjoint analyses, when the first step is to find a common compromise or consensus on which to project each of the individual modalities.
Conjoint analyses also known as STATIS <span class="citation" data-cites="4fOW94wl">[<a href="#ref-4fOW94wl" role="doc-biblioref">34</a>]</span> was a very early multimodal method designed as PCA of PCAs where the first step in the analyses was to find what the different modalities had in common and define a consensus <span class="citation" data-cites="18b0ymB7t">[<a href="#ref-18b0ymB7t" role="doc-biblioref">35</a>]</span> onto which the individual tables were projected.
This method can be seen as an extension of the class of matrix decomposition methods to data cubes.
Many extensions to matrix decompositions have been designed for multimodal data, <span class="citation" data-cites="nhuT45y5">[<a href="#ref-nhuT45y5" role="doc-biblioref">36</a>]</span> offers an overview of the relations between many of them.</p>
<h3 id="reasoning-by-analogy-with-geospatial-problems">Reasoning by analogy with geospatial problems</h3>
<p>In both the <a href="#proteomics-section">proteomics</a> example
and the <a href="#spatial-section">spatial</a> examplary data, a spatial dimension is already naturally available.
As in previous studies one can leverage
extensive methods developed in spatial statistics to
quantify spatial effects <span class="citation" data-cites="1ABBBCpyT">[<a href="#ref-1ABBBCpyT" role="doc-biblioref">37</a>]</span>.
Contiguity and clustering can be tested and easily understood in the spatial context.</p>
<p>In these cases, layers of information can be mapped to the natural coordinate system in the same way
a GIS system incorporates them (Figure <a href="#fig:interpretation">4</a>B).</p>
<p>The spatial coordinate system analogy can be pursued
further by finding a “consensus space” that provides a common coordinate system.</p>
<p>There are however pitfalls in using very sophisticated dimension reduction techniques which lead to over-interpretation or misinterpretation
(size of clusters in tSNE related to sampling baselines rather than density, …)</p>
<h3 id="disparate-sources-of-evidence-are-more-compelling-than-more-of-the-same.">Disparate sources of evidence are more compelling than more of the same.</h3>
<p>Following <a href="https://www.encyclopedia.com/people/philosophy-and-religion/roman-catholic-and-orthodox-churches-general-biographies/john-henry-newman">Cardinal Newman’s principle</a><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
disparate sources of evidence, or in this case data from different technologies, are more compelling than many replicates of the same technology.
Thus, if different technologies allow a consensus on underlying latent variables, this information is worth retaining.</p>
<h3 id="explaining-results-to-biologists-through-generative-models-and-simulations-ex-factor-analysis-hierarchical-models.">Explaining results to biologists through generative models and simulations (ex: Factor Analysis, Hierarchical models).</h3>
<p>Several difficulties arise when explaining summaries and conclusions, problems encountered include non-identifiability of models
or non-sufficiency of summaries, simulations can often provide effective communication tools.</p>
<p>One can often generate data from different probabilistic models and show that the methods cannot differentiate between the generation processes, this is the identifiability problems that most overparametrized models lead to.
Added constraints on the parameters can often
be integrated into the analyses to make them more realistic and reduce if not eliminate the identifiability issues.</p>
<h3 id="meaningful-interpretation-by-linking-in-databases">Meaningful Interpretation by linking in databases</h3>
<p>In the right side of Figure <a href="#fig:interpretation">4</a>A we show how connections to layers of information from outside databases can be incorporated into the final output. Real biological understanding is often subordinated to the integration
of this contiguous information.
Either from the metadata already available in the multiassay containers as for instance in the <a href="https://bioconductor.org/packages/release/bioc/html/MultiAssayExperiment.html">MultiAssayExperiment package</a> or from exterior sources such as Gene Ontologies, Biomart <span class="citation" data-cites="XkAC715J">[<a href="#ref-XkAC715J" role="doc-biblioref">38</a>]</span>, Kegg, Human Cell Atlas (HCA) or other sources often available through links provided within systems like bioconductor ().</p>
<p>Redundant biological knowledge is often enlightening,
as many methods suffer from identifiability issues (ie in a gradient, the direction of the direction is unknown).
By providing information on the extreme points in a map
or brushing a map with known gene expression features
one can delineate orientations and clusters.</p>
<p>For instance coloring by CD56 across time shows the dynamics of immune response <span class="citation" data-cites="1GblcsF7">[<a href="#ref-1GblcsF7" role="doc-biblioref">39</a>]</span> (Figure <a href="#fig:interpretation">4</a>C).</p>
<h3 id="visualization-tools-for-interpretation-and-communication-to-biologists">Visualization tools for interpretation and communication to biologists</h3>
<p>An example of effective visual interpretation tools is interactive brushing of UMAP plot, see Figure <a href="#fig:interpretation">4</a>C by Kris Sankaran.</p>
<h3 id="interpretation-for-data-scientists-reading-the-methods-sections-requires-a-good-understanding-of-the-building-blocks">Interpretation for data scientists reading the methods sections requires a good understanding of the building blocks</h3>
<p>Spanning all of these interpretation challenges is a further central communication barriers within the community of data scientists, computer scientists and computational biologists ie communicating about methods within a community of practitionners who do not have the same vocabulary or background.</p>
<p>Many tools are used as black boxes and users
don’t know or agree on what exactly the methods are doing (MOFA and tSNE are examples).
The first step in unblinding these black boxes used as methodology shortcuts is to have a clear glossary of terms and how we are using them.
Many synonyms for multimodal data exist and some have nuances, see the table we have compiled (ref: Table1).
Understanding the relation between methods developed by different teams is essential and we often try to organize the methods first, thus it is useful to create a dichotomy of methods and their underlying properties.</p>
<p>A very useful tool for making methodological black boxes more transparent are simulated data.
These can follow benchmark methods such as those presented in <a href="#benchmarking-section">benchmarking</a> and use well defined generative processes to clarify what some complex methods do.</p>
<p>Visualization of the data, following the step by step transformations and optimizations of data representations also help clarify how certain methods fit models or compress and reduce data dimensionality.
These visualizations are often very specialized (think for instance, correspondence analyses, goodness of fit plots like qqplots or rootograms or mean-variance fitting).
These intermediary plots don’t usually end up in the main text of final biological publications and serve as intermediary checks to unpack the black boxes.</p>
<h3 id="missing">Missing</h3>
<ul>
<li><p>Validation through complementary data and sequential experimental design.</p></li>
<li><p>Examples from other parts, references and commentary here missing until documents become availabe (<span class="citation" data-cites="sec:seqFish">[<span class="citeproc-not-found" data-reference-id="sec:seqFish"><strong>???</strong></span>]</span>)</p></li>
</ul>
<h3 id="references">References</h3>
<p>Cell type definition:
<span class="citation" data-cites="H4wZSl5d">[<a href="#ref-H4wZSl5d" role="doc-biblioref">32</a>]</span></p>
<p>Factor Analysis:
<span class="citation" data-cites="q9SIZrho">[<a href="#ref-q9SIZrho" role="doc-biblioref">33</a>]</span></p>
<p>Statis, conjoint analysis:
<span class="citation" data-cites="4fOW94wl">[<a href="#ref-4fOW94wl" role="doc-biblioref">34</a>]</span></p>
<p>The French way:
<span class="citation" data-cites="18b0ymB7t">[<a href="#ref-18b0ymB7t" role="doc-biblioref">35</a>]</span></p>
<p>Overview and connections of methods: KS
<span class="citation" data-cites="nhuT45y5">[<a href="#ref-nhuT45y5" role="doc-biblioref">36</a>]</span></p>
<p>Kevin Murphy:
Probabilistic Machine Learning, MIT Press
<span class="citation" data-cites="doi:10.5555/2380985">[<span class="citeproc-not-found" data-reference-id="doi:10.5555/2380985"><strong>???</strong></span>]</span>
<span class="citation" data-cites="aSqxpadK">[<a href="#ref-aSqxpadK" role="doc-biblioref">40</a>]</span>
<span class="citation" data-cites="aSqxpadK">[<a href="#ref-aSqxpadK" role="doc-biblioref">40</a>]</span></p>
<p>GIS: reference
https://www.usgs.gov/faqs/what-a-geographic-information-system-gis</p>
<p>Original: https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/styles/full_width/public/thumbnails/image/8BaseLayersofTheNationalMap.JPG</p>
<p>Biomart:
<span class="citation" data-cites="XkAC715J">[<a href="#ref-XkAC715J" role="doc-biblioref">38</a>]</span></p>
<p>UMAP:
<span class="citation" data-cites="172t1QM5n">[<a href="#ref-172t1QM5n" role="doc-biblioref">41</a>]</span>
https://arxiv.org/abs/1802.03426v2</p>
<p>Spatial tumor and immune cells:
<span class="citation" data-cites="1ABBBCpyT">[<a href="#ref-1ABBBCpyT" role="doc-biblioref">37</a>]</span></p>
<p>CD56 Immune cell coloring, paper with C. Blish:
<span class="citation" data-cites="1GblcsF7">[<a href="#ref-1GblcsF7" role="doc-biblioref">39</a>]</span></p>
<p>Footnote:
Cardinal Newman wrote <strong>The Grammar of Assent.</strong> and cited in [Bruno de Finetti, Volume 1, 1974 Theory of Probability]:</p>
<p><em>Supposes a thesis (e.g. the guilt of an accused man) is supported by a great deal of circumstantial evidence of different forms, but in agreement with each other; then even if each piece of evidence is in itself insufficient to produce any strong belief, the thesis is decisively strengthened by their joint effect.</em></p>
<p><a name="benchmarking-section"></a></p>
<h2 id="techniques-and-challenges-for-benchmarking-methods">Techniques and challenges for benchmarking methods</h2>
<p>Visualizations and biological assessment of marker gene lists
resulting from multi-omics analyses provide a critical interpretation of high-throughput data integration, but additional
quantitative metrics are necessary to delineate biologically-relevant
features from features arising from either computational or
technical artifacts. Quantitative benchmarks
are also essential to enable unbiased comparisons between analytical
methods. For example, the goal of multi-platform single-cell data
analysis is often the recovery of known cell types through
computational methods. Metrics such as the adjusted Rand Index
(ARI) enable a direct assessment of the clustering results with respect
to known cell types. When cell types or biological features are not
known <em>a priori</em>, benchmark methods can also be used to discover known
relationships between data modalities. For example, <em>cis</em> gene
regulatory mechanisms observed between chromatin accessibility and
gene expression. Our hackathons highlighted that many of these relationships are not fully understood
at the single-cell level, and that benchmarking standards are critically needed for validation (Figure <a href="#fig:benchmark">5</a>A).</p>
<div id="fig:benchmark" class="fignos">
<figure>
<img src="images/Benchmark_mockup.png" style="width:50.0%" alt="" /><figcaption><span>Figure 5:</span> </figcaption>
</figure>
</div>
<p>Caption figure: <strong>A</strong> Systematic benchmarking of single-cell multi-omic analysis
methods can involve experimental data (as per our hackathons),
custom control datasets, where known structure is imposed through the experimental design or simulated data. The amount of biological signal and ground truth available varies
considerably between these types of data. The resulting multi-omics datasets are analysed
by competing methods and compared using metrics that have general purpose or take ground truth into account (e.g. cell type labels or number of cell types simulated).
<strong>B</strong> scNMT-seq study: correlations with linear projections (MOFA+) evaluated with cross-validation.</p>
<h3 id="challenges-and-strategies-for-benchmarking">Challenges and strategies for benchmarking</h3>
<p>Benchmarking multi-modal methods is inherently difficult, as ground
truth is rarely known. Ground truth can be introduced through simulating
high-throughput data <em>in silico</em>, but in the context of data integration,
the simulation of a realistic covariance structure across features and
across data modalities are challenging
<span class="citation" data-cites="cZOVX9E7">[<a href="#ref-cZOVX9E7" role="doc-biblioref">42</a>]</span> and must rely on an underlying
generative model that may introduce further biases into the benchmarking
analysis. Another strategy is to use cross-validation within a study,
or conduct cross-study validation to assess whether solutions found by
multi-modal methods generalize to held-out observations or held-out
studies. The latter was attempted in the <a href="#proteomics-section">spatial proteomics</a>
cross-study hackathon, but where ground truth was unknown.</p>
<!--. Moreover, these simulations can inadvertently embed the same underlying assumptions as the computational methods employed for analysis, introducing further biases into benchmark studies. Therefore, high-throughput datasets with known ground truth are also critical for multi-omics studies and robust test grounds for future hackathon studies that were widely discussed throughout the workshop.-->
<h4 id="challenge-1-creating-benchmarking-datasets">Challenge 1: creating benchmarking datasets</h4>
<p>Benchmark datasets serve two main purposes: to provide ground truth for the intended effect of exposure in a proposed study design, and to provide validation for an analytic task for which a new computational method may be proposed (e.g. data integration in our hackathons), Figure <a href="#fig:benchmark">5</a>A.</p>
<p>For single-cell studies, benchmark datasets have largely focused on measuring sequencing depth and diversity of cell types derived from a single assay of interest (e.g. scRNA-seq). Common experimental designs involve creating artificial samples through the mixing of cells in known proportions <span class="citation" data-cites="VmqVY5HQ dVbihx0f Vz4pQdwU">[<a href="#ref-VmqVY5HQ" role="doc-biblioref">43</a>,<a href="#ref-dVbihx0f" role="doc-biblioref">44</a>,<a href="#ref-Vz4pQdwU" role="doc-biblioref">45</a>]</span> or creating dilution series to simulate variation in cell size <span class="citation" data-cites="PxOZHHKj VmqVY5HQ">[<a href="#ref-VmqVY5HQ" role="doc-biblioref">43</a>,<a href="#ref-PxOZHHKj" role="doc-biblioref">46</a>]</span>. Simulating data is also popular and made more convenient through software such as the <code>splatter</code> R package <span class="citation" data-cites="117yS2Kkv">[<a href="#ref-117yS2Kkv" role="doc-biblioref">47</a>]</span>.</p>
<p>For multi-modal assays, while the intended effects can vary based on the leading biological questions, one may abstract out common data integration tasks such as co-embedding, mapping or correlation, and inferring causal relationships. We distinguish data integration from further downstream analyses that may occur on integrated samples such as differential analysis of both assays with regard to a certain exposure. Both the intended effects and data integration task rely on study design that takes into account the biological and technical variability via replicates, block design, randomization, the power analysis for the intended effect or data integration task, and the dependencies between modalities. For example, gene expression depends on gene regulatory element activity and thus requires that experiment design must also account for spatial and temporal elements in sampling for a given observation.</p>
<p>As such, no universal benchmark data scheme may suit every combination of modalities (e.g. mising cells design does not generalise to the spatial context), and benchmark datasets should be established for commonly used combinations of modalities or technologies towards specific data integration tasks.</p>
<h4 id="challenge-2-cross-validation-within-study">Challenge 2: cross-validation within study</h4>
<p>Cross-validation within a representative
multi-modal study is one possible approach for quantitative assessment
for unbiased comparison of methods. We note that the approach of
cross-validation – in which observations are split into folds or left
out individually for assessing model fit – has been used often for
parameter tuning within methods, or for other aspects of model selection
<span class="citation" data-cites="13ibOJcF0 maAEgLQK yVYfg2ZK YY25QUrX 5B54vifR tOD4Gkgt AQWTNms4 bFa7ptnr wkhRfjyx wP2BgpVi QSXGprag cZOVX9E7">[<a href="#ref-QSXGprag" role="doc-biblioref">24</a>,<a href="#ref-cZOVX9E7" role="doc-biblioref">42</a>,<a href="#ref-13ibOJcF0" role="doc-biblioref">48</a>,<a href="#ref-maAEgLQK" role="doc-biblioref">49</a>,<a href="#ref-yVYfg2ZK" role="doc-biblioref">50</a>,<a href="#ref-YY25QUrX" role="doc-biblioref">51</a>,<a href="#ref-5B54vifR" role="doc-biblioref">52</a>,<a href="#ref-tOD4Gkgt" role="doc-biblioref">53</a>,<a href="#ref-AQWTNms4" role="doc-biblioref">54</a>,<a href="#ref-bFa7ptnr" role="doc-biblioref">55</a>,<a href="#ref-wkhRfjyx" role="doc-biblioref">56</a>,<a href="#ref-wP2BgpVi" role="doc-biblioref">57</a>]</span>.<br />
Similarly, permutation has been used to create null datasets, either
as a demonstration that a particular method is not overfitting, or for
parameter tuning, where the optimal parameter setting should result in
a model score that is far from the null distribution of model scores
<span class="citation" data-cites="j7x8dqSL MYhQ5fRN NSuq56O9">[<a href="#ref-j7x8dqSL" role="doc-biblioref">58</a>,<a href="#ref-MYhQ5fRN" role="doc-biblioref">59</a>,<a href="#ref-NSuq56O9" role="doc-biblioref">60</a>]</span>.
Cross-validation is particularly useful as a quantitative assessment
of a method’s self-consistency, even though it cannot determine the
<em>accuracy</em> of a method in a completely unbiased way if we do not have
access to an external test data set for further confirmation.</p>
<p>As part of the third hackathon, a cross-validation analysis of the scNMT-seq dataset using MOFA+ demonstrated that strong
relationships found among pairs of modalities in single-cells used
for training the model was often found to be equally strong
in held out cells (Figure <a href="#fig:benchmark">5</a>B)<strong>this sentence is unclear</strong>. This analysis revealed how we could reliably match dimensions of
latent space across cross-validation folds. Previous evaluations of
multi-modal methods have focused only on the top ‘latent factor’
<span class="citation" data-cites="IZfv7up4">[<a href="#ref-IZfv7up4" role="doc-biblioref">61</a>]</span>, however, we showed in our analyses, many latent factors can be reliably
discovered in held out cells in studies of complex biological
processes such as the differentiation of embryonic cells.</p>
<p>For clustering assessment, several studies have used resampling or
data-splitting strategies to determine prediction strength
<span class="citation" data-cites="4CvJHFCU kVhMOlK2 gbdea2Ea I1iOQSFC">[<a href="#ref-gbdea2Ea" role="doc-biblioref">12</a>,<a href="#ref-4CvJHFCU" role="doc-biblioref">62</a>,<a href="#ref-kVhMOlK2" role="doc-biblioref">63</a>,<a href="#ref-I1iOQSFC" role="doc-biblioref">64</a>]</span>. These techniques could be further extended
in a multi-modal setting for clustering of cells into putative cell
types or cell states. Community-based benchmarking efforts in the
area of multi-modal data analysis could follow the paradigm of
the <a href="http://dreamchallenges.org/">DREAM Challenges</a>, with multi-modal
training data provided and test samples held out, in order to evaluate
the method submissions from participating groups.</p>
<!--
Mike: I will add the vignettes refs in a supp table and cross refer appropriately
[cross-validation analysis of the scNMT-seq dataset](https://mikelove.github.io/BIRSBIO2020.Benchmarking.CVmofa/)
was performed as part of the hackathon for this meeting using MOFA+ (Figure {@fig:benchmark}B).
-->
<h4 id="challenge-3-cross-validation-between-studies">Challenge 3: cross-validation between studies</h4>
<p>Our benchmarking hackathons have emphasized the need to access
external studies for methods assessment and validation, where either
the ground truth is based on biological knowledge of the system being
studied, or via high-quality control experiments where the ground truth
(e.g. cell type labels) are known (Figure <a href="#fig:benchmark">5</a>A).
To take advantage of all data and technologies available, cross-study
validation could also extend to cross-platform to assess whether
relationships discovered in one dataset are present in other datasets,
such as looking across single-cell and bulk omics, as was recently proposed in <span class="citation" data-cites="1DuDJywpg">[<a href="#ref-1DuDJywpg" role="doc-biblioref">65</a>]</span>.</p>
<p><a name="software-section"></a></p>
<h2 id="software-strategies-to-enable-analyses-of-multimodal-single-cell-experiments">Software strategies to enable analyses of multimodal single-cell experiments</h2>
<p>Open-source software is essential in bioinformatics and computational biology. Benchmark datasets, analysis pipelines, and the development of multimodal genome-scale experiments are all enabled through community-developed, open-source software, and data sharing platforms. A wide array of genomics frameworks for multi-platform single-cell data have been developed in R and Python. Along with other software, these frameworks use standardized licensing in Creative Commons, Artistic, or GNU so that all components are accessible for full vetting by the community. Our hackathons hinged on the central challenges such as widescale adoption, extension, and collaboration to enable inference and visualization of the multimodal single-cell experiments in our analytic frameworks. We designed each case study to leverage and build on these open frameworks to further develop and evaluate robust benchmarking strategies. Easy to use data packages to distribute the multi-omics data and reproducible vignettes were key outputs from our workshop.</p>
<h4 id="collaboration-enabled-through-continuous-integration">Collaboration enabled through continuous integration</h4>
<p>Open-source software efforts facilitate a community-level coordinated approach to support collaboration rather than duplication of effort between groups working on similar problems. Real-time improvements to the tool-set should be feasible, respecting the needs for stability, reliability, and continuity of access to evolving components. To that end, exploration and engagement with all these tools is richly enabled through code sharing resources. Our hackathons directly leveraged through GitHub with our <a href="https://github.com/BIRSBiointegration/Hackathon/blob/master/analysis-vignettes.md">reproducible analyses reports</a> to enable continuous integration of changes to source codes (using Github Action), and containerized snapshots of the analyses environments. The hackathons analyses conducted in R were assembled into R packages to facilitate libraries loading, while those conducted in Python enabled automatic installation and deployment
<!--(using https://github.com/fastai/fastpages).--></p>
<h4 id="usability-and-adoption-by-the-community">Usability and adoption by the community</h4>
<p>Robust software ecosystems are required to build broad user bases <span class="citation" data-cites="dwXJ9SC4 102RKxFFz 14np73aSU">[<a href="#ref-dwXJ9SC4" role="doc-biblioref">66</a>,<a href="#ref-102RKxFFz" role="doc-biblioref">67</a>,<a href="#ref-14np73aSU" role="doc-biblioref">68</a>]</span>. Bioconductor is one example of such ecosystem, that provides multiplatform and continuous delivery of contributed software while assisting a wide range of users with standardized documentation, tests, community forums, and workshops <span class="citation" data-cites="E7tdylV2 oRTa5zGU SkTqlnmn">[<a href="#ref-E7tdylV2" role="doc-biblioref">69</a>,<a href="#ref-oRTa5zGU" role="doc-biblioref">70</a>,<a href="#ref-SkTqlnmn" role="doc-biblioref">71</a>]</span>. In the case of the hackathons, the R/Bioconductor ecosystem for multi-omics enabled data structures and vignettes to support reproducible, open-source, open development analysis. During this workshop, we identified key software goals needed to advance the methods and interpretation of multi-omics.</p>
<!-- consider removing
The hackathons highlighted central challenges that require further community-level software development, in particular: 
* The management of multimodal single-cell data for interactive and batch analyses,
* The development of software infrastructure to support scalable solutions for multimodal single-cell analysis,
* The implementation of robust visualization methods for multimodal single-cell analysis and ensure their accessibility to researchers with visual impairments?
-->
<!--A wide array of open-source genomics frameworks for multi-platform single-cell data are also developing in R, Python, and in other software frameworks that enable graphical user interfaces for point-and-click exploration. We take it for granted that __openness__ is a _sine qua non_ for computational tooling in 
bioinformatics.  This widespread availability, combined with standardized licensing
in Creative Commons, Artistic, or GNU frameworks enables all components need to be accessible for full vetting by the community, thereby facilitating widescale adoption, extension, and collaboration. 
These open source software efforts also facilitate a community-level __coordinated approach__,
to support collaboration rather than duplication of effort between groups working on similar problems. Real-time improvements to the tool-set should
be feasible, respecting the needs for stability, reliability, and continuity of access to evolving components. To that end, exploration and engagement with all these tools is richly enabled through code sharing resources like GitHub. Our hackathons directly leveraged such code sharing through GitHub, with contributed analyses reports [https://github.com/BIRSBiointegration/Hackathon/blob/master/analysis-vignettes.md] compiled into reproducible workflows [using GitHub Actions] enabling continuous integration of changes to source codes and continuous delivery of vignettes as well as containerized snapshots of the analyses environments. For challenge studies conducted in R, the source code and vignettes were assembled into R packages, which took the loaded libraries as dependencies. For those carried out in Python, the requirements were included in the source files for automatic installation and deployment[using https://github.com/fastai/fastpages].
-->
<!-- 
While GitHub enables code distribution and accessibility, it does not address issues of useability or adoption. The open-source and community needs for multi-omics go beyond code sharing and ultimately addressed through robust software ecosystems [@doi:10.1126/science.aaf6162; @https://chaoss.github.io/grimoirelab/; @http://ceur-ws.org/Vol-987/3.pdf]. As an example of an ecosystem of broad scope, we cite bioconductor.org [@https://bioconductor.org].  Bioconductor supports developers who seek to build broad user bases by providing multiplatform/multistream continuous integration/continuous delivery of contributed packages [@https://bioconductor.org/checkResults/], and users with different skill sets by articulating standards for documentation, and testing, and by hosting community forums and workshops [@https://bioconductor.org/support/]. In the case of the hackathons, the R/Bioconductor ecosystem for multi-omics enabled data structures and vignettes to support reproducible, open-source, open development analysis. The further community engagement and communication from the workshop were critical to identify additional key software goals needed to advance the methods and interpretation of multi-omics. 
-->
<!-- In this section, we reflect on the software infrastructure that enabled our analytic frameworks for inference and visualization of the multimodal single-cell experiments. Notably, the hackathons highlighted the following central challenges that require further community-level software development. 
* How should multimodal single-cell data be managed for interactive and batch analyses?
* What methods will help software developers create scalable solutions for multimodal single-cell analysis?
* How can we implement robust visualization methods for multimodal single-cell analysis and ensure their accessibility to researchers with visual impairments?
-->
<h3 id="challenge-1-data-accessibility">Challenge 1: data accessibility</h3>
<p>Providing data to the scientific community is a long-standing issue. A particular challenge in our hackathons was that each data modality was characterized by a different collection of features from possibly non-overlapping collections of samples (see <a href="#common-challenges-section">common challenges</a> section). Thus, common data structures are needed to store and operate on these data collections, and support data dissemination with robust metadata and implementation of analytical frameworks.</p>
<p>The <code>MultiAssayExperiment</code> integrative data class from Bioconductor was our class of choice to enable the collation of standard data formats, easy data access, and processing. It uses the S4 object-oriented structure in R <span class="citation" data-cites="mlBLKi3Y gdnUpsQo">[<a href="#ref-mlBLKi3Y" role="doc-biblioref">72</a>,<a href="#ref-gdnUpsQo" role="doc-biblioref">73</a>]</span> and includes several features to support multi-platform genomics data analysis, to store features from multiple data modalities (e.g. gene expression units from scRNA-seq and protein units in sc-proteomics) from either the same or distinct cells, biological specimen of origin, or from multiple dimensions (e.g. spatial coordinates, locations of eQTLs). This class also enables to store sample metadata (e.g. study, center, phenotype, perturbation) and provides a map between the datasets from different assays for downstream analysis.</p>
<!--
questions still unanswered from Elana / Vince
Is this a unique storage feature of Bioconductor or is there something comparable in python or other bioinformatics ecosystems that we should discuss as well to be comprehensive?
-->
<p>In our hackathons, pre-processing steps applied to the raw data were fully documented. The input data were stored as <code>MultiAssayExperiment</code> objects that were centrally managed and hosted on <code>ExperimentHub</code><span class="citation" data-cites="12geyVA4y">[<a href="#ref-12geyVA4y" role="doc-biblioref">74</a>]</span> as a starting point for all analyses. The <code>SingleCellMultiModal</code> package was used to query the relevant datasets for each analysis [doi:10.18129/B9.bioc.SingleCellMultiModal] (Figure <a href="#fig:spatialExpt">6</a>). Text-based machine-readable data were also made available for non-R users, and also to facilitate alternative data preprocessing for participants.</p>
<!--Aedin, could you please check me that this is what you meant to say by "At the moment, it includes the hackathons scNMT-seq and the seqFISH+scRNA-seq (Fig. {@fig:spatialExpt}) datasets, easily stored because of the samples overlapping between multiple modalities, while we are working on the integration of the scProteomics dataset which has no overlap between samples."
-->
<p>Besides efficient data storage, several hackathon contributors used the <code>MultiAssayExperiment</code> class to implement further data processing and extraction of spatial information from raster objects in their analyses. This infrastructure was readily suitable for the spatial and scNMT-seq hackathons but the lack of overlap between samples in the spatial proteomics hackathon revealed an important area of future work to link biologically related datasets without direct feature or sample mappings for multi-omics analysis. Further, our hackathons highlighted the need for scalability of storing and efficiently retrieving single-cell data datasets <span class="citation" data-cites="KhbsUBNe mOp2pMsC">[<a href="#ref-KhbsUBNe" role="doc-biblioref">75</a>,<a href="#ref-mOp2pMsC" role="doc-biblioref">76</a>]</span>. New algorithms are emerging, that allow for data to be stored in memory or on disk (e.g. <span class="citation" data-cites="g9O7LIML 19jAJjD6o">[<a href="#ref-g9O7LIML" role="doc-biblioref">77</a>,<a href="#ref-19jAJjD6o" role="doc-biblioref">78</a>]</span> in R or <span class="citation" data-cites="qIZTS1II">[<a href="#ref-qIZTS1II" role="doc-biblioref">79</a>]</span> in Python).</p>
<!-- Note from Kim-Anh
This line 50 does not flow very well, should it be included elsewhere?
-->
<div id="fig:spatialExpt" class="fignos">
<figure>
<img src="images/MSA_SpE.png" style="width:50.0%" alt="" /><figcaption><span>Figure 6:</span> </figcaption>
</figure>
</div>
<p>Caption figure: <strong>A</strong> Software infrastructure using Bioconductor for the first hackathon to combine seqFISH-based <code>SpatialExperiment</code> and <code>SingleCellExperiment</code> instances into a <code>MultiAssayExperiment</code>. <strong>B</strong> To combine these two different experiments, the seqFISH data were stored into a <code>SpatialExperiment</code> S4 class object, while the scRNA-seq data were stored into a <code>SingleCellExperiment</code> class object <span class="citation" data-cites="R7sfk7Aq">[<a href="#ref-R7sfk7Aq" role="doc-biblioref">80</a>]</span>. These objects were then stored into a <code>MultiAssayExperiment</code> class object and released with the <code>SingleCellMultiModal</code> Bioconductor package <span class="citation" data-cites="doi:10.18129/B9.bioc.SingleCellMultiModal">[<span class="citeproc-not-found" data-reference-id="doi:10.18129/B9.bioc.SingleCellMultiModal"><strong>???</strong></span>]</span>.</p>
<!--
Common data structures to store and operate on these data collections can support data dissemination with robust metadata and implementation of the common analysis frameworks for multi-omics data interpretation that can be employed across diverse measurement technologies. As an example, Bioconductor has built a ready-to-use integrative data class `MultiAssayExperiment` on the S4 object oriented structure in R [@doi:10.1158/0008-5472.CAN-17-0344]. The `MultiAssayExperiment` class includes the following features to support multi-platform genomics data analysis
   1) Storage for variables or features from multiple data modalities (e.g. gene expression units from scRNA-seq and protein units in sc-proteomics), either from the same cells or distinct cells from the same or distinct starting samples or biological specimen of origin. In some cases, the feature may be multidimensional (e.g. spatial coordinates, locations of eQTLs).  
   2) Metadata for sample of origin for the individual cells, e.g. study, center, phenotype, perturbation, in all the variables or features stored.
   3) A map between the datasets from the different assays to enable analysis.
-->
<!-- I removed this part (Kim-Anh)
The `MultiAssayExperiment` class is designed so that the variables or features stored for each assay in `MultiAssayExperiment` each independently use Bioconductor data structures for the stored data modality and bind metadata annotating the molecular features for each assay into this class instance. For example,
genes and transcripts can be enumerated using gene labels from Ensembl [@doi:10.1093/nar/gkz966] as catalog identifiers, represented as
genomic regions through `GRanges` instances [@doi:10.1371/journal.pcbi.1003118], etc.  
-->
<!-- I reedited this part and included in caption
In our context, input data across all hackathons were pre-processed with steps documented, and the data were stored in `MultiAssayExperiment` [@doi:10.18129/B9.bioc.MultiAssayExperiment] objects which allows collating of standard data formats as well as powerful data access and data processing methods. The datasets were centrally managed and hosted on `ExperimentHub`[@doi:10.18129/B9.bioc.ExperimentHub] and the `SingleCellMultiModal` package [doi:10.18129/B9.bioc.SingleCellMultiModal] was used to query the relevant datasets for each analysis. Figure {@fig:spatialExpt} shows how this
class was used to amalgamate and annotate the multimodal dataset consisting of seqFISH and scRNA-seq experimental data employed for this first hackathon.
To combine these two different experiments, the seqFISH data were stored into the SpatialExperiment S4 class object, while the scRNA-seq data were stored into a SingleCellExperiment Bioconductor class object [@doi:10.18129/B9.bioc.SingleCellExperiment]. 
Then, these objects were easily stored into a MultiAssayExperiment class object and released with the SingleCellMultiModal Bioconductor package [@doi:10.18129/B9.bioc.SingleCellMultiModal]. 
<!-- In our hackathon context, we considered multi-assay measurements from the same cell (e.g. scNMT-seq) or integration of multi-assay measurements from  (seqFish, scProteomics).
-->
<h3 id="challenge-2-software-infrastructure-to-handle-assay-specific-features">Challenge 2: software infrastructure to handle assay-specific features</h3>
<p>The hackathons further highlighted emerging challenges to handle different data modalities.</p>
<p>RNA-seq has well-defined units and IDs (e.g., transcript names), but other assays need to be summarized at different genomic scales (e.g., gene promoters, exons, introns, or gene bodies), as was highlighted in the scNMT-seq hackathon. Tools such as the <code>GenomicRanges</code> R package <span class="citation" data-cites="1FbF6M2UI">[<a href="#ref-1FbF6M2UI" role="doc-biblioref">81</a>]</span> have been proposed to compute summaries at different scales and overlaps between signal (e.g., ATAC-seq peaks) and genomic annotation.</p>
<p>Further, the observations of different modalities may not be directly comparable: for instance, gene expression may be measured from individual cells in single-cell RNA-seq, but spatial transcriptomics may have a finer (sub-cellular) or coarser (multi-cellular) resolution. Methods such as SPOTlight <span class="citation" data-cites="wrQUNea">[<a href="#ref-wrQUNea" role="doc-biblioref">82</a>]</span> can be used to deconvolute multi-cellular spots signal.</p>
<p>Finally, in the absence of universal standards, the metadata available may vary from modalities, or independent studies (e.g. spatial proteomics), thus urging the need from the computational biology community to define the minimum set of metadata variables necessary for each assay, as well as for pairs of assays to be comparable for common analyses.</p>
<!--Is this problem solved through the multiAssayExperiment and/or broader Bioconductor ecosystem? If so how and if not what are areas of future work needed as a field.-->
<h3 id="challenge-3-accessible-vizualization">Challenge 3: accessible vizualization</h3>
<p>Our brainstorm discussions on the <a href="#challenges-interp-section">Data Interpretation Challenge</a> highlighted the importance of novel data visualization strategies to make sens of multi-modal data analyses. Often, these visualization strategies rely on heatmaps or reduced dimension plots, and utilize color to represent the different dimensions. These colors and low dimensional plots facilitate pattern detection and interpretation of increasingly complex and rich data. However, relying on color for interpretation leads to difficulties in perceiving patterns for a substantial proportion of the population with color vision deficiencies and can result in different data interpretations between individuals.</p>
<!--
(the basis for the Ishihara's color vision tests) in multi-colored figures Moreover, relying on perceived patterns through color can result in different data interpretations between individuals, particularly reflecting their individual color detection capacities. 
-->
<p>Presenting accessible scientific information requires the inclusion of colorblind friendly visualizations <span class="citation" data-cites="11uDSb0Nf Ecm3XS4">[<a href="#ref-11uDSb0Nf" role="doc-biblioref">83</a>,<a href="#ref-Ecm3XS4" role="doc-biblioref">84</a>]</span> standardized as default settings through use of color palettes such as R/viridis <span class="citation" data-cites="lLv68Zzx">[<a href="#ref-lLv68Zzx" role="doc-biblioref">85</a>]</span> and dittoSeq <span class="citation" data-cites="doi:10.18129/B9.bioc.dittoSeq">[<span class="citeproc-not-found" data-reference-id="doi:10.18129/B9.bioc.dittoSeq"><strong>???</strong></span>]</span> with a limit of 10 colors. Additional visual cues to differentiate regions or cells can also reduce the dependence on colors using hatched areas or point shapes. The inclusion an “accessibility caption” accompanying figures which to guide the reader’s perception of the images would also greatly benefit broader data accessibility. Thus, implementing community standards for accessible visualizations is essential for bioinformatics software communities to ensure standardized interpretation of multi-platform single-cell data.</p>
<!-- Overall, a broader discussion regarding the accessibility of our figures that is not just limited to color vision deficiencies would be greatly beneficial towards improving data accessibility.
Perhaps one tool to address broader accessibility could be
[US Government tools for accessibility](https://accessibility.18f.gov/tools/)
-->
<!--### Details of working components
you can interact with underlying data at [google sheet](https://docs.google.com/spreadsheets/d/1tSUQ9iDKqq72TB9G3Cx1evg2sekS-ytx5wRXDv6vxfg/edit?usp=sharing)
-->
<table>
<colgroup>
<col style="width: 12%" />
<col style="width: 53%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Brief name (link)</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Matlab package</td>
<td><a href="https://gitlab.com/gernerlab/cytomap">CytoMAP</a></td>
<td>CytoMAP: A Spatial Analysis Toolbox Reveals Features of Myeloid Cell Organization in Lymphoid Tissues</td>
</tr>
<tr class="even">
<td>Matlab package</td>
<td><a href="https://github.com/BodenmillerGroup/histoCAT">histoCAT</a></td>
<td>histoCAT: analysis of cell phenotypes and interactions in multiplex image cytometry data</td>
</tr>
<tr class="odd">
<td>Python library</td>
<td><a href="https://pytorch.org">PyTorch</a></td>
<td>General framework for deep learning</td>
</tr>
<tr class="even">
<td>Python package</td>
<td><a href="https://github.com/BiomedicalMachineLearning/SpaCell">SpaCell</a></td>
<td>SpaCell: integrating tissue morphology and spatial gene expression to predict disease cells</td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/theislab/scanpy">Scanpy</a></td>
<td>Python package for single cell analysis</td>
</tr>
<tr class="even">
<td>R data class</td>
<td><a href="https://bioconductor.org/packages/MultiAssayExperiment">MultiAssayExperiment</a></td>
<td>unify multiple experiments</td>
</tr>
<tr class="odd">
<td>R data class</td>
<td><a href="https://github.com/drighelli/SpatialExperiment">SpatialExperiment</a></td>
<td>SpatialExperiment: a collection of S4 classes for Spatial Data</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/RubD/Giotto">Giotto</a></td>
<td>Spatial transcriptomics</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://github.com/BodenmillerGroup/cytomapper">cytomapper</a></td>
<td>cytomapper: Visualization of highly multiplexed imaging cytometry data in R</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/RachelQueen1/Spaniel/">Spaniel</a></td>
<td>Spaniel: analysis and interactive sharing of Spatial Transcriptomics data</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://github.com/satijalab/seurat">Seurat</a></td>
<td>R toolkit for single cell genomics</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/LieberInstitute/spatialLIBD">SpatialLIBD</a></td>
<td>Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://cardinalmsi.org/">Cardinal</a></td>
<td>Cardinal: an R package for statistical analysis of mass spectrometry-based imaging experiments</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/FertigLab/CoGAPS">CoGAPS</a></td>
<td>scCoGAPS learns biologically meaningful latent spaces from sparse scRNA-Seq data</td>
</tr>
<tr class="odd">
<td>R package</td>
<td><a href="https://github.com/genesofeve/projectR">projectR</a></td>
<td>ProjectR is a transfer learning framework to rapidly explore latent spaces across independent datasets</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/waldronlab/SingleCellMultiModal">SingleCellMultiModal</a></td>
<td>Serves multiple datasets obtained from GEO and other sources and represents them as MultiAssayExperiment objects</td>
</tr>
<tr class="odd">
<td>R scripts</td>
<td><a href="https://github.com/drighelli/SpatialAnalysis">SpatialAnalysis</a></td>
<td>Scripts for SpatialExperiment usage</td>
</tr>
<tr class="even">
<td>Self-contained GUI</td>
<td><a href="https://github.com/jfnavarro/st_viewer">ST viewer</a></td>
<td>ST viewer: a tool for analysis and visualization of spatial transcriptomics datasets</td>
</tr>
<tr class="odd">
<td>Shiny app</td>
<td><a href="https://zouter.shinyapps.io/server/">Dynverse</a></td>
<td>A comparison of single-cell trajectory inference methods: towards more accurate and robust tools</td>
</tr>
<tr class="even">
<td>R package</td>
<td><a href="https://github.com/mixOmicsTeam/mixOmics">mixOmics</a></td>
<td>R toolkit for multivariate analysis of multi-modal data</td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/YosefLab/scVI">totalVI</a></td>
<td>A variational autoencoder (deep learning model) to integrate RNA and protein data from CITE-seq experiments</td>
</tr>
<tr class="even">
<td>Python web application</td>
<td></td>
<td><a href="https://imjoy.io/#/">ImJoy</a></td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/napari/napari">napari</a></td>
<td>Interactive big multi-dimensional 3D image viewer</td>
</tr>
<tr class="even">
<td>Software</td>
<td><a href="https://qupath.github.io/">QuPath</a></td>
<td>Multiplex whole slide image analysis</td>
</tr>
<tr class="odd">
<td>Python package</td>
<td><a href="https://github.com/hammerlab/cytokit">Cytokit</a></td>
<td>Multiplex whole slide image analysis</td>
</tr>
<tr class="even">
<td>Python package</td>
<td><a href="https://gitlab.com/engje/cmif">cmIF</a></td>
<td>Multiplex whole slide image analysis</td>
</tr>
<tr class="odd">
<td>Software</td>
<td><a href="https://github.com/kruegert/facetto">Facetto</a></td>
<td>Multiplex whole slide image analysis, not available yet</td>
</tr>
<tr class="even">
<td>Software, Python based</td>
<td><a href="https://cellprofiler.org/">CellProfiler</a></td>
<td>Image analysis</td>
</tr>
</tbody>
</table>
<h2 id="discussion">Discussion</h2>
<p>The Mathematical Frameworks for Integrative Analysis of Emerging Biological Data Workshop demonstrated the power of hackathons to both inform and develop new analysis methods to capture the complex, multi-scale nature of biological datasets from high-throughput data modalities. Notably, the hackathon studies of the workshop were specifically designed to span state-of-the-art multi-omics challenges to map the epigenetic, molecular, and cellular interaction across time and sample populations. Single-cell measurements spanning molecular modalities can inherently simplify the challenge of linking disparate biological scales, but layering new sets of molecular measurements increases the complexity of the analyses to interpret these data. The computational needs hinge on the underlying biological question being asked as well as the characteristics of the data themselves. In our workshop, different modelling considerations had to be made for multi-modal integration, as higlighted in the seqFISH and scNMT-seq challenges (matching on the same genes, or cells) and the scProteomics challenge (partially unmatched measurements). Regardless, through these hackathons we identified several common analysis themes spanning algorithmic advances, interpretation, benchmarking, and software infrastructure necessary for biological interpretation. All hackathons required methods for dealing with data quality, data loss from summarization, timing variances between and within omics layers, and batch effects. These represent the necessary challenges to overcome in the coming years, along with efficient and insightful data visualization strategies to infer regulatory relationships between different omics.</p>
<p>Technologies to profile biological systems at single-cell resolution and across molecular scales are advancing at an unprecedented pace. Analytically, these advances require the computational community to pursue research that can first enable robust analyses tailored to a specific biology or measurement technology, and second, that can scale and adapt to these rapid advances. Our hackathons highlighted current technologies for spatial molecular profiling. The two technologies used in this study both have limited molecular resolution. Therefore, multi-platform data combining the spatial molecular data from either seqFISH, MIBI, or imaging mass cytometry require complementary data from other single-cell technologies to provide both high spatial and molecular resolution enabled through data integration. We note that additional technologies, such as slide-seq <span class="citation" data-cites="kuQ9iKB8">[<a href="#ref-kuQ9iKB8" role="doc-biblioref">86</a>]</span> and Visium from 10X Genomics produce spatially resolved molecular measurements approaching measurements of the whole transcriptome, but lack the fine spatial resolution of these alternative imaging technologies. As such, emerging technologies still require further multi-platform data integration for comprehensive analysis.
The scNMT-seq challenge did not include spatially resolved data but highlighted the potential of further inference of gene regulation through concurrent profiling of RNA, methylation, and chromatin state. Technological advances for multi-omics spatial data and epigenetics data are rapidly advancing and becoming increasingly available through Nanostring, 10X Genomics, Akoya Biosciences, and others. Our workshop keynote Bernd Bodenmiller presented new research-level technological advances that enable three-dimensional spatial molecular profiling <span class="citation" data-cites="11JyGlUPl">[<a href="#ref-11JyGlUPl" role="doc-biblioref">87</a>]</span>. Other technologies are currently expanding to allow for temporally resolved profiling <span class="citation" data-cites="12q1TKAaX">[<a href="#ref-12q1TKAaX" role="doc-biblioref">88</a>]</span>. Integration strategies aware of these future directions and the mathematical challenges that span technologies will be most adept at advancing biological knowledge: this was the primary aim of this workshop.</p>
<p>The implementation of novel analysis tools requires further robust software ecosystems, including Bioconductor <span class="citation" data-cites="z8JnDHpr">[<a href="#ref-z8JnDHpr" role="doc-biblioref">89</a>]</span>, Biopython, and toolkits such as Scanpy <span class="citation" data-cites="qIZTS1II">[<a href="#ref-qIZTS1II" role="doc-biblioref">79</a>]</span>, Seurat <span class="citation" data-cites="lNBJZodk">[<a href="#ref-lNBJZodk" role="doc-biblioref">90</a>]</span>, or Giotto <span class="citation" data-cites="1HWhMi97j">[<a href="#ref-1HWhMi97j" role="doc-biblioref">10</a>]</span>, in which users can create their analysis approaches and while anticipating stable and adaptive data structures robust for these emerging technologies. The size of these emerging datasets, particularly in the context of their application to atlas projects (e.g. the Human Tumor Atlas Network <span class="citation" data-cites="udPM4KR1">[<a href="#ref-udPM4KR1" role="doc-biblioref">91</a>]</span>, Human Cell Atlas <span class="citation" data-cites="vk9ZInF3">[<a href="#ref-vk9ZInF3" role="doc-biblioref">92</a>]</span>, Allen Brain Initiative or ENCODE, to cite a few) are key examples that computational efficiency and scalability of these implementations are becoming ever more critical.
&lt;!–are there others or citations I should be using for this?–!&gt;</p>
<p>In addition to new technologies, we wish to emphasize that arising multi-omics analysis methods can support the generation of new data sources to resolve the multi-scale nature of biological systems. For example, while the workshop posed the scNMT-seq data and spatial molecular datasets as distinct challenges for data integration, integration of matched datasets between these spatial and epigenetic profiling techniques could further resolve the dependence of cell-type and cellular-interactions of regulatory networks. By embedding prior biological knowledge as rules in the analysis approaches, additional sources of data can generate a new representation of a biological system. For example, curated regulatory networks from databases such as KEGG, Biocarta, GO, or MSigDB
&lt;!– are there more resources and add citations–!&gt; provide commonly used frameworks for this prior knowledge. These gene regulatory networks must be extended to map the impact of cellular context on transcriptional regulation that are being uncovered by emerging single-cell atlases. The regulatory networks and dynamic features captured in single-cell data also provide the potential for future techniques to predict molecular and cellular states. Our hackathons and workshop have shown that merging single-cell data with mathematical models have the potential to predict behaviors in biological systems using rules derived from only prior biological knowledge.</p>
<h2 id="vignettes">Vignettes</h2>
<table>
<colgroup>
<col style="width: 14%" />
<col style="width: 25%" />
<col style="width: 20%" />
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 12%" />
</colgroup>
<thead>
<tr class="header">
<th>Hackathon</th>
<th>Participant</th>
<th>Title</th>
<th>Language</th>
<th>Vignette</th>
<th>Additional info</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>scNMTseq</td>
<td>Al JalalAbadi</td>
<td><a href="https://github.com/ajabadi/BIRSBIO2020.scNMTseq.PLS">PLS</a></td>
<td>R</td>
<td><a href="https://ajabadi.github.io/BIRSBIO2020.scNMTseq.PLS/articles">Vignette</a></td>
<td><a href="https://hub.docker.com/repository/docker/aljabadi/birs_bio_2020-scnmtseq-pls">Docker</a></td>
</tr>
<tr class="even">
<td>scNMTseq</td>
<td>Wancen Mu and Michael Love</td>
<td><a href="https://github.com/mikelove/BIRSBIO2020.Benchmarking.CVmofa">CV-MOFA</a></td>
<td>R</td>
<td><a href="https://mikelove.github.io/BIRSBIO2020.Benchmarking.CVmofa/articles/MOFA-scNMTseq.html">Vignette</a></td>
<td><a href="https://hub.docker.com/repository/docker/aljabadi/birs_bio_2020-benchmarking-cv_mofa">Docker</a></td>
</tr>
<tr class="odd">
<td>scNMTseq</td>
<td>Josh Welch</td>
<td><a href="https://github.com/jw156605/BIRSBIO2020.scNMTseq.LIGER">LIGER analysis of scNMT-seq</a></td>
<td>R</td>
<td><a href="https://jw156605.github.io/BIRSBIO2020.scNMTseq.LIGER/articles/scNMT_liger.html">Vignette</a></td>
<td><a href="https://hub.docker.com/r/joshuawd/birsbio2020_scnmtseq_liger">Docker</a></td>
</tr>
<tr class="even">
<td>scNMTseq</td>
<td>Arshi Arora</td>
<td><a href="https://github.com/arorarshi/BIRSBIO2020.scNMTseq.MOSAIC">MOSAIC analysis of scNMT-seq</a></td>
<td>R</td>
<td><a href="https://arorarshi.github.io/BIRSBIO2020.scNMTseq.MOSAIC/articles">Vignette</a></td>
<td><a href="https://hub.docker.com/repository/docker/arorarshi/birs_bio_2020-scnmtseq-mosaic">Docker</a></td>
</tr>
<tr class="odd">
<td>scProteomics</td>
<td>Lauren Hsu</td>
<td><a href="https://github.com/laurenhsu1/BIRSBIO2020.scProteomics.exploratory">Exploratory analyses</a></td>
<td>R</td>
<td><a href="https://laurenhsu1.github.io/BIRSBIO2020.scProteomics.exploratory/articles">Vignette</a></td>
<td><a href="https://hub.docker.com/repository/docker/laurenhsu/birsbio2020_scproteomics_exploratory">Docker</a></td>
</tr>
<tr class="even">
<td>scProteomics</td>
<td>Chen Meng</td>
<td><a href="https://github.com/mengchen18/BIRSBIO2020.scProteomics.predictPartialOverlappingData">Predicting partially overlapping data</a></td>
<td>R</td>
<td><a href="https://mengchen18.github.io/BIRSBIO2020.scProteomics.predictPartialOverlappingData/articles/predictPartialOverlapData.html">Vignette</a></td>
<td></td>
</tr>
<tr class="odd">
<td>scProteomics</td>
<td>Pratheepa Jeganathan</td>
<td><a href="https://github.com/PratheepaJ/BIRSBIO2020scProteomicsLDA">Latent Dirichlet Allocation</a></td>
<td>R</td>
<td><a href="https://pratheepaj.github.io/BIRSBIO2020scProteomicsLDA/articles">Vignette</a></td>
<td></td>
</tr>
<tr class="even">
<td>scProteomics</td>
<td>Yingxin Lin</td>
<td><a href="https://github.com/YingxinLin/BIRSBIO2020.scProteomics.survival">Integrative analysis of breast cancer survival based on spatial features</a></td>
<td>R</td>
<td><a href="https://yingxinlin.github.io/BIRSBIO2020.scProteomics.survival/index.html">Vignette</a></td>
<td><a href="https://hub.docker.com/repository/docker/yingxinlin/scproteomics">Docker</a></td>
</tr>
<tr class="odd">
<td>scSpatial</td>
<td>Alexis Coullomb</td>
<td><a href="https://github.com/AlexCoul/BIRSBIO2020.seqFISH.neighbors_aggregation">Neighbours Aggregtion</a></td>
<td>Python</td>
<td><a href="https://alexcoul.github.io/BIRSBIO2020.seqFISH.neighbors_aggregation/spatial%20analysis/transcriptomics/2020/07/15/BIRS_Biointegration-seqFISH_challenge-neighbors_aggregation.html">Vignette</a></td>
<td></td>
</tr>
<tr class="even">
<td>scSpatial</td>
<td>Joshua Sodicoff</td>
<td><a href="https://github.com/jsodicoff/BIRSBIO2020.seqFISH.LIGERintegration">Utilizing LIGER for the integration of spatial transcriptomic data</a></td>
<td>R</td>
<td><a href="https://jsodicoff.github.io/BIRSBIO2020.seqFISH.LIGERintegration/articles">Vignette</a></td>
<td><a href="https://hub.docker.com/r/sodicoff/birsbio2020.seqfish.liger_int">Docker</a></td>
</tr>
<tr class="odd">
<td>scSpatial</td>
<td>Dario Righelli</td>
<td><a href="https://github.com/drighelli/BIRSBIO2020.seqFISH.SpatialAnalysis">SpatialExperiment Analysis</a></td>
<td>R</td>
<td><a href="https://drighelli.github.io/BIRSBIO2020.seqFISH.SpatialAnalysis/articles">Vignette</a></td>
<td><a href="https://hub.docker.com/r/drighelli/birsbio2020_seqfish_spatialanalysis">Docker</a></td>
</tr>
<tr class="even">
<td>scSpatial</td>
<td>Amrit Singh</td>
<td><a href="https://github.com/singha53/BIRSBIO2020.seqFISH.SSEnet">seqFISH+scRNASeq integration using semi-supervised glmnet</a></td>
<td>R</td>
<td><a href="https://singha53.github.io/BIRSBIO2020.seqFISH.SSEnet/articles">Vignette</a></td>
<td><a href="https://hub.docker.com/repository/docker/singha53/birsbio2020_seqfish_ssenet">Docker</a></td>
</tr>
<tr class="odd">
<td>scSpatial</td>
<td>Hang Xu</td>
<td><a href="https://github.com/gooday23/BIRSBIO2020.seqFISHChallenge.geneSeletction">Cortex seq-FISH + scRNA data - gene selection</a></td>
<td>Python</td>
<td><a href="https://gooday23.github.io/BIRSBIO2020.seqFISHChallenge.geneSeletction/seqfish/scrna/2020/07/20/BIRS_Biointegration-seqFish_challenge-geneselection.html">Vignette</a></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="glossary">Glossary</h2>
<div id="tbl:table_gloss" class="tablenos">
<table>
<caption><span>Table 1:</span> Glossary of interchangeable terms in the field of single-cell and bulk multi-omics (multi-source) data analysis. </caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>Consensus Term</th>
<th>Related Terms</th>
<th>Description</th>
<th>Citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>network</td>
<td>graph, adjacency matrix</td>
<td>A set of <em>nodes</em>, representing objects of interest, linked by <em>edges</em>, representing specific relationships between nodes.</td>
<td>?</td>
</tr>
<tr class="even">
<td>node</td>
<td>vertex</td>
<td>Element of interest in a network and linked to other nodes. For example: people, cells, proteins or genes. Nodes can have several properties called <em>attributes</em> like cell type or position.</td>
<td>?</td>
</tr>
<tr class="odd">
<td>edge</td>
<td>link</td>
<td>The relationship between 2 nodes in a network. For example: friendship in social networks, cells in contact in a spatial network, or gene-gene interactions in a gene regulatory network.</td>
<td>?</td>
</tr>
<tr class="even">
<td>concordant</td>
<td>concordant, coherent, consistent</td>
<td>?</td>
<td><span class="citation" data-cites="IZfv7up4"><a href="#ref-IZfv7up4" role="doc-biblioref">61</a></span></td>
</tr>
<tr class="odd">
<td>contributions</td>
<td>variable weights, loadings, eigenvector, axis, direction, dimension, coefficients, slopes</td>
<td>Contributions of the original variables in constructing the components.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">24</a></span>, <span class="citation" data-cites="18fTyQGoG"><a href="#ref-18fTyQGoG" role="doc-biblioref">94</a></span></td>
</tr>
<tr class="even">
<td>latent factors</td>
<td>variates, scores, projections, components, latent/hidden/unobserved variables/factors</td>
<td>Weighted linear combinations of the original variables.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">24</a></span>, <span class="citation" data-cites="18fTyQGoG"><a href="#ref-18fTyQGoG" role="doc-biblioref">94</a></span></td>
</tr>
<tr class="odd">
<td>multimodal</td>
<td>Multiview, multiway arrays, multimodal, multidomain, multiblock, multitable, multi-omics, multi-source data analysis methods, N-integration</td>
<td>Methods pertaining to the analysis of multiple data matrices for the same set of observations.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">24</a></span>, <span class="citation" data-cites="nhuT45y5"><a href="#ref-nhuT45y5" role="doc-biblioref">36</a></span>, <span class="citation" data-cites="2SDWXiwB"><a href="#ref-2SDWXiwB" role="doc-biblioref">95</a></span></td>
</tr>
<tr class="even">
<td>conjoint analysis</td>
<td>conjoint analysis, P-integration, meta-analysis, multigroup data analysis</td>
<td>Methods pertaining to the analysis of multiple data matrices for the same set of variables.</td>
<td><span class="citation" data-cites="QSXGprag"><a href="#ref-QSXGprag" role="doc-biblioref">24</a></span>, <span class="citation" data-cites="18fTyQGoG"><a href="#ref-18fTyQGoG" role="doc-biblioref">94</a></span>, <span class="citation" data-cites="UqaGRGDg"><a href="#ref-UqaGRGDg" role="doc-biblioref">96</a></span></td>
</tr>
<tr class="odd">
<td>variable</td>
<td>feature, variable</td>
<td>A measurable quantity that describes an observation’s attributes. Variables from different modalities include age, sex, gene or protein abundance, single nucleotide variants, operational taxonomic units, pixel intensity <em>etc.</em></td>
<td>?</td>
</tr>
<tr class="even">
<td>biomarker</td>
<td>marker, biomarker</td>
<td>A variable that is associated with normal or disease processes, or responses to exposures, or interventions. Any change in this variable is also associated with a change in the associated clinical outcome. These variables may be used for diagnostic, monitoring, Pharmacodynamic responses. Examples include LDL cholesterol, CD4 counts, hemoglobin A1C.</td>
<td><span class="citation" data-cites="AtapBaNb"><a href="#ref-AtapBaNb" role="doc-biblioref">97</a></span></td>
</tr>
<tr class="odd">
<td>panel</td>
<td>biomarker panel, biomarker signature</td>
<td>A subset of the originally measured variables that are determined to be associated with the outcome or response variable. This may be determined using statistical inference, feature selection methods, or machine/statistical learning.</td>
<td><span class="citation" data-cites="17aD4MFPS"><a href="#ref-17aD4MFPS" role="doc-biblioref">98</a></span>, <span class="citation" data-cites="XWx8RAwW"><a href="#ref-XWx8RAwW" role="doc-biblioref">99</a></span></td>
</tr>
<tr class="even">
<td>observation</td>
<td>sample, observation, array</td>
<td>A single entity belonging to a larger grouping. Examples include patients, subjects, participants, cells, biological sample, usually the unit of observation on which the variables are measured <em>etc.</em></td>
<td>?</td>
</tr>
</tbody>
</table>
</div>
<h2 class="page_break_before" id="references-1">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-14mVWQABt">
<p>1. <strong>Method of the Year 2019: Single-cell multimodal omics</strong> <br />
Nature Methods<br />
(2020-01) <a href="https://www.nature.com/articles/s41592-019-0703-5">https://www.nature.com/articles/s41592-019-0703-5</a> <br />
DOI: <a href="https://doi.org/10.1038/s41592-019-0703-5">10.1038/s41592-019-0703-5</a></p>
</div>
<div id="ref-14LoEihpl">
<p>2. <strong>Adult mouse cortical cell taxonomy revealed by single cell transcriptomics</strong> <br />
Bosiljka Tasic, Vilas Menon, Thuc Nghi Nguyen, Tae Kyung Kim, Tim Jarsky, Zizhen Yao, Boaz Levi, Lucas T Gray, Staci A Sorensen, Tim Dolbeare, … Hongkui Zeng<br />
<em>Nature Neuroscience</em> (2016-01-04) <a href="https://doi.org/f778w5">https://doi.org/f778w5</a> <br />
DOI: <a href="https://doi.org/10.1038/nn.4216">10.1038/nn.4216</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26727548">26727548</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4985242">PMC4985242</a></p>
</div>
<div id="ref-13v18bjoF">
<p>3. <strong>Identification of spatially associated subpopulations by combining scRNAseq and sequential fluorescence in situ hybridization data</strong> <br />
Qian Zhu, Sheel Shah, Ruben Dries, Long Cai, Guo-Cheng Yuan<br />
<em>Nature Biotechnology</em> (2018-10-29) <a href="https://doi.org/gfgn8x">https://doi.org/gfgn8x</a> <br />
DOI: <a href="https://doi.org/10.1038/nbt.4260">10.1038/nbt.4260</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30371680">30371680</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6488461">PMC6488461</a></p>
</div>
<div id="ref-bJBIpCn7">
<p>4. <strong>A Single-Cell Atlas of the Tumor and Immune Ecosystem of Human Breast Cancer</strong> <br />
Johanna Wagner, Maria Anna Rapsomaniki, Stéphane Chevrier, Tobias Anzeneder, Claus Langwieder, August Dykgers, Martin Rees, Annette Ramaswamy, Simone Muenst, Savas Deniz Soysal, … Bernd Bodenmiller<br />
<em>Cell</em> (2019-05) <a href="https://doi.org/gfzbz7">https://doi.org/gfzbz7</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2019.03.005">10.1016/j.cell.2019.03.005</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30982598">30982598</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6526772">PMC6526772</a></p>
</div>
<div id="ref-18RF7h7kj">
<p>5. <strong>A Structured Tumor-Immune Microenvironment in Triple Negative Breast Cancer Revealed by Multiplexed Ion Beam Imaging</strong> <br />
Leeat Keren, Marc Bosse, Diana Marquez, Roshan Angoshtari, Samir Jain, Sushama Varma, Soo-Ryum Yang, Allison Kurian, David Van Valen, Robert West, … Michael Angelo<br />
<em>Cell</em> (2018-09) <a href="https://doi.org/gd4wms">https://doi.org/gd4wms</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2018.08.039">10.1016/j.cell.2018.08.039</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30193111">30193111</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6132072">PMC6132072</a></p>
</div>
<div id="ref-wFwe0y4i">
<p>6. <strong>Epigenetic regulation in development: is the mouse a good model for the human?</strong> <br />
Courtney W Hanna, Hannah Demond, Gavin Kelsey<br />
<em>Human Reproduction Update</em> (2018-09) <a href="https://doi.org/gd3d4z">https://doi.org/gd3d4z</a> <br />
DOI: <a href="https://doi.org/10.1093/humupd/dmy021">10.1093/humupd/dmy021</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29992283">29992283</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6093373">PMC6093373</a></p>
</div>
<div id="ref-8Hx7hvP9">
<p>7. <strong>Single-cell in situ RNA profiling by sequential hybridization</strong> <br />
Eric Lubeck, Ahmet F Coskun, Timur Zhiyentayev, Mubhij Ahmad, Long Cai<br />
<em>Nature Methods</em> (2014-03-28) <a href="https://doi.org/ggrr5b">https://doi.org/ggrr5b</a> <br />
DOI: <a href="https://doi.org/10.1038/nmeth.2892">10.1038/nmeth.2892</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24681720">24681720</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4085791">PMC4085791</a></p>
</div>
<div id="ref-lsQbrG4W">
<p>8. <strong>In Situ Transcription Profiling of Single Cells Reveals Spatial Organization of Cells in the Mouse Hippocampus</strong> <br />
Sheel Shah, Eric Lubeck, Wen Zhou, Long Cai<br />
<em>Neuron</em> (2016-10) <a href="https://doi.org/f8875g">https://doi.org/f8875g</a> <br />
DOI: <a href="https://doi.org/10.1016/j.neuron.2016.10.001">10.1016/j.neuron.2016.10.001</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27764670">27764670</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5087994">PMC5087994</a></p>
</div>
<div id="ref-dx9o8qYU">
<p>9. <strong>Transcriptome-scale super-resolved imaging in tissues by RNA seqFISH+</strong> <br />
Chee-Huat Linus Eng, Michael Lawson, Qian Zhu, Ruben Dries, Noushin Koulena, Yodai Takei, Jina Yun, Christopher Cronin, Christoph Karp, Guo-Cheng Yuan, Long Cai<br />
<em>Nature</em> (2019-03-25) <a href="https://doi.org/gfxgqx">https://doi.org/gfxgqx</a> <br />
DOI: <a href="https://doi.org/10.1038/s41586-019-1049-y">10.1038/s41586-019-1049-y</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30911168">30911168</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6544023">PMC6544023</a></p>
</div>
<div id="ref-1HWhMi97j">
<p>10. <strong>Giotto, a toolbox for integrative analysis and visualization of spatial expression data</strong> <br />
Ruben Dries, Qian Zhu, Rui Dong, Chee-Huat Linus Eng, Huipeng Li, Kan Liu, Yuntian Fu, Tianxiao Zhao, Arpan Sarkar, Feng Bao, … Guo-Cheng Yuan<br />
<em>bioRxiv</em> (2020-05-30) <a href="https://doi.org/gg84qf">https://doi.org/gg84qf</a> <br />
DOI: <a href="https://doi.org/10.1101/701680">10.1101/701680</a></p>
</div>
<div id="ref-124247ZE6">
<p>11. <strong>Spatial reconstruction of single-cell gene expression data</strong> <br />
Rahul Satija, Jeffrey A Farrell, David Gennert, Alexander F Schier, Aviv Regev<br />
<em>Nature Biotechnology</em> (2015-04-13) <a href="https://doi.org/f7bmck">https://doi.org/f7bmck</a> <br />
DOI: <a href="https://doi.org/10.1038/nbt.3192">10.1038/nbt.3192</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25867923">25867923</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4430369">PMC4430369</a></p>
</div>
<div id="ref-gbdea2Ea">
<p>12. <strong>Cluster Validation by Prediction Strength</strong> <br />
Robert Tibshirani, Guenther Walther<br />
<em>Journal of Computational and Graphical Statistics</em> (2005-09) <a href="https://doi.org/fvtcf4">https://doi.org/fvtcf4</a> <br />
DOI: <a href="https://doi.org/10.1198/106186005x59243">10.1198/106186005x59243</a></p>
</div>
<div id="ref-yWwOzARC">
<p>13. <strong>Optimal-Transport Analysis of Single-Cell Gene Expression Identifies Developmental Trajectories in Reprogramming</strong> <br />
Geoffrey Schiebinger, Jian Shu, Marcin Tabaka, Brian Cleary, Vidya Subramanian, Aryeh Solomon, Joshua Gould, Siyan Liu, Stacie Lin, Peter Berube, … Eric S. Lander<br />
<em>Cell</em> (2019-03) <a href="https://doi.org/gfwk5n">https://doi.org/gfwk5n</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2019.02.026">10.1016/j.cell.2019.02.026</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30849376">30849376</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6615720">PMC6615720</a></p>
</div>
<div id="ref-15aSce9Vm">
<p>14. <strong>Inferring spatial and signaling relationships between cells from single cell transcriptomic data</strong> <br />
Zixuan Cang, Qing Nie<br />
<em>Nature Communications</em> (2020-04-29) <a href="https://doi.org/gg9pf7">https://doi.org/gg9pf7</a> <br />
DOI: <a href="https://doi.org/10.1038/s41467-020-15968-5">10.1038/s41467-020-15968-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32350282">32350282</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7190659">PMC7190659</a></p>
</div>
<div id="ref-yCBL1fje">
<p>15. <strong>Spatial proteomics: a powerful discovery tool for cell biology</strong> <br />
Emma Lundberg, Georg H. H. Borner<br />
<em>Nature Reviews Molecular Cell Biology</em> (2019-01-18) <a href="https://doi.org/gft39v">https://doi.org/gft39v</a> <br />
DOI: <a href="https://doi.org/10.1038/s41580-018-0094-y">10.1038/s41580-018-0094-y</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30659282">30659282</a></p>
</div>
<div id="ref-KsY7PFJ8">
<p>16. <strong>Matching species traits to environmental variables: a new three-table ordination method</strong> <br />
S. Dolédec, D. Chessel, C. J. F. ter Braak, S. Champely<br />
<em>Environmental and Ecological Statistics</em> (1996-06) <a href="https://doi.org/fhwz55">https://doi.org/fhwz55</a> <br />
DOI: <a href="https://doi.org/10.1007/bf02427859">10.1007/bf02427859</a></p>
</div>
<div id="ref-8vGho6cJ">
<p>17. <strong>Using single‐cell genomics to understand developmental processes and cell fate decisions</strong> <br />
Jonathan A Griffiths, Antonio Scialdone, John C Marioni<br />
<em>Molecular Systems Biology</em> (2018-04-16) <a href="https://doi.org/gdgbtq">https://doi.org/gdgbtq</a> <br />
DOI: <a href="https://doi.org/10.15252/msb.20178046">10.15252/msb.20178046</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29661792">29661792</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5900446">PMC5900446</a></p>
</div>
<div id="ref-3QdXjbeH">
<p>18. <strong>Reprogramming the Methylome: Erasing Memory and Creating Diversity</strong> <br />
Heather J. Lee, Timothy A. Hore, Wolf Reik<br />
<em>Cell Stem Cell</em> (2014-06) <a href="https://doi.org/f6f83c">https://doi.org/f6f83c</a> <br />
DOI: <a href="https://doi.org/10.1016/j.stem.2014.05.008">10.1016/j.stem.2014.05.008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24905162">24905162</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4051243">PMC4051243</a></p>
</div>
<div id="ref-1FWgnoNlO">
<p>19. <strong>scNMT-seq enables joint profiling of chromatin accessibility DNA methylation and transcription in single cells</strong> <br />
Stephen J. Clark, Ricard Argelaguet, Chantriolnt-Andreas Kapourani, Thomas M. Stubbs, Heather J. Lee, Celia Alda-Catalinas, Felix Krueger, Guido Sanguinetti, Gavin Kelsey, John C. Marioni, … Wolf Reik<br />
<em>Nature Communications</em> (2018-02-22) <a href="https://doi.org/gc4q72">https://doi.org/gc4q72</a> <br />
DOI: <a href="https://doi.org/10.1038/s41467-018-03149-4">10.1038/s41467-018-03149-4</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29472610">29472610</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5823944">PMC5823944</a></p>
</div>
<div id="ref-1H9T8tTsB">
<p>20. <strong>Multi-omics profiling of mouse gastrulation at single-cell resolution</strong> <br />
Ricard Argelaguet, Stephen J. Clark, Hisham Mohammed, L. Carine Stapel, Christel Krueger, Chantriolnt-Andreas Kapourani, Ivan Imaz-Rosshandler, Tim Lohoff, Yunlong Xiang, Courtney W. Hanna, … Wolf Reik<br />
<em>Nature</em> (2019-12-11) <a href="https://doi.org/ggfrnn">https://doi.org/ggfrnn</a> <br />
DOI: <a href="https://doi.org/10.1038/s41586-019-1825-8">10.1038/s41586-019-1825-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31827285">31827285</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6924995">PMC6924995</a></p>
</div>
<div id="ref-TvcYLBQI">
<p>21. <strong>Pan-cancer identification of clinically relevant genomic subtypes using outcome-weighted integrative clustering</strong> <br />
Arshi Arora, Adam B. Olshen, Venkatraman E. Seshan, Ronglai Shen<br />
<em>bioRxiv</em> (2020-05-12) <a href="https://doi.org/gg8np9">https://doi.org/gg8np9</a> <br />
DOI: <a href="https://doi.org/10.1101/2020.05.11.084798">10.1101/2020.05.11.084798</a></p>
</div>
<div id="ref-MaZsghuS">
<p>22. <strong>Single-Cell Multi-omic Integration Compares and Contrasts Features of Brain Cell Identity</strong> <br />
Joshua D. Welch, Velina Kozareva, Ashley Ferreira, Charles Vanderburg, Carly Martin, Evan Z. Macosko<br />
<em>Cell</em> (2019-06) <a href="https://doi.org/gf3m3v">https://doi.org/gf3m3v</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2019.05.006">10.1016/j.cell.2019.05.006</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31178122">31178122</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6716797">PMC6716797</a></p>
</div>
<div id="ref-Ee0L8PLY">
<p>23. <strong>Variable selection for generalized canonical correlation analysis</strong> <br />
A. Tenenhaus, C. Philippe, V. Guillemot, K.-A. Le Cao, J. Grill, V. Frouin<br />
<em>Biostatistics</em> (2014-02-17) <a href="https://doi.org/gg583d">https://doi.org/gg583d</a> <br />
DOI: <a href="https://doi.org/10.1093/biostatistics/kxu001">10.1093/biostatistics/kxu001</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24550197">24550197</a></p>
</div>
<div id="ref-QSXGprag">
<p>24. <strong>mixOmics: An R package for ‘omics feature selection and multiple data integration</strong> <br />
Florian Rohart, Benoît Gautier, Amrit Singh, Kim-Anh Lê Cao<br />
<em>PLOS Computational Biology</em> (2017-11-03) <a href="https://doi.org/gcj84s">https://doi.org/gcj84s</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1005752">10.1371/journal.pcbi.1005752</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29099853">29099853</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5687754">PMC5687754</a></p>
</div>
<div id="ref-GngCJZvg">
<p>25. <strong>impute</strong> <br />
Robert Tibshirani Trevor Hastie<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg9dds">https://doi.org/gg9dds</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.impute">10.18129/b9.bioc.impute</a></p>
</div>
<div id="ref-Bf6HgBfZ">
<p>26. <strong>MOFA+: a statistical framework for comprehensive integration of multi-modal single-cell data</strong> <br />
Ricard Argelaguet, Damien Arnol, Danila Bredikhin, Yonatan Deloro, Britta Velten, John C. Marioni, Oliver Stegle<br />
<em>Genome Biology</em> (2020-05-11) <a href="https://doi.org/ggvwsr">https://doi.org/ggvwsr</a> <br />
DOI: <a href="https://doi.org/https://doi.org/10.1186/s13059-020-02015-1">https://doi.org/10.1186/s13059-020-02015-1</a></p>
</div>
<div id="ref-1HahRBkyb">
<p>27. <strong>Adjusting batch effects in microarray expression data using empirical Bayes methods</strong> <br />
W. Evan Johnson, Cheng Li, Ariel Rabinovic<br />
<em>Biostatistics</em> (2007-01) <a href="https://doi.org/dsf386">https://doi.org/dsf386</a> <br />
DOI: <a href="https://doi.org/10.1093/biostatistics/kxj037">10.1093/biostatistics/kxj037</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16632515">16632515</a></p>
</div>
<div id="ref-1156sEPws">
<p>28. <strong>Variance stabilization applied to microarray data calibration and to the quantification of differential expression</strong> <br />
W. Huber, A. von Heydebreck, H. Sultmann, A. Poustka, M. Vingron<br />
<em>Bioinformatics</em> (2002-07-01) <a href="https://doi.org/dbb6xx">https://doi.org/dbb6xx</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/18.suppl_1.s96">10.1093/bioinformatics/18.suppl_1.s96</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12169536">12169536</a></p>
</div>
<div id="ref-OekvE5up">
<p>29. <strong>Integrative inference of brain cell similarities and differences from single-cell genomics</strong> <br />
Joshua Welch, Velina Kozareva, Ashley Ferreira, Charles Vanderburg, Carly Martin, Evan Macosko<br />
<em>bioRxiv</em> (2018-11-02) <a href="https://doi.org/gfgr7b">https://doi.org/gfgr7b</a> <br />
DOI: <a href="https://doi.org/10.1101/459891">10.1101/459891</a></p>
</div>
<div id="ref-v4W8vQ17">
<p>30. <strong>mogsa</strong> <br />
Chen Meng<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg583f">https://doi.org/gg583f</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.mogsa">10.18129/b9.bioc.mogsa</a></p>
</div>
<div id="ref-UCIhFB5B">
<p>31. <strong>Combining the fourth-corner and the RLQ methods for assessing trait responses to environmental variation</strong> <br />
Stéphane Dray, Philippe Choler, Sylvain Dolédec, Pedro R. Peres-Neto, Wilfried Thuiller, Sandrine Pavoine, Cajo J. F. ter Braak<br />
<em>Ecology</em> (2014-01) <a href="https://doi.org/gdsf9z">https://doi.org/gdsf9z</a> <br />
DOI: <a href="https://doi.org/10.1890/13-0196.1">10.1890/13-0196.1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24649641">24649641</a></p>
</div>
<div id="ref-H4wZSl5d">
<p>32. <strong>What Is Your Conceptual Definition of “Cell Type” in the Context of a Mature Organism?</strong> <br />
Cell Systems<br />
(2017-03) <a href="https://doi.org/d38b">https://doi.org/d38b</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cels.2017.03.006">10.1016/j.cels.2017.03.006</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28334573">28334573</a></p>
</div>
<div id="ref-q9SIZrho">
<p>33. <strong>Multiple factor analysis.</strong> <br />
L. L. Thurstone<br />
<em>Psychological Review</em> (1931) <a href="https://doi.org/dq4k9p">https://doi.org/dq4k9p</a> <br />
DOI: <a href="https://doi.org/10.1037/h0069792">10.1037/h0069792</a></p>
</div>
<div id="ref-4fOW94wl">
<p>34. <strong>The ACT (STATIS method)</strong> <br />
Christine Lavit, Yves Escoufier, Robert Sabatier, Pierre Traissac<br />
<em>Computational Statistics &amp; Data Analysis</em> (1994-08) <a href="https://doi.org/c8xttz">https://doi.org/c8xttz</a> <br />
DOI: <a href="https://doi.org/10.1016/0167-9473(94)90134-1">10.1016/0167-9473(94)90134-1</a></p>
</div>
<div id="ref-18b0ymB7t">
<p>35. <strong>Multivariate data analysis: The French way</strong> <br />
Susan Holmes<br />
<em>Institute of Mathematical Statistics</em> (2008) <a href="https://doi.org/cmnf7j">https://doi.org/cmnf7j</a> <br />
DOI: <a href="https://doi.org/10.1214/193940307000000455">10.1214/193940307000000455</a></p>
</div>
<div id="ref-nhuT45y5">
<p>36. <strong>Multitable Methods for Microbiome Data Integration</strong> <br />
Kris Sankaran, Susan P. Holmes<br />
<em>Frontiers in Genetics</em> (2019-08-28) <a href="https://doi.org/gf8dqn">https://doi.org/gf8dqn</a> <br />
DOI: <a href="https://doi.org/10.3389/fgene.2019.00627">10.3389/fgene.2019.00627</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31555316">31555316</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6724662">PMC6724662</a></p>
</div>
<div id="ref-1ABBBCpyT">
<p>37. <strong>Quantitative, Architectural Analysis of Immune Cell Subsets in Tumor-Draining Lymph Nodes from Breast Cancer Patients and Healthy Lymph Nodes</strong> <br />
A. Francesca Setiadi, Nelson C. Ray, Holbrook E. Kohrt, Adam Kapelner, Valeria Carcamo-Cavazos, Edina B. Levic, Sina Yadegarynia, Chris M. van der Loos, Erich J. Schwartz, Susan Holmes, Peter P. Lee<br />
<em>PLoS ONE</em> (2010-08-25) <a href="https://doi.org/bp4qj5">https://doi.org/bp4qj5</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pone.0012420">10.1371/journal.pone.0012420</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20811638">20811638</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2928294">PMC2928294</a></p>
</div>
<div id="ref-XkAC715J">
<p>38. <strong>Mapping identifiers for the integration of genomic datasets with the R/Bioconductor package biomaRt</strong> <br />
Steffen Durinck, Paul T Spellman, Ewan Birney, Wolfgang Huber<br />
<em>Nature Protocols</em> (2009-07-23) <a href="https://doi.org/c4b7dd">https://doi.org/c4b7dd</a> <br />
DOI: <a href="https://doi.org/10.1038/nprot.2009.97">10.1038/nprot.2009.97</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19617889">19617889</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3159387">PMC3159387</a></p>
</div>
<div id="ref-1GblcsF7">
<p>39. <strong>Characterization of the Impact of Daclizumab Beta on Circulating Natural Killer Cells by Mass Cytometry</strong> <br />
Thanmayi Ranganath, Laura J. Simpson, Anne-Maud Ferreira, Christof Seiler, Elena Vendrame, Nancy Zhao, Jason D. Fontenot, Susan Holmes, Catherine A. Blish<br />
<em>Frontiers in Immunology</em> (2020-04-24) <a href="https://doi.org/gg5jcr">https://doi.org/gg5jcr</a> <br />
DOI: <a href="https://doi.org/10.3389/fimmu.2020.00714">10.3389/fimmu.2020.00714</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32391016">32391016</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7194113">PMC7194113</a></p>
</div>
<div id="ref-aSqxpadK">
<p>40. <strong>Machine learning: a probabilistic perspective</strong> <br />
Kevin P. Murphy<br />
<em>MIT Press</em> (2012) <br />
ISBN: <a href="https://worldcat.org/isbn/9780262018029">9780262018029</a></p>
</div>
<div id="ref-172t1QM5n">
<p>41. <strong>Dimensionality reduction for visualizing single-cell data using UMAP</strong> <br />
Etienne Becht, Leland McInnes, John Healy, Charles-Antoine Dutertre, Immanuel WH Kwok, Lai Guan Ng, Florent Ginhoux, Evan W Newell<br />
<em>Nature Biotechnology</em> (2018-12-03) <a href="https://doi.org/gfkwzq">https://doi.org/gfkwzq</a> <br />
DOI: <a href="https://doi.org/10.1038/nbt.4314">10.1038/nbt.4314</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30531897">30531897</a></p>
</div>
<div id="ref-cZOVX9E7">
<p>42. <strong>DIABLO: an integrative approach for identifying key molecular drivers from multi-omics assays</strong> <br />
Amrit Singh, Casey P Shannon, Benoît Gautier, Florian Rohart, Michaël Vacher, Scott J Tebbutt, Kim-Anh Lê Cao<br />
<em>Bioinformatics</em> (2019-09-01) <a href="https://doi.org/ggpt9c">https://doi.org/ggpt9c</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bty1054">10.1093/bioinformatics/bty1054</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30657866">30657866</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6735831">PMC6735831</a></p>
</div>
<div id="ref-VmqVY5HQ">
<p>43. <strong>Benchmarking single cell RNA-sequencing analysis pipelines using mixture control experiments</strong> <br />
Luyi Tian, Xueyi Dong, Saskia Freytag, Kim-Anh Lê Cao, Shian Su, Abolfazl JalalAbadi, Daniela Amann-Zalcenstein, Tom S. Weber, Azadeh Seidi, Jafar S. Jabbari, … Matthew E. Ritchie<br />
<em>Nature Methods</em> (2019-05-27) <a href="https://doi.org/gf3jhp">https://doi.org/gf3jhp</a> <br />
DOI: <a href="https://doi.org/10.1038/s41592-019-0425-8">10.1038/s41592-019-0425-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31133762">31133762</a></p>
</div>
<div id="ref-dVbihx0f">
<p>44. <strong>Benchmarking single-cell RNA-sequencing protocols for cell atlas projects</strong> <br />
Elisabetta Mereu, Atefeh Lafzi, Catia Moutinho, Christoph Ziegenhain, Davis J. McCarthy, Adrián Álvarez-Varela, Eduard Batlle, Sagar, Dominic Grün, Julia K. Lau, … Holger Heyn<br />
<em>Nature Biotechnology</em> (2020-04-06) <a href="https://doi.org/ggrbbh">https://doi.org/ggrbbh</a> <br />
DOI: <a href="https://doi.org/10.1038/s41587-020-0469-4">10.1038/s41587-020-0469-4</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32518403">32518403</a></p>
</div>
<div id="ref-Vz4pQdwU">
<p>45. <strong>Systematic comparison of single-cell and single-nucleus RNA-sequencing methods</strong> <br />
Jiarui Ding, Xian Adiconis, Sean K. Simmons, Monika S. Kowalczyk, Cynthia C. Hession, Nemanja D. Marjanovic, Travis K. Hughes, Marc H. Wadsworth, Tyler Burks, Lan T. Nguyen, … Joshua Z. Levin<br />
<em>Nature Biotechnology</em> (2020-04-06) <a href="https://doi.org/ggrksw">https://doi.org/ggrksw</a> <br />
DOI: <a href="https://doi.org/10.1038/s41587-020-0465-8">10.1038/s41587-020-0465-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32341560">32341560</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7289686">PMC7289686</a></p>
</div>
<div id="ref-PxOZHHKj">
<p>46. <strong>Accounting for technical noise in single-cell RNA-seq experiments</strong> <br />
Philip Brennecke, Simon Anders, Jong Kyoung Kim, Aleksandra A Kołodziejczyk, Xiuwei Zhang, Valentina Proserpio, Bianka Baying, Vladimir Benes, Sarah A Teichmann, John C Marioni, Marcus G Heisler<br />
<em>Nature Methods</em> (2013-09-22) <a href="https://doi.org/gbd3mc">https://doi.org/gbd3mc</a> <br />
DOI: <a href="https://doi.org/10.1038/nmeth.2645">10.1038/nmeth.2645</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24056876">24056876</a></p>
</div>
<div id="ref-117yS2Kkv">
<p>47. <strong>Splatter: simulation of single-cell RNA sequencing data</strong> <br />
Luke Zappia, Belinda Phipson, Alicia Oshlack<br />
<em>Genome Biology</em> (2017-09-12) <a href="https://doi.org/gc3h3g">https://doi.org/gc3h3g</a> <br />
DOI: <a href="https://doi.org/10.1186/s13059-017-1305-0">10.1186/s13059-017-1305-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28899397">28899397</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5596896">PMC5596896</a></p>
</div>
<div id="ref-13ibOJcF0">
<p>48. <strong>A Sparse PLS for Variable Selection when Integrating Omics Data</strong> <br />
Kim-Anh Lê Cao, Debra Rossouw, Christèle Robert-Granié, Philippe Besse<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2008-01-18) <a href="https://doi.org/cw7zft">https://doi.org/cw7zft</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1390">10.2202/1544-6115.1390</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19049491">19049491</a></p>
</div>
<div id="ref-maAEgLQK">
<p>49. <strong>Sparse principal component analysis via regularized low rank matrix approximation</strong> <br />
Haipeng Shen, Jianhua Z. Huang<br />
<em>Journal of Multivariate Analysis</em> (2008-07) <a href="https://doi.org/b7x3cc">https://doi.org/b7x3cc</a> <br />
DOI: <a href="https://doi.org/10.1016/j.jmva.2007.06.007">10.1016/j.jmva.2007.06.007</a></p>
</div>
<div id="ref-yVYfg2ZK">
<p>50. <strong>Quantifying the Association between Gene Expressions and DNA-Markers by Penalized Canonical Correlation Analysis</strong> <br />
Sandra Waaijenborg, Philip C. Verselewel de Witt Hamer, Aeilko H Zwinderman<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2008-01-23) <a href="https://doi.org/bpzb68">https://doi.org/bpzb68</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1329">10.2202/1544-6115.1329</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18241193">18241193</a></p>
</div>
<div id="ref-YY25QUrX">
<p>51. <strong><span style="font-weight:normal;">CCA</span> : An <em>R</em> Package to Extend Canonical Correlation Analysis</strong> <br />
Ignacio Gonzalez, Sébastien Déjean, Pascal Martin, Alain Baccini<br />
<em>Journal of Statistical Software</em> (2008) <a href="https://doi.org/gf4f5m">https://doi.org/gf4f5m</a> <br />
DOI: <a href="https://doi.org/10.18637/jss.v023.i12">10.18637/jss.v023.i12</a></p>
</div>
<div id="ref-5B54vifR">
<p>52. <strong>HIGHLIGHTING RELATIONSHIPS BETWEEN HETEROGENEOUS BIOLOGICAL DATA THROUGH GRAPHICAL DISPLAYS BASED ON REGULARIZED CANONICAL CORRELATION ANALYSIS</strong> <br />
I. GONZÁLEZ, S. DÉJEAN, P. G. P. MARTIN, O. GONÇALVES, P. BESSE, A. BACCINI<br />
<em>Journal of Biological Systems</em> (2011-11-21) <a href="https://doi.org/bmbjf5">https://doi.org/bmbjf5</a> <br />
DOI: <a href="https://doi.org/10.1142/s0218339009002831">10.1142/s0218339009002831</a></p>
</div>
<div id="ref-tOD4Gkgt">
<p>53. <strong>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</strong> <br />
D. M. Witten, R. Tibshirani, T. Hastie<br />
<em>Biostatistics</em> (2009-04-17) <a href="https://doi.org/fd4g54">https://doi.org/fd4g54</a> <br />
DOI: <a href="https://doi.org/10.1093/biostatistics/kxp008">10.1093/biostatistics/kxp008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19377034">19377034</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2697346">PMC2697346</a></p>
</div>
<div id="ref-AQWTNms4">
<p>54. <strong>Sparse Canonical Correlation Analysis with Application to Genomic Data Integration</strong> <br />
Elena Parkhomenko, David Tritchler, Joseph Beyene<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2009-01-06) <a href="https://doi.org/b7x4jb">https://doi.org/b7x4jb</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1406">10.2202/1544-6115.1406</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19222376">19222376</a></p>
</div>
<div id="ref-bFa7ptnr">
<p>55. <strong>Integrative analysis of gene expression and copy number alterations using canonical correlation analysis</strong> <br />
Charlotte Soneson, Henrik Lilljebjörn, Thoas Fioretos, Magnus Fontes<br />
<em>BMC Bioinformatics</em> (2010-04-15) <a href="https://doi.org/dtxhsx">https://doi.org/dtxhsx</a> <br />
DOI: <a href="https://doi.org/10.1186/1471-2105-11-191">10.1186/1471-2105-11-191</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20398334">20398334</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2873536">PMC2873536</a></p>
</div>
<div id="ref-wkhRfjyx">
<p>56. <strong>Gene expression signatures modulated by epidermal growth factor receptor activation and their relationship to cetuximab resistance in head and neck squamous cell carcinoma</strong> <br />
Elana J Fertig, Qing Ren, Haixia Cheng, Hiromitsu Hatakeyama, Adam P Dicker, Ulrich Rodeck, Michael Considine, Michael F Ochs, Christine H Chung<br />
<em>BMC Genomics</em> (2012) <a href="https://doi.org/gb3fgp">https://doi.org/gb3fgp</a> <br />
DOI: <a href="https://doi.org/10.1186/1471-2164-13-160">10.1186/1471-2164-13-160</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22549044">22549044</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3460736">PMC3460736</a></p>
</div>
<div id="ref-wP2BgpVi">
<p>57. <strong>Identifying multi-layer gene regulatory modules from multi-dimensional genomic data</strong> <br />
W. Li, S. Zhang, C.-C. Liu, X. J. Zhou<br />
<em>Bioinformatics</em> (2012-08-03) <a href="https://doi.org/f4d488">https://doi.org/f4d488</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bts476">10.1093/bioinformatics/bts476</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22863767">22863767</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3463121">PMC3463121</a></p>
</div>
<div id="ref-j7x8dqSL">
<p>58. <strong>Cross-platform comparison and visualisation of gene expression data using co-inertia analysis</strong> <br />
Aedín C. Culhane, Guy Perrière, Desmond G. Higgins<br />
<em>BMC bioinformatics</em> (2003-11-21) <br />
DOI: <a href="https://doi.org/10.1186/1471-2105-4-59">10.1186/1471-2105-4-59</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC317282">PMC317282</a></p>
</div>
<div id="ref-MYhQ5fRN">
<p>59. <strong>Extensions of Sparse Canonical Correlation Analysis with Applications to Genomic Data</strong> <br />
Daniela M Witten, Robert J. Tibshirani<br />
<em>Statistical Applications in Genetics and Molecular Biology</em> (2009-01-09) <a href="https://doi.org/b45jtg">https://doi.org/b45jtg</a> <br />
DOI: <a href="https://doi.org/10.2202/1544-6115.1470">10.2202/1544-6115.1470</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19572827">19572827</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2861323">PMC2861323</a></p>
</div>
<div id="ref-NSuq56O9">
<p>60. <strong>MOGSA: Integrative Single Sample Gene-set Analysis of Multiple Omics Data</strong> <br />
Chen Meng, Azfar Basunia, Bjoern Peters, Amin Moghaddas Gholami, Bernhard Kuster, Aedín C. Culhane<br />
<em>Molecular &amp; Cellular Proteomics</em> (2019-08-09) <a href="https://doi.org/ggf3j3">https://doi.org/ggf3j3</a> <br />
DOI: <a href="https://doi.org/10.1074/mcp.tir118.001251">10.1074/mcp.tir118.001251</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31243065">31243065</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6692785">PMC6692785</a></p>
</div>
<div id="ref-IZfv7up4">
<p>61. <strong>Consistency and overfitting of multi-omics methods on experimental data</strong> <br />
Sean D McCabe, Dan-Yu Lin, Michael I Love<br />
<em>Briefings in Bioinformatics</em> (2020-07) <a href="https://doi.org/gghpmf">https://doi.org/gghpmf</a> <br />
DOI: <a href="https://doi.org/10.1093/bib/bbz070">10.1093/bib/bbz070</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31281919">31281919</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7373174">PMC7373174</a></p>
</div>
<div id="ref-4CvJHFCU">
<p>62. <strong>Bootstrapping cluster analysis: Assessing the reliability of conclusions from microarray experiments</strong> <br />
M. K. Kerr, G. A. Churchill<br />
<em>Proceedings of the National Academy of Sciences</em> (2001-07-24) <a href="https://doi.org/cgpp6p">https://doi.org/cgpp6p</a> <br />
DOI: <a href="https://doi.org/10.1073/pnas.161273698">10.1073/pnas.161273698</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11470909">11470909</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC55356">PMC55356</a></p>
</div>
<div id="ref-kVhMOlK2">
<p>63. <strong>A prediction-based resampling method for estimating the number of clusters in a dataset</strong> <br />
Sandrine Dudoit, Jane Fridlyand<br />
<em>Genome Biology</em> (2002-06-25) <br />
DOI: <a href="https://doi.org/10.1186/gb-2002-3-7-research0036">10.1186/gb-2002-3-7-research0036</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC126241">PMC126241</a></p>
</div>
<div id="ref-I1iOQSFC">
<p>64. <strong>A Three-Gene Model to Robustly Identify Breast Cancer Molecular Subtypes</strong> <br />
Benjamin Haibe-Kains, Christine Desmedt, Sherene Loi, Aedin C. Culhane, Gianluca Bontempi, John Quackenbush, Christos Sotiriou<br />
<em>JNCI: Journal of the National Cancer Institute</em> (2012-02-22) <a href="https://doi.org/fzb27r">https://doi.org/fzb27r</a> <br />
DOI: <a href="https://doi.org/10.1093/jnci/djr545">10.1093/jnci/djr545</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22262870">22262870</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3283537">PMC3283537</a></p>
</div>
<div id="ref-1DuDJywpg">
<p>65. <strong>A simple, scalable approach to building a cross-platform transcriptome atlas</strong> <br />
Paul W Angel, Nadia Rajab, Yidi Deng, Chris M Pacheco, Tyrone Chen, Kim-Anh Lê Cao, Jarny Choi, Christine A Wells<br />
<em>bioRxiv</em> (2020-03-11) <a href="https://doi.org/gg898g">https://doi.org/gg898g</a> <br />
DOI: <a href="https://doi.org/10.1101/2020.03.09.984468">10.1101/2020.03.09.984468</a></p>
</div>
<div id="ref-dwXJ9SC4">
<p>66. <strong>A federated ecosystem for sharing genomic, clinical data</strong> <br />
The Global Alliance for Genomics and Health<br />
<em>Science</em> (2016-06-09) <a href="https://doi.org/ggctm3">https://doi.org/ggctm3</a> <br />
DOI: <a href="https://doi.org/10.1126/science.aaf6162">10.1126/science.aaf6162</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27284183">27284183</a></p>
</div>
<div id="ref-102RKxFFz">
<p>67. <strong>GrimoireLab - Software Development and Community Analytics platform</strong> <a href="https://chaoss.github.io/grimoirelab/">https://chaoss.github.io/grimoirelab/</a></p>
</div>
<div id="ref-14np73aSU">
<p>68. <a href="http://ceur-ws.org/Vol-987/3.pdf">http://ceur-ws.org/Vol-987/3.pdf</a></p>
</div>
<div id="ref-E7tdylV2">
<p>69. <strong>Bioconductor - Home</strong> <a href="https://bioconductor.org/">https://bioconductor.org/</a></p>
</div>
<div id="ref-oRTa5zGU">
<p>70. <strong>Bioconductor build/check results</strong> <a href="https://bioconductor.org/checkResults/">https://bioconductor.org/checkResults/</a></p>
</div>
<div id="ref-SkTqlnmn">
<p>71. <a href="https://bioconductor.org/support">https://bioconductor.org/support</a></p>
</div>
<div id="ref-mlBLKi3Y">
<p>72. <strong>MultiAssayExperiment</strong> <br />
Marcel Ramos [Aut, Cre], Levi Waldron [Aut], MultiAssay SIG[Ctb]<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg6p3d">https://doi.org/gg6p3d</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.multiassayexperiment">10.18129/b9.bioc.multiassayexperiment</a></p>
</div>
<div id="ref-gdnUpsQo">
<p>73. <strong>Software for the Integration of Multiomics Experiments in Bioconductor</strong> <br />
Marcel Ramos, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez, Tiffany Chan, Phil Chapman, Sean R. Davis, David Gomez-Cabrero, … Levi Waldron<br />
<em>Cancer Research</em> (2017-10-31) <a href="https://doi.org/gcj278">https://doi.org/gcj278</a> <br />
DOI: <a href="https://doi.org/10.1158/0008-5472.can-17-0344">10.1158/0008-5472.can-17-0344</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29092936">29092936</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5679241">PMC5679241</a></p>
</div>
<div id="ref-12geyVA4y">
<p>74. <strong>ExperimentHub</strong> <br />
Bioconductor Package Maintainer <maintainer@bioconductor.org><br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg6p3c">https://doi.org/gg6p3c</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.experimenthub">10.18129/b9.bioc.experimenthub</a></p>
</div>
<div id="ref-KhbsUBNe">
<p>75. <strong>DelayedArray</strong> <br />
Hervé Pagès<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg5tw4">https://doi.org/gg5tw4</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.delayedarray">10.18129/b9.bioc.delayedarray</a></p>
</div>
<div id="ref-mOp2pMsC">
<p>76. <strong>rhdf5</strong> <br />
Bernd Fischer [Aut], Gregoire Pau [Aut], Mike Smith [Aut, Cre]<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg5tw6">https://doi.org/gg5tw6</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.rhdf5">10.18129/b9.bioc.rhdf5</a></p>
</div>
<div id="ref-g9O7LIML">
<p>77. <strong>mbkmeans: fast clustering for single cell data using mini-batch <em>k</em> -means</strong> <br />
Stephanie C. Hicks, Ruoxi Liu, Yuwei Ni, Elizabeth Purdom, Davide Risso<br />
<em>bioRxiv</em> (2020-05-27) <a href="https://doi.org/gg5tw3">https://doi.org/gg5tw3</a> <br />
DOI: <a href="https://doi.org/10.1101/2020.05.27.119438">10.1101/2020.05.27.119438</a></p>
</div>
<div id="ref-19jAJjD6o">
<p>78. <strong>mbkmeans</strong> <br />
Yuwei Ni, Davide Risso, Stephanie Hicks, Elizabeth Purdom<br />
<em>Bioconductor</em> <a href="https://doi.org/gg5tw5">https://doi.org/gg5tw5</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.mbkmeans">10.18129/b9.bioc.mbkmeans</a></p>
</div>
<div id="ref-qIZTS1II">
<p>79. <strong>SCANPY: large-scale single-cell gene expression data analysis</strong> <br />
F. Alexander Wolf, Philipp Angerer, Fabian J. Theis<br />
<em>Genome Biology</em> (2018-02-06) <a href="https://doi.org/gc22s9">https://doi.org/gc22s9</a> <br />
DOI: <a href="https://doi.org/10.1186/s13059-017-1382-0">10.1186/s13059-017-1382-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29409532">29409532</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5802054">PMC5802054</a></p>
</div>
<div id="ref-R7sfk7Aq">
<p>80. <strong>SingleCellExperiment</strong> <br />
Aaron Lun [Aut, Cph], Davide Risso [Aut, Cre, Cph]<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg5wfr">https://doi.org/gg5wfr</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.singlecellexperiment">10.18129/b9.bioc.singlecellexperiment</a></p>
</div>
<div id="ref-1FbF6M2UI">
<p>81. <strong>GenomicRanges</strong> <br />
H. Pagès P. Aboyoun<br />
<em>Bioconductor</em> (2017) <a href="https://doi.org/gg6rfz">https://doi.org/gg6rfz</a> <br />
DOI: <a href="https://doi.org/10.18129/b9.bioc.genomicranges">10.18129/b9.bioc.genomicranges</a></p>
</div>
<div id="ref-wrQUNea">
<p>82. <strong>SPOTlight: Seeded NMF regression to Deconvolute Spatial Transcriptomics Spots with Single-Cell Transcriptomes</strong> <br />
Marc Elosua, Paula Nieto, Elisabetta Mereu, Ivo Gut, Holger Heyn<br />
<em>bioRxiv</em> (2020-06-04) <a href="https://doi.org/gg6rfx">https://doi.org/gg6rfx</a> <br />
DOI: <a href="https://doi.org/10.1101/2020.06.03.131334">10.1101/2020.06.03.131334</a></p>
</div>
<div id="ref-11uDSb0Nf">
<p>83. <strong>Points of view: Color blindness</strong> <br />
Bang Wong<br />
<em>Nature Methods</em> (2011-06-01) <a href="https://www.nature.com/articles/nmeth.1618">https://www.nature.com/articles/nmeth.1618</a> <br />
DOI: <a href="https://doi.org/10.1038/nmeth.1618">10.1038/nmeth.1618</a></p>
</div>
<div id="ref-Ecm3XS4">
<p>84. <strong>Color coding</strong> <br />
Bang Wong<br />
<em>Nature Methods</em> (2010-08) <a href="https://doi.org/dhm3mz">https://doi.org/dhm3mz</a> <br />
DOI: <a href="https://doi.org/10.1038/nmeth0810-573">10.1038/nmeth0810-573</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20704014">20704014</a></p>
</div>
<div id="ref-lLv68Zzx">
<p>85. <strong>The viridis color palettes</strong> <a href="https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html">https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html</a></p>
</div>
<div id="ref-kuQ9iKB8">
<p>86. <strong>Slide-seq: A scalable technology for measuring genome-wide expression at high spatial resolution</strong> <br />
Samuel G. Rodriques, Robert R. Stickels, Aleksandrina Goeva, Carly A. Martin, Evan Murray, Charles R. Vanderburg, Joshua Welch, Linlin M. Chen, Fei Chen, Evan Z. Macosko<br />
<em>Science</em> (2019-03-29) <a href="https://doi.org/gfxpjk">https://doi.org/gfxpjk</a> <br />
DOI: <a href="https://doi.org/10.1126/science.aaw1219">10.1126/science.aaw1219</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30923225">30923225</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6927209">PMC6927209</a></p>
</div>
<div id="ref-11JyGlUPl">
<p>87. <strong>Highly multiplexed molecular and cellular mapping of breast cancer tissue in three dimensions using mass tomography</strong> <br />
Raúl Catena, Alaz Özcan, Laura Kütt, Alex Plüss, Peter Schraml, Holger Moch, Bernd Bodenmiller, IMAXT Consortium<br />
<em>Cold Spring Harbor Laboratory</em> (2020-05-25) <a href="https://doi.org/gg87jf">https://doi.org/gg87jf</a> <br />
DOI: <a href="https://doi.org/10.1101/2020.05.24.113571">10.1101/2020.05.24.113571</a></p>
</div>
<div id="ref-12q1TKAaX">
<p>88. <strong>ZipSeq: barcoding for real-time mapping of single cell transcriptomes</strong> <br />
Kenneth H. Hu, John P. Eichorst, Chris S. McGinnis, David M. Patterson, Eric D. Chow, Kelly Kersten, Stephen C. Jameson, Zev J. Gartner, Arjun A. Rao, Matthew F. Krummel<br />
<em>Nature Methods</em> (2020-07-06) <a href="https://doi.org/gg87jd">https://doi.org/gg87jd</a> <br />
DOI: <a href="https://doi.org/10.1038/s41592-020-0880-2">10.1038/s41592-020-0880-2</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32632238">32632238</a></p>
</div>
<div id="ref-z8JnDHpr">
<p>89. <strong>Orchestrating single-cell analysis with Bioconductor</strong> <br />
Robert A. Amezquita, Aaron T. L. Lun, Etienne Becht, Vince J. Carey, Lindsay N. Carpp, Ludwig Geistlinger, Federico Marini, Kevin Rue-Albrecht, Davide Risso, Charlotte Soneson, … Stephanie C. Hicks<br />
<em>Nature Methods</em> (2019-12-02) <a href="https://doi.org/ggdxgx">https://doi.org/ggdxgx</a> <br />
DOI: <a href="https://doi.org/10.1038/s41592-019-0654-x">10.1038/s41592-019-0654-x</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31792435">31792435</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7358058">PMC7358058</a></p>
</div>
<div id="ref-lNBJZodk">
<p>90. <strong>Integrating single-cell transcriptomic data across different conditions, technologies, and species</strong> <br />
Andrew Butler, Paul Hoffman, Peter Smibert, Efthymia Papalexi, Rahul Satija<br />
<em>Nature Biotechnology</em> (2018-04-02) <a href="https://doi.org/gc87v6">https://doi.org/gc87v6</a> <br />
DOI: <a href="https://doi.org/10.1038/nbt.4096">10.1038/nbt.4096</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29608179">29608179</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6700744">PMC6700744</a></p>
</div>
<div id="ref-udPM4KR1">
<p>91. <strong>The Human Tumor Atlas Network: Charting Tumor Transitions across Space and Time at Single-Cell Resolution</strong> <br />
Orit Rozenblatt-Rosen, Aviv Regev, Philipp Oberdoerffer, Tal Nawy, Anna Hupalowska, Jennifer E. Rood, Orr Ashenberg, Ethan Cerami, Robert J. Coffey, Emek Demir, … Xiaowei Zhuang<br />
<em>Cell</em> (2020-04) <a href="https://doi.org/ggtkzd">https://doi.org/ggtkzd</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2020.03.053">10.1016/j.cell.2020.03.053</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32302568">32302568</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7376497">PMC7376497</a></p>
</div>
<div id="ref-vk9ZInF3">
<p>92. <strong>The Human Cell Atlas</strong> <br />
Aviv Regev, Sarah A Teichmann, Eric S Lander, Ido Amit, Christophe Benoist, Ewan Birney, Bernd Bodenmiller, Peter Campbell, Piero Carninci, Menna Clatworthy, … Human Cell Atlas Meeting Participants<br />
<em>eLife</em> (2017-12-05) <a href="https://doi.org/gcnzcv">https://doi.org/gcnzcv</a> <br />
DOI: <a href="https://doi.org/10.7554/elife.27041">10.7554/elife.27041</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29206104">29206104</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5762154">PMC5762154</a></p>
</div>
<div id="ref-1DYAsd4eB">
<p>93. <strong>The Human Cell Atlas: from vision to reality</strong> <br />
Orit Rozenblatt-Rosen, Michael J. T. Stubbington, Aviv Regev, Sarah A. Teichmann<br />
<em>Nature</em> (2017-10-26) <a href="https://doi.org/gfgkr8">https://doi.org/gfgkr8</a> <br />
DOI: <a href="https://doi.org/10.1038/550451a">10.1038/550451a</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29072289">29072289</a></p>
</div>
<div id="ref-18fTyQGoG">
<p>94. <strong>Multivariate analysis of multiblock and multigroup data</strong> <br />
A. Eslami, E. M. Qannari, A. Kohler, S. Bougeard<br />
<em>Chemometrics and Intelligent Laboratory Systems</em> (2014-04) <a href="https://doi.org/f52wrr">https://doi.org/f52wrr</a> <br />
DOI: <a href="https://doi.org/10.1016/j.chemolab.2014.01.016">10.1016/j.chemolab.2014.01.016</a></p>
</div>
<div id="ref-2SDWXiwB">
<p>95. <strong>Dimension reduction techniques for the integrative analysis of multi-omics data</strong> <br />
Chen Meng, Oana A. Zeleznik, Gerhard G. Thallinger, Bernhard Kuster, Amin M. Gholami, Aedín C. Culhane<br />
<em>Briefings in Bioinformatics</em> (2016-07) <a href="https://doi.org/f83qvd">https://doi.org/f83qvd</a> <br />
DOI: <a href="https://doi.org/10.1093/bib/bbv108">10.1093/bib/bbv108</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26969681">26969681</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4945831">PMC4945831</a></p>
</div>
<div id="ref-UqaGRGDg">
<p>96. <strong>Robust meta-analysis of gene expression using the elastic net</strong> <br />
Jacob J. Hughey, Atul J. Butte<br />
<em>Nucleic Acids Research</em> (2015-07-13) <a href="https://doi.org/f7nnbm">https://doi.org/f7nnbm</a> <br />
DOI: <a href="https://doi.org/10.1093/nar/gkv229">10.1093/nar/gkv229</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25829177">25829177</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4499117">PMC4499117</a></p>
</div>
<div id="ref-AtapBaNb">
<p>97. <strong>Biomarker definitions and their applications</strong> <br />
Robert M Califf<br />
<em>Experimental Biology and Medicine</em> (2018-02-06) <a href="https://doi.org/gcxh8n">https://doi.org/gcxh8n</a> <br />
DOI: <a href="https://doi.org/10.1177/1535370217750088">10.1177/1535370217750088</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29405771">29405771</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5813875">PMC5813875</a></p>
</div>
<div id="ref-17aD4MFPS">
<p>98. <strong>Biomarker signatures of aging</strong> <br />
Paola Sebastiani, Bharat Thyagarajan, Fangui Sun, Nicole Schupf, Anne B. Newman, Monty Montano, Thomas T. Perls<br />
<em>Aging Cell</em> (2017-04) <a href="https://doi.org/d2cm">https://doi.org/d2cm</a> <br />
DOI: <a href="https://doi.org/10.1111/acel.12557">10.1111/acel.12557</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28058805">28058805</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5334528">PMC5334528</a></p>
</div>
<div id="ref-XWx8RAwW">
<p>99. <strong>Biomarker Panels in Critical Care</strong> <br />
Susan R. Conway, Hector R. Wong<br />
<em>Critical Care Clinics</em> (2020-01) <a href="https://doi.org/d2cn">https://doi.org/d2cn</a> <br />
DOI: <a href="https://doi.org/10.1016/j.ccc.2019.08.007">10.1016/j.ccc.2019.08.007</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31733684">31733684</a></p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Supposes a thesis (e.g. the guilt of an accused man) is supported by a great deal of circumstantial evidence of different forms, but in agreement with each other; then even if each piece of evidence is in itself insufficient to produce any strong belief, the thesis is decisively strengthened by their joint effect.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!-- default theme -->

<style>
    /* import google fonts */
    @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
    @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

    /* -------------------------------------------------- */
    /* global */
    /* -------------------------------------------------- */

    /* all elements */
    * {
        /* force sans-serif font unless specified otherwise */
        font-family: "Open Sans", "Helvetica", sans-serif;

        /* prevent text inflation on some mobile browsers */
        -webkit-text-size-adjust: none !important;
        -moz-text-size-adjust: none !important;
        -o-text-size-adjust: none !important;
        text-size-adjust: none !important;
    }

    @media only screen {
        /* "page" element */
        body {
            position: relative;
            box-sizing: border-box;
            font-size: 12pt;
            line-height: 1.5;
            max-width: 8.5in;
            margin: 20px auto;
            padding: 40px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* "page" element */
        body {
            padding: 20px;
            margin: 0;
            border-radius: 0;
            border: none;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
            background: none;
        }
    }

    /* -------------------------------------------------- */
    /* headings */
    /* -------------------------------------------------- */

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 20px 0;
        padding: 0;
        font-weight: bold;
    }

    /* biggest heading */
    h1 {
        margin: 40px 0;
        text-align: center;
    }

    /* second biggest heading */
    h2 {
        margin-top: 30px;
        padding-bottom: 5px;
        border-bottom: solid 1px #bdbdbd;
    }

    /* heading font sizes */
    h1 {
        font-size: 2em;
    }
    h2 {
        font-size: 1.5em;
    }
    h3{
        font-size: 1.35em;
    }
    h4 {
        font-size: 1.25em;
    }
    h5 {
        font-size: 1.15em;
    }
    h6 {
        font-size: 1em;
    }

    /* -------------------------------------------------- */
    /* manuscript header */
    /* -------------------------------------------------- */

    /* manuscript title */
    header > h1 {
        margin: 0;
    }

    /* manuscript title caption text (ie "automatically generated on") */
    header + p {
        text-align: center;
        margin-top: 10px;
    }

    /* -------------------------------------------------- */
    /* text elements */
    /* -------------------------------------------------- */

    /* links */
    a {
        color: #2196f3;
        overflow-wrap: break-word;
    }

    /* normal links (not empty, not button link, not syntax highlighting link) */
    a:not(:empty):not(.button):not(.sourceLine) {
        padding-left: 1px;
        padding-right: 1px;
    }

    /* superscripts and subscripts */
    sub,
    sup {
        /* prevent from affecting line height */
        line-height: 0;
    }

    /* unordered and ordered lists*/
    ul,
    ol {
        padding-left: 20px;
    }

    /* class for styling text semibold */
    .semibold {
        font-weight: 600;
    }

    /* class for styling elements horizontally left aligned */
    .left {
        display: block;
        text-align: left;
        margin-left: auto;
        margin-right: 0;
        justify-content: left;
    }

    /* class for styling elements horizontally centered */
    .center {
        display: block;
        text-align: center;
        margin-left: auto;
        margin-right: auto;
        justify-content: center;
    }

    /* class for styling elements horizontally right aligned */
    .right {
        display: block;
        text-align: right;
        margin-left: 0;
        margin-right: auto;
        justify-content: right;
    }

    /* -------------------------------------------------- */
    /* section elements */
    /* -------------------------------------------------- */

    /* horizontal divider line */
    hr {
        border: none;
        height: 1px;
        background: #bdbdbd;
    }

    /* paragraphs, horizontal dividers, figures, tables, code */
    p,
    hr,
    figure,
    table,
    pre {
        /* treat all as "paragraphs", with consistent vertical margins */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* figures */
    /* -------------------------------------------------- */

    /* figure */
    figure {
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure caption */
    figcaption {
        padding: 0;
        padding-top: 10px;
    }

    /* figure image element */
    figure img {
        max-width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure auto-number */
    img + figcaption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* tables */
    /* -------------------------------------------------- */

    /* table */
    table {
        border-collapse: collapse;
        border-spacing: 0;
        width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* table cells */
    th,
    td {
        border: solid 1px #bdbdbd;
        padding: 10px;
        /* squash table if too wide for page by forcing line breaks */
        overflow-wrap: break-word;
        word-break: break-word;
    }

    /* header row and even rows */
    th,
    tr:nth-child(2n) {
        background-color: #fafafa;
    }

    /* odd rows */
    tr:nth-child(2n + 1) {
        background-color: #ffffff;
    }

    /* table caption */
    caption {
        text-align: left;
        padding: 0;
        padding-bottom: 10px;
    }

    /* table auto-number */
    table > caption > span:first-of-type,
    div.table_wrapper > table > caption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* code */
    /* -------------------------------------------------- */

    /* multi-line code block */
    pre {
        padding: 10px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
        break-inside: avoid;
        text-align: left;
    }

    /* inline code, ie code within normal text */
    :not(pre) > code {
        padding: 0 4px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
    }

    /* code text */
    /* apply all children, to reach syntax highlighting sub-elements */
    code,
    code * {
        /* force monospace font */
        font-family: "Source Code Pro", "Courier New", monospace;
    }

    /* -------------------------------------------------- */
    /* quotes */
    /* -------------------------------------------------- */

    /* quoted text */
    blockquote {
        margin: 0;
        padding: 0;
        border-left: 4px solid #bdbdbd;
        padding-left: 16px;
        break-inside: avoid;
    }

    /* -------------------------------------------------- */
    /* banners */
    /* -------------------------------------------------- */

    /* info banners */
    .banner {
        box-sizing: border-box;
        display: block;
        position: relative;
        width: 100%;
        margin-top: 20px;
        margin-bottom: 20px;
        padding: 20px;
        text-align: center;
    }

    /* paragraph in banner */
    .banner > p {
        margin: 0;
    }

    /* -------------------------------------------------- */
    /* highlight colors */
    /* -------------------------------------------------- */

    .white {
        background: #ffffff;
    }
    .lightgrey {
        background: #eeeeee;
    }
    .grey {
        background: #757575;
    }
    .darkgrey {
        background: #424242;
    }
    .black {
        background: #000000;
    }
    .lightred {
        background: #ffcdd2;
    }
    .lightyellow {
        background: #ffecb3;
    }
    .lightgreen {
        background: #dcedc8;
    }
    .lightblue {
        background: #e3f2fd;
    }
    .lightpurple {
        background: #f3e5f5;
    }
    .red {
        background: #f44336;
    }
    .orange {
        background: #ff9800;
    }
    .yellow {
        background: #ffeb3b;
    }
    .green {
        background: #4caf50;
    }
    .blue {
        background: #2196f3;
    }
    .purple {
        background: #9c27b0;
    }
    .white,
    .lightgrey,
    .lightred,
    .lightyellow,
    .lightgreen,
    .lightblue,
    .lightpurple,
    .orange,
    .yellow,
    .white a,
    .lightgrey a,
    .lightred a,
    .lightyellow a,
    .lightgreen a,
    .lightblue a,
    .lightpurple a,
    .orange a,
    .yellow a {
        color: #000000;
    }
    .grey,
    .darkgrey,
    .black,
    .red,
    .green,
    .blue,
    .purple,
    .grey a,
    .darkgrey a,
    .black a,
    .red a,
    .green a,
    .blue a,
    .purple a {
        color: #ffffff;
    }

    /* -------------------------------------------------- */
    /* buttons */
    /* -------------------------------------------------- */

    /* class for styling links like buttons */
    .button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        margin: 5px;
        padding: 10px 20px;
        font-size: 0.75em;
        font-weight: 600;
        text-transform: uppercase;
        text-decoration: none;
        letter-spacing: 1px;
        background: none;
        color: #2196f3;
        border: solid 1px #bdbdbd;
        border-radius: 5px;
    }

    /* buttons when hovered */
    .button:hover:not([disabled]),
    .icon_button:hover:not([disabled]) {
        cursor: pointer;
        background: #f5f5f5;
    }

    /* buttons when disabled */
    .button[disabled],
    .icon_button[disabled] {
        opacity: 0.35;
        pointer-events: none;
    }

    /* class for styling buttons containg only single icon */
    .icon_button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        text-decoration: none;
        margin: 0;
        padding: 0;
        background: none;
        border-radius: 5px;
        border: none;
        width: 20px;
        height: 20px;
        min-width: 20px;
        min-height: 20px;
    }

    /* icon button inner svg image */
    .icon_button > svg {
        height: 16px;
    }

    /* -------------------------------------------------- */
    /* icons */
    /* -------------------------------------------------- */

    /* class for styling icons inline with text */
    .inline_icon {
        height: 1em;
        position: relative;
        top: 0.125em;
    }

    /* -------------------------------------------------- */
    /* print control */
    /* -------------------------------------------------- */

    @media print {
        @page {
            /* suggested printing margin */
            margin: 0.5in;
        }

        /* document and "page" elements */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
        }

        /* "page" element */
        body {
            font-size: 11pt !important;
            line-height: 1.35;
        }

        /* all headings */
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            margin: 15px 0;
        }

        /* figures and tables */
        figure, table {
            font-size: 0.85em;
        }

        /* table cells */
        th,
        td {
            padding: 5px;
        }

        /* shrink font awesome icons */
        i.fas,
        i.fab,
        i.far,
        i.fal {
            transform: scale(0.85);
        }

        /* decrease banner margins */
        .banner {
            margin-top: 15px;
            margin-bottom: 15px;
            padding: 15px;
        }

        /* class for centering an element vertically on its own page */
        .page_center {
            margin: auto;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            vertical-align: middle;
            break-before: page;
            break-after: page;
        }

        /* always insert a page break before the element */
        .page_break_before {
            break-before: page;
        }

        /* always insert a page break after the element */
        .page_break_after {
            break-after: page;
        }

        /* avoid page break before the element */
        .page_break_before_avoid {
            break-before: avoid;
        }

        /* avoid page break after the element */
        .page_break_after_avoid {
            break-after: avoid;
        }

        /* avoid page break inside the element */
        .page_break_inside_avoid {
            break-inside: avoid;
        }
    }

    /* -------------------------------------------------- */
    /* override pandoc css quirks */
    /* -------------------------------------------------- */

    .sourceCode {
        /* prevent unsightly overflow in wide code blocks */
        overflow: auto !important;
    }

    div.sourceCode {
        /* prevent background fill on top-most code block  container */
        background: none !important;
    }

    .sourceCode * {
        /* force consistent line spacing */
        line-height: 1.5 !important;
    }

    div.sourceCode {
        /* style code block margins same as <pre> element */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* tablenos */
    /* -------------------------------------------------- */

    /* tablenos wrapper */
    .tablenos {
        /* show scrollbar on tables if necessary to prevent overflow */
        width: 100%;
        margin: 20px 0;
    }

    .tablenos > table {
        /* move margins from table to table_wrapper to allow margin collapsing */
        margin: 0;
    }

    @media only screen {
        /* tablenos wrapper */
        .tablenos {
            /* show scrollbar on tables if necessary to prevent overflow */
            overflow-x: auto !important;
        }

        .tablenos th,
        .tablenos td {
            overflow-wrap: unset !important;
            word-break: unset !important;
        }

        /* table in wrapper */
        .tablenos table,
        .tablenos table * {
            /* don't break table words */
            overflow-wrap: normal !important;
        }
    }

    /* -------------------------------------------------- */
    /* mathjax */
    /* -------------------------------------------------- */

    /* mathjax containers */
    .math.display > span:not(.MathJax_Preview) {
        /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
        display: flex !important;
        overflow-x: auto !important;
        overflow-y: hidden !important;
        justify-content: center;
        align-items: center;
        margin: 0 !important;
    }

    /* right click menu */
    .MathJax_Menu {
        border-radius: 5px !important;
        border: solid 1px #bdbdbd !important;
        box-shadow: none !important;
    }

    /* equation auto-number */
    span[id^="eq:"] > span.math.display + span {
        font-weight: 600;
    }

    /* equation */
    span[id^="eq:"] > span.math.display > span {
        /* nudge to make room for equation auto-number and anchor */
        margin-right: 60px !important;
    }

    /* -------------------------------------------------- */
    /* anchors plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anchor button */
        .anchor {
            opacity: 0;
            margin-left: 5px;
        }

        /* anchor buttons within <h2>'s */
        h2 .anchor {
            margin-left: 10px;
        }

        /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
        *:hover > .anchor,
        .anchor:hover,
        .anchor:focus {
            opacity: 1;
        }

        /* anchor button when hovered */
        .anchor:hover {
            cursor: pointer;
        }
    }

    /* always show anchor button on devices with no mouse/hover ability */
    @media (hover: none) {
        .anchor {
            opacity: 1;
        }
    }

    /* always hide anchor button on print */
    @media only print {
        .anchor {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* accordion plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* accordion arrow button */
        .accordion_arrow {
            margin-right: 10px;
        }

        /* arrow icon when <h2> data-collapsed attribute true */
        h2[data-collapsed="true"] > .accordion_arrow > svg {
            transform: rotate(-90deg);
        }

        /* all elements (except <h2>'s) when data-collapsed attribute true */
        *:not(h2)[data-collapsed="true"] {
            display: none;
        }

        /* accordion arrow button when hovered and <h2>'s when hovered */
        .accordion_arrow:hover,
        h2[data-collapsed="true"]:hover,
        h2[data-collapsed="false"]:hover {
            cursor: pointer;
        }
    }

    /* always hide accordion arrow button on print */
    @media only print {
        .accordion_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* tooltips plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* tooltip container */
        #tooltip {
            position: absolute;
            width: 50%;
            min-width: 240px;
            max-width: 75%;
            z-index: 1;
        }

        /* tooltip content */
        #tooltip_content {
            margin-bottom: 5px;
            padding: 20px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
            overflow-wrap: break-word;
        }

        /* tooltip copy of paragraphs and figures */
        #tooltip_content > p,
        #tooltip_content > figure {
            margin: 0;
            max-height: 320px;
            overflow-y: auto;
        }

        /* tooltip copy of <img> */
        #tooltip_content > figure > img {
            max-height: 260px;
        }

        /* navigation bar */
        #tooltip_nav_bar {
            margin-top: 10px;
            text-align: center;
        }

        /* navigation bar previous/next buton */
        #tooltip_nav_bar > .icon_button {
            position: relative;
            top: 3px;
        }

        /* navigation bar previous button */
        #tooltip_nav_bar > .icon_button:first-of-type {
            margin-right: 5px;
        }

        /* navigation bar next button */
        #tooltip_nav_bar > .icon_button:last-of-type {
            margin-left: 5px;
        }
    }

    /* always hide tooltip on print */
    @media only print {
        #tooltip {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* jump to first plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* jump button */
        .jump_arrow {
            position: relative;
            top: 0.125em;
            margin-right: 5px;
        }
    }

    /* always hide jump button on print */
    @media only print {
        .jump_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* link highlight plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anything with data-highlighted attribute true */
        [data-highlighted="true"] {
            background: #ffeb3b;
        }

        /* anything with data-selected attribute true */
        [data-selected="true"] {
            background: #ff8a65 !important;
        }

        /* animation definition for glow */
        @keyframes highlight_glow {
            0% {
                background: none;
            }
            10% {
                background: #bbdefb;
            }
            100% {
                background: none;
            }
        }

        /* anything with data-glow attribute true */
        [data-glow="true"] {
            animation: highlight_glow 2s;
        }
    }

    /* -------------------------------------------------- */
    /* table of contents plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* toc panel */
        #toc_panel {
            box-sizing: border-box;
            position: fixed;
            top: 0;
            left: 0;
            background: #ffffff;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            z-index: 2;
        }

        /* toc panel when closed */
        #toc_panel[data-open="false"] {
            min-width: 60px;
            width: 60px;
            height: 60px;
            border-right: solid 1px #bdbdbd;
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc panel when open */
        #toc_panel[data-open="true"] {
            min-width: 260px;
            max-width: 480px;
            /* keep panel edge consistent distance away from "page" edge */
            width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
            bottom: 0;
            border-right: solid 1px #bdbdbd;
        }

        /* toc panel header */
        #toc_header {
            box-sizing: border-box;
            display: flex;
            flex-direction: row;
            align-items: center;
            height: 60px;
            margin: 0;
            padding: 20px;
        }

        /* toc panel header when hovered */
        #toc_header:hover {
            cursor: pointer;
        }

        /* toc panel header when panel open */
        #toc_panel[data-open="true"] > #toc_header {
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc open/close header button */
        #toc_button {
            margin-right: 20px;
        }

        /* hide toc list and header text when closed */
        #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
        #toc_panel[data-open="false"] > #toc_list {
            display: none;
        }

        /* toc list of entries */
        #toc_list {
            box-sizing: border-box;
            width: 100%;
            padding: 20px;
            position: absolute;
            top: calc(60px + 1px);
            bottom: 0;
            overflow: auto;
        }

        /* toc entry, link to section in document */
        .toc_link {
            display: block;
            padding: 5px;
            position: relative;
            font-weight: 600;
            text-decoration: none;
        }

        /* toc entry when hovered or when "viewed" */
        .toc_link:hover,
        .toc_link[data-viewing="true"] {
            background: #f5f5f5;
        }

        /* toc entry, level 1 indentation */
        .toc_link[data-level="1"] {
            margin-left: 0;
        }

        /* toc entry, level 2 indentation */
        .toc_link[data-level="2"] {
            margin-left: 20px;
        }

        /* toc entry, level 3 indentation */
        .toc_link[data-level="3"] {
            margin-left: 40px;
        }

        /* toc entry, level 4 indentation */
        .toc_link[data-level="4"] {
            margin-left: 60px;
        }

        /* toc entry bullets */
        #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
            position: absolute;
            left: -15px;
            top: -1px;
            font-size: 1.5em;
        }

        /* toc entry, level 2 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
            content: "\2022";
        }

        /* toc entry, level 3 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
            content: "\25AB";
        }

        /* toc entry, level 4 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
            content: "-";
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* push <body> ("page") element down to make room for toc icon */
        .toc_body_nudge {
            padding-top: 60px;
        }

        /* toc icon when panel closed and not hovered */
        #toc_panel[data-open="false"]:not(:hover) {
            background: rgba(255, 255, 255, 0.75);
        }
    }

    /* always hide toc panel on print */
    @media only print {
        #toc_panel {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* lightbox plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* regular <img> in document when hovered */
        .lightbox_document_img:hover {
            cursor: pointer;
        }

        .body_no_scroll {
            overflow: hidden !important;
        }

        /* screen overlay */
        #lightbox_overlay {
            display: flex;
            flex-direction: column;
            position: fixed;
            left: 0;
            top: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.75);
            z-index: 3;
        }

        /* middle area containing lightbox image */
        #lightbox_image_container {
            flex-grow: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            position: relative;
            padding: 20px;
        }

        /* bottom area containing caption */
        #lightbox_bottom_container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100px;
            min-height: 100px;
            max-height: 100px;
            background: rgba(0, 0, 0, 0.5);
        }

        /* image number info text box */
        #lightbox_number_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            left: 2px;
            top: 0;
            z-index: 4;
        }

        /* zoom info text box */
        #lightbox_zoom_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            right: 2px;
            top: 0;
            z-index: 4;
        }

        /* copy of image caption */
        #lightbox_caption {
            box-sizing: border-box;
            display: inline-block;
            width: 100%;
            max-height: 100%;
            padding: 10px 0;
            text-align: center;
            overflow-y: auto;
            color: #ffffff;
        }

        /* navigation previous/next button */
        .lightbox_button {
            width: 100px;
            height: 100%;
            min-width: 100px;
            min-height: 100%;
            color: #ffffff;
        }

        /* navigation previous/next button when hovered */
        .lightbox_button:hover {
            background: none !important;
        }

        /* navigation button icon */
        .lightbox_button > svg {
            height: 25px;
        }

        /* figure auto-number */
        #lightbox_caption > span:first-of-type {
            font-weight: bold;
            margin-right: 5px;
        }

        /* lightbox image when hovered */
        #lightbox_img:hover {
            cursor: grab;
        }

        /* lightbox image when grabbed */
        #lightbox_img:active {
            cursor: grabbing;
        }
    }

    /* when on screen < 480px wide */
    @media only screen and (max-width: 480px) {
        /* make navigation buttons skinnier on small screens to make more room for caption text */
        .lightbox_button {
            width: 50px;
            min-width: 50px;
        }
    }

    /* always hide lightbox on print */
    @media only print {
        #lightbox_overlay {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* hypothesis (annotations) plugin */
    /* -------------------------------------------------- */

    /* hypothesis activation button */
    #hypothesis_button {
        box-sizing: border-box;
        position: fixed;
        top: 0;
        right: 0;
        width: 60px;
        height: 60px;
        background: #ffffff;
        border-radius: 0;
        border-left: solid 1px #bdbdbd;
        border-bottom: solid 1px #bdbdbd;
        box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
        z-index: 2;
    }

    /* hypothesis button svg */
    #hypothesis_button > svg {
        position: relative;
        top: -4px;
    }

    /* hypothesis annotation count */
    #hypothesis_count {
        position: absolute;
        left: 0;
        right: 0;
        bottom: 5px;
    }

    /* side panel */
    .annotator-frame {
        width: 280px !important;
    }

    /* match highlight color to rest of theme */
    .annotator-highlights-always-on .annotator-hl {
        background-color: #ffeb3b !important;
    }

    /* match focused color to rest of theme */
    .annotator-hl.annotator-hl-focused {
        background-color: #ff8a65 !important;
    }

    /* match bucket bar color to rest of theme */
    .annotator-bucket-bar {
        background: #f5f5f5 !important;
    }

    /* always hide button, toolbar, and tooltip on print */
    @media only print {
        #hypothesis_button {
            display: none;
        }

        .annotator-frame {
            display: none !important;
        }

        hypothesis-adder {
            display: none !important;
        }
    }
</style>
<!-- anchors plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds an anchor next to each of a certain type
        // of element that provides a human-readable url to that specific
        // item/position in the document (eg "manuscript.html#abstract"). It
        // also makes it such that scrolling out of view of a target removes
        // its identifier from the url.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'anchors';

        // default plugin options
        const options = {
            // which types of elements to add anchors next to, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3, [id^="fig:"], [id^="tbl:"], [id^="eq:"]',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // add anchor to each element of specified types
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements)
                addAnchor(element);

            // attach scroll listener to window
            window.addEventListener('scroll', onScroll);
        }

        // when window is scrolled
        function onScroll() {
            // if url has hash and user has scrolled out of view of hash
            // target, remove hash from url
            const tolerance = 100;
            const target = getHashTarget();
            if (target) {
                if (
                    target.getBoundingClientRect().top >
                        window.innerHeight + tolerance ||
                    target.getBoundingClientRect().bottom < 0 - tolerance
                )
                    history.pushState(null, null, ' ');
            }
        }

        // add anchor to element
        function addAnchor(element) {
            let addTo; // element to add anchor button to

            // if figure or table, modify withId and addTo to get expected
            // elements
            if (element.id.indexOf('fig:') === 0) {
                addTo = element.querySelector('figcaption');
            } else if (element.id.indexOf('tbl:') === 0) {
                addTo = element.querySelector('caption');
            } else if (element.id.indexOf('eq:') === 0) {
                addTo = element.querySelector('.eqnos-number');
            }

            addTo = addTo || element;
            const id = element.id || null;

            // do not add anchor if element doesn't have assigned id.
            // id is generated by pandoc and is assumed to be unique and
            // human-readable
            if (!id)
                return;

            // create anchor button
            const anchor = document.createElement('a');
            anchor.innerHTML = document.querySelector('.icon_link').innerHTML;
            anchor.title = 'Link to this part of the document';
            anchor.classList.add('icon_button', 'anchor');
            anchor.dataset.ignore = 'true';
            anchor.href = '#' + id;
            addTo.appendChild(anchor);
        }

        // get element that is target of link or url hash
        function getHashTarget() {
            const hash = window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- link icon -->

<template class="icon_link">
    <!-- modified from: https://fontawesome.com/icons/link -->
    <svg width="16" height="16" viewBox="0 0 512 512">
        <path
            fill="currentColor"
            d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
        ></path>
    </svg>
</template>
<!-- accordion plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows sections of content under <h2> headings
        // to be collapsible.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'accordion';

        // default plugin options
        const options = {
            // whether to always start expanded ('false'), always start
            // collapsed ('true'), or start collapsed when screen small ('auto')
            startCollapsed: 'auto',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <h2> heading
            const headings = document.querySelectorAll('h2');
            for (const heading of headings) {
                addArrow(heading);

                // start expanded/collapsed based on option
                if (
                    options.startCollapsed === 'true' ||
                    (options.startCollapsed === 'auto' && isSmallScreen())
                )
                    collapseHeading(heading);
                else
                    expandHeading(heading);
            }

            // attach hash change listener to window
            window.addEventListener('hashchange', onHashChange);
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                goToElement(target);
        }

        // add arrow to heading
        function addArrow(heading) {
            // add arrow button
            const arrow = document.createElement('button');
            arrow.innerHTML = document.querySelector(
                '.icon_angle_down'
            ).innerHTML;
            arrow.classList.add('icon_button', 'accordion_arrow');
            heading.insertBefore(arrow, heading.firstChild);

            // attach click listener to heading and button
            heading.addEventListener('click', onHeadingClick);
            arrow.addEventListener('click', onArrowClick);
        }

        // determine if on mobile-like device with small screen
        function isSmallScreen() {
            return Math.min(window.innerWidth, window.innerHeight) < 480;
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get element that is target of hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // when <h2> heading is clicked
        function onHeadingClick(event) {
            // only collapse if <h2> itself is target of click (eg, user did
            // not click on anchor within <h2>)
            if (event.target === this)
                toggleCollapse(this);
        }

        // when arrow button is clicked
        function onArrowClick() {
            toggleCollapse(this.parentNode);
        }

        // collapse section if expanded, expand if collapsed
        function toggleCollapse(heading) {
            if (heading.dataset.collapsed === 'false')
                collapseHeading(heading);
            else
                expandHeading(heading);
        }

        // elements to exclude from collapse, such as table of contents panel,
        // hypothesis panel, etc
        const exclude = '#toc_panel, div.annotator-frame, #lightbox_overlay';

        // collapse section
        function collapseHeading(heading) {
            heading.setAttribute('data-collapsed', 'true');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'true');
        }

        // expand section
        function expandHeading(heading) {
            heading.setAttribute('data-collapsed', 'false');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'false');
        }

        // get list of elements between this <h2> and next <h2> or <h1>
        // ("children" of the <h2> section)
        function getChildren(heading) {
            return nextUntil(heading, 'h2, h1', exclude);
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get list of elements after a start element up to element matching
        // query
        function nextUntil(element, query, exclude) {
            const elements = [];
            while (element = element.nextElementSibling, element) {
                if (element.matches(query))
                    break;
                if (!element.matches(exclude))
                    elements.push(element);
            }
            return elements;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
    <!-- modified from: https://fontawesome.com/icons/angle-down -->
    <svg width="16" height="16" viewBox="0 0 448 512">
        <path
            fill="currentColor"
            d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
        ></path>
    </svg>
</template>
<!-- tooltips plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when the user hovers or
        // focuses a link to a citation or figure, a tooltip appears with a
        // preview of the reference content, along with arrows to navigate
        // between instances of the same reference in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tooltips';

        // default plugin options
        const options = {
            // whether user must click off to close tooltip instead of just
            // un-hovering
            clickClose: 'false',
            // delay (in ms) between opening and closing tooltip
            delay: '100',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach hover and focus listeners to link
                link.addEventListener('mouseover', onLinkHover);
                link.addEventListener('mouseleave', onLinkUnhover);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('touchend', onLinkTouch);
            }

            // attach mouse, key, and resize listeners to window
            window.addEventListener('mousedown', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('keyup', onKeyUp);
            window.addEventListener('resize', onResize);
        }

        // when link is hovered
        function onLinkHover() {
            // function to open tooltip
            const delayOpenTooltip = function() {
                openTooltip(this);
            }.bind(this);

            // run open function after delay
            this.openTooltipTimer = window.setTimeout(
                delayOpenTooltip,
                options.delay
            );
        }

        // when mouse leaves link
        function onLinkUnhover() {
            // cancel opening tooltip
            window.clearTimeout(this.openTooltipTimer);

            // don't close on unhover if option specifies
            if (options.clickClose === 'true')
                return;

            // function to close tooltip
            const delayCloseTooltip = function() {
                // if tooltip open and if mouse isn't over tooltip, close
                const tooltip = document.getElementById('tooltip');
                if (tooltip && !tooltip.matches(':hover'))
                    closeTooltip();
            };

            // run close function after delay
            this.closeTooltipTimer = window.setTimeout(
                delayCloseTooltip,
                options.delay
            );
        }

        // when link is focused (tabbed to)
        function onLinkFocus(event) {
            openTooltip(this);
        }

        // when link is touched on touch screen
        function onLinkTouch(event) {
            // attempt to force hover state on first tap always, and trigger
            // regular link click (and navigation) on second tap
            if (event.target === document.activeElement)
                event.target.click();
            else {
                document.activeElement.blur();
                event.target.focus();
            }
            if (event.cancelable)
                event.preventDefault();
            event.stopPropagation();
            return false;
        }

        // when mouse is clicked anywhere in window
        function onClick(event) {
            closeTooltip();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'tooltip_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'tooltip_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeTooltip();
                    break;
            }
        }

        // when window is resized or zoomed
        function onResize() {
            closeTooltip();
        }

        // get all links of types we wish to handle
        function getLinks() {
            const queries = [];
            // exclude buttons, anchor links, toc links, etc
            const exclude =
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            queries.push('a[href^="#ref-"]' + exclude); // citation links
            queries.push('a[href^="#fig:"]' + exclude); // figure links
            const query = queries.join(', ');
            return document.querySelectorAll(query);
        }

        // get links with same target, get index of link in set, get total
        // same links
        function getSameLinks(link) {
            const sameLinks = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    sameLinks.push(otherLink);
            }

            return {
                elements: sameLinks,
                index: sameLinks.indexOf(link),
                total: sameLinks.length
            };
        }

        // open tooltip
        function openTooltip(link) {
            // delete tooltip if it exists, start fresh
            closeTooltip();

            // make tooltip element
            const tooltip = makeTooltip(link);

            // if source couldn't be found and tooltip not made, exit
            if (!tooltip)
                return;

            // make navbar elements
            const navBar = makeNavBar(link);
            if (navBar)
                tooltip.firstElementChild.appendChild(navBar);

            // attach tooltip to page
            document.body.appendChild(tooltip);

            // position tooltip
            const position = function() {
                positionTooltip(link);
            };
            position();

            // if tooltip contains images, position again after they've loaded
            const imgs = tooltip.querySelectorAll('img');
            for (const img of imgs)
                img.addEventListener('load', position);
        }

        // close (delete) tooltip
        function closeTooltip() {
            const tooltip = document.getElementById('tooltip');
            if (tooltip)
                tooltip.remove();
        }

        // make tooltip
        function makeTooltip(link) {
            // get target element that link points to
            const source = getSource(link);

            // if source can't be found, exit
            if (!source)
                return;

            // create new tooltip
            const tooltip = document.createElement('div');
            tooltip.id = 'tooltip';
            const tooltipContent = document.createElement('div');
            tooltipContent.id = 'tooltip_content';
            tooltip.appendChild(tooltipContent);

            // make copy of source node and put in tooltip
            const sourceCopy = makeCopy(source);
            tooltipContent.appendChild(sourceCopy);

            // attach mouse event listeners
            tooltip.addEventListener('click', onTooltipClick);
            tooltip.addEventListener('mousedown', onTooltipClick);
            tooltip.addEventListener('touchstart', onTooltipClick);
            tooltip.addEventListener('mouseleave', onTooltipUnhover);

            // (for interaction with lightbox plugin)
            // transfer click on tooltip copied img to original img
            const sourceImg = source.querySelector('img');
            const sourceCopyImg = sourceCopy.querySelector('img');
            if (sourceImg && sourceCopyImg) {
                const clickImg = function() {
                    sourceImg.click();
                    closeTooltip();
                };
                sourceCopyImg.addEventListener('click', clickImg);
            }

            return tooltip;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // when tooltip is clicked
        function onTooltipClick(event) {
            // when user clicks on tooltip, stop click from transferring
            // outside of tooltip (eg, click off to close tooltip, or eg click
            // off to unhighlight same refs)
            event.stopPropagation();
        }

        // when tooltip is unhovered
        function onTooltipUnhover(event) {
            if (options.clickClose === 'true')
                return;

            // make sure new mouse/touch/focus no longer over tooltip or any
            // element within it
            const tooltip = document.getElementById('tooltip');
            if (!tooltip)
                return;
            if (this.contains(event.relatedTarget))
                return;

            closeTooltip();
        }

        // make nav bar to go betwen prev/next instances of same reference
        function makeNavBar(link) {
            // find other links to the same source
            const sameLinks = getSameLinks(link);

            // don't show nav bar when singular reference
            if (sameLinks.total <= 1)
                return;

            // find prev/next links with same target
            const prevLink = getPrevLink(link, sameLinks);
            const nextLink = getNextLink(link, sameLinks);

            // create nav bar
            const navBar = document.createElement('div');
            navBar.id = 'tooltip_nav_bar';
            const text = sameLinks.index + 1 + ' of ' + sameLinks.total;

            // create nav bar prev/next buttons
            const prevButton = document.createElement('button');
            const nextButton = document.createElement('button');
            prevButton.id = 'tooltip_prev_button';
            nextButton.id = 'tooltip_next_button';
            prevButton.title =
                'Jump to the previous occurence of this item in the document [←]';
            nextButton.title =
                'Jump to the next occurence of this item in the document [→]';
            prevButton.classList.add('icon_button');
            nextButton.classList.add('icon_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;
            navBar.appendChild(prevButton);
            navBar.appendChild(document.createTextNode(text));
            navBar.appendChild(nextButton);

            // attach click listeners to buttons
            prevButton.addEventListener('click', function() {
                onPrevNextClick(link, prevLink);
            });
            nextButton.addEventListener('click', function() {
                onPrevNextClick(link, nextLink);
            });

            return navBar;
        }

        // get previous link with same target
        function getPrevLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if < 1
            let index;
            if (sameLinks.index - 1 >= 0)
                index = sameLinks.index - 1;
            else
                index = sameLinks.total - 1;
            return sameLinks.elements[index];
        }

        // get next link with same target
        function getNextLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if > total
            let index;
            if (sameLinks.index + 1 <= sameLinks.total - 1)
                index = sameLinks.index + 1;
            else
                index = 0;
            return sameLinks.elements[index];
        }

        // get element that is target of link or url hash
        function getSource(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if ref or figure, modify target to get expected element
            if (id.indexOf('ref-') === 0)
                target = target.querySelector('p');
            else if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');

            return target;
        }

        // when prev/next arrow button is clicked
        function onPrevNextClick(link, prevNextLink) {
            if (link && prevNextLink)
                goToElement(prevNextLink, window.innerHeight * 0.5);
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // determine position to place tooltip based on link position in
        // viewport and tooltip size
        function positionTooltip(link, left, top) {
            const tooltipElement = document.getElementById('tooltip');
            if (!tooltipElement)
                return;

            // get convenient vars for position/dimensions of
            // link/tooltip/page/view
            link = getRectInPage(link);
            const tooltip = getRectInPage(tooltipElement);
            const view = getRectInPage();

            // horizontal positioning
            if (left)
                // use explicit value
                left = left;
            else if (link.left + tooltip.width < view.right)
                // fit tooltip to right of link
                left = link.left;
            else if (link.right - tooltip.width > view.left)
                // fit tooltip to left of link
                left = link.right - tooltip.width;
            // center tooltip in view
            else
                left = (view.right - view.left) / 2 - tooltip.width / 2;

            // vertical positioning
            if (top)
                // use explicit value
                top = top;
            else if (link.top - tooltip.height > view.top)
                // fit tooltip above link
                top = link.top - tooltip.height;
            else if (link.bottom + tooltip.height < view.bottom)
                // fit tooltip below link
                top = link.bottom;
            else {
                // center tooltip in view
                top = view.top + view.height / 2 - tooltip.height / 2;
                // nudge off of link to left/right if possible
                if (link.right + tooltip.width < view.right)
                    left = link.right;
                else if (link.left - tooltip.width > view.left)
                    left = link.left - tooltip.width;
            }

            tooltipElement.style.left = left + 'px';
            tooltipElement.style.top = top + 'px';
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get position of element relative to page
        function getRectInPage(element) {
            const rect = getRectInView(element);
            const body = getRectInView(document.body);

            const newRect = {};
            newRect.left = rect.left - body.left;
            newRect.top = rect.top - body.top;
            newRect.right = rect.right - body.left;
            newRect.bottom = rect.bottom - body.top;
            newRect.width = rect.width;
            newRect.height = rect.height;

            return newRect;
        }

        // (for interaction with accordion plugin)
        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // (for interaction with accordion plugin)
        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- jump to first plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds a button next to each reference entry,
        // figure, and table that jumps the page to the first occurrence of a
        // link to that item in the manuscript.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'jumpToFirst';

        // default plugin options
        const options = {
            // whether to add buttons next to reference entries
            references: 'true',
            // whether to add buttons next to figures
            figures: 'true',
            // whether to add buttons next to tables
            tables: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            if (options.references !== 'false')
                makeReferenceButtons();
            if (options.figures !== 'false')
                makeFigureButtons();
            if (options.tables !== 'false')
                makeTableButtons();
        }

        // when jump button clicked
        function onButtonClick() {
            const first = getFirstOccurrence(this.dataset.id);
            if (!first)
                return;

            // update url hash so navigating "back" in history will return
            // user to jump button
            window.location.hash = this.dataset.id;
            // scroll to link
            window.setTimeout(function() {
                goToElement(first, window.innerHeight * 0.5);
            }, 0);
        }

        // get first occurence of link to item in document
        function getFirstOccurrence(id) {
            let query = 'a';
            query += '[href="#' + id + '"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelector(query);
        }

        // add button next to each reference entry
        function makeReferenceButtons() {
            const references = document.querySelectorAll('div[id^="ref-"]');
            for (const reference of references) {
                // get reference id and element to add button to
                const id = reference.id;
                const container = reference.firstElementChild;
                const first = getFirstOccurrence(id);

                // if can't find link to reference, ignore
                if (!first)
                    continue;

                // make jump button
                let button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this reference in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.innerHTML = button.outerHTML + container.innerHTML;
                button = container.firstElementChild;
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeFigureButtons() {
            const figures = document.querySelectorAll('[id^="fig:"]');
            for (const figure of figures) {
                // get figure id and element to add button to
                const id = figure.id;
                const container = figure.querySelector('figcaption') || figure;
                const first = getFirstOccurrence(id);

                // if can't find link to figure, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this figure in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeTableButtons() {
            const tables = document.querySelectorAll('[id^="tbl:"]');
            for (const table of tables) {
                // get ref id and element to add button to
                const id = table.id;
                const container = table.querySelector('caption') || table;
                const first = getFirstOccurrence(id);

                // if can't find link to table, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this table in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
    <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
    <svg width="16" height="16" viewBox="0 0 320 512">
        <path
            fill="currentColor"
            d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
        ></path>
    </svg>
</template>
<!-- link highlight plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user hovers or
        // focuses a link, other links that have the same target will be
        // highlighted. It also makes it such that when clicking a link, the
        // target of the link (eg reference, figure, table) is briefly
        // highlighted.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'linkHighlight';

        // default plugin options
        const options = {
            // whether to also highlight links that go to external urls
            externalLinks: 'false',
            // whether user must click off to unhighlight instead of just
            // un-hovering
            clickUnhighlight: 'false',
            // whether to also highlight links that are unique
            highlightUnique: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach mouse and focus listeners to link
                link.addEventListener('mouseenter', onLinkFocus);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('mouseleave', onLinkUnhover);
            }

            // attach click and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('hashchange', onHashChange);

            // run hash change on window load in case user has navigated
            // directly to hash
            onHashChange();
        }

        // when link is focused (tabbed to) or hovered
        function onLinkFocus() {
            highlight(this);
        }

        // when link is unhovered
        function onLinkUnhover() {
            if (options.clickUnhighlight !== 'true')
                unhighlightAll();
        }

        // when the mouse is clicked anywhere in window
        function onClick(event) {
            unhighlightAll();
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                glowElement(target);
        }

        // get element that is target of link or url hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            return target;
        }

        // start glow sequence on an element
        function glowElement(element) {
            const startGlow = function() {
                onGlowEnd();
                element.dataset.glow = 'true';
                element.addEventListener('animationend', onGlowEnd);
            };
            const onGlowEnd = function() {
                element.removeAttribute('data-glow');
                element.removeEventListener('animationend', onGlowEnd);
            };
            startGlow();
        }

        // highlight link and all others with same target
        function highlight(link) {
            // force unhighlight all to start fresh
            unhighlightAll();

            // get links with same target
            if (!link)
                return;
            const sameLinks = getSameLinks(link);

            // if link unique and option is off, exit and don't highlight
            if (sameLinks.length <= 1 && options.highlightUnique !== 'true')
                return;

            // highlight all same links, and "select" (special highlight) this
            // one
            for (const sameLink of sameLinks) {
                if (sameLink === link)
                    sameLink.setAttribute('data-selected', 'true');
                else
                    sameLink.setAttribute('data-highlighted', 'true');
            }
        }

        // unhighlight all links
        function unhighlightAll() {
            const links = getLinks();
            for (const link of links) {
                link.setAttribute('data-selected', 'false');
                link.setAttribute('data-highlighted', 'false');
            }
        }

        // get links with same target
        function getSameLinks(link) {
            const results = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    results.push(otherLink);
            }
            return results;
        }

        // get all links of types we wish to handle
        function getLinks() {
            let query = 'a';
            if (options.externalLinks !== 'true')
                query += '[href^="#"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelectorAll(query);
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- table of contents plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin provides a "table of contents" (toc) panel on
        // the side of the document that allows the user to conveniently
        // navigate between sections of the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tableOfContents';

        // default plugin options
        const options = {
            // which types of elements to add links for, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3',
            // whether default behavior is to be closed ('false'), open
            // ('true'), or only open when screen wide enough to fit panel
            // ('auto'). note: still always starts closed when page loads.
            open: 'auto',
            // if list item is more than this many characters, text will be
            // truncated
            charLimit: '50',
            // whether or not to show bullets next to each toc item
            bullets: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // make toc panel and populate with entries (links to document
            // sections)
            const panel = makePanel();
            if (!panel)
                return;
            makeEntries(panel);
            document.body.insertBefore(panel, document.body.firstChild);

            closePanel();

            // attach click, scroll, and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('scroll', onScroll);
            window.addEventListener('hashchange', onScroll);
            window.addEventListener('keyup', onKeyUp);
            onScroll();

            // add class to push document body down out of way of toc button
            document.body.classList.add('toc_body_nudge');
        }

        // determine if screen wide enough to fit toc panel
        function isSmallScreen() {
            // in default theme:
            // 816px = 8.5in = width of "page" (<body>) element
            // 260px = min width of toc panel (*2 for both sides of <body>)
            return window.innerWidth < 816 + 260 * 2;
        }

        // open/close panel based on option and screen size
        function openOrClosePanel() {
            if (
                options.open === 'true' ||
                (options.open === 'auto' && !isSmallScreen())
            )
                openPanel();
            else
                closePanel();
        }

        // when mouse is clicked anywhere in window
        function onClick() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                openOrClosePanel();
        }

        // when window is scrolled or hash changed
        function onScroll() {
            highlightViewed();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            // close on esc
            if (event.key === 'Escape')
                closePanel();
        }

        // find entry of currently viewed document section in toc and highlight
        function highlightViewed() {
            const firstId = getFirstInView(options.typesQuery);

            // get toc entries (links), unhighlight all, then highlight viewed
            const list = document.getElementById('toc_list');
            if (!firstId || !list)
                return;
            const links = list.querySelectorAll('a');
            for (const link of links)
                link.dataset.viewing = 'false';
            const link = list.querySelector('a[href="#' + firstId + '"]');
            if (!link)
                return;
            link.dataset.viewing = 'true';
        }

        // get first or previous toc listed element in top half of view
        function getFirstInView(query) {
            // get all elements matching query and with id
            const elements = document.querySelectorAll(query);
            const elementsWithIds = [];
            for (const element of elements) {
                if (element.id)
                    elementsWithIds.push(element);
            }


            // get first or previous element in top half of view
            for (let i = 0; i < elementsWithIds.length; i++) {
                const element = elementsWithIds[i];
                const prevElement = elementsWithIds[Math.max(0, i - 1)];
                if (element.getBoundingClientRect().top >= 0) {
                    if (
                        element.getBoundingClientRect().top <
                        window.innerHeight / 2
                    )
                        return element.id;
                    else
                        return prevElement.id;
                }
            }
        }

        // make panel
        function makePanel() {
            // create panel
            const panel = document.createElement('div');
            panel.id = 'toc_panel';
            if (options.bullets === 'true')
                panel.dataset.bullets = 'true';

            // create header
            const header = document.createElement('div');
            header.id = 'toc_header';

            // create toc button
            const button = document.createElement('button');
            button.id = 'toc_button';
            button.innerHTML = document.querySelector('.icon_th_list').innerHTML;
            button.title = 'Table of Contents';
            button.classList.add('icon_button');

            // create header text
            const text = document.createElement('h3');
            text.innerHTML = 'View Table of Contents';

            // create container for toc list
            const list = document.createElement('div');
            list.id = 'toc_list';

            // attach click listeners
            panel.addEventListener('click', onPanelClick);
            header.addEventListener('click', onHeaderClick);
            button.addEventListener('click', onButtonClick);

            // attach elements
            header.appendChild(button);
            header.appendChild(text);
            panel.appendChild(header);
            panel.appendChild(list);

            return panel;
        }

        // create toc entries (links) to each element of the specified types
        function makeEntries(panel) {
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements) {
                // do not add link if element doesn't have assigned id
                if (!element.id)
                    continue;

                // create link/list item
                const link = document.createElement('a');
                link.classList.add('toc_link');
                switch (element.tagName.toLowerCase()) {
                    case 'h1':
                        link.dataset.level = '1';
                        break;
                    case 'h2':
                        link.dataset.level = '2';
                        break;
                    case 'h3':
                        link.dataset.level = '3';
                        break;
                    case 'h4':
                        link.dataset.level = '4';
                        break;
                }
                link.title = element.innerText;
                let text = element.innerText;
                if (text.length > options.charLimit)
                    text = text.slice(0, options.charLimit) + '...';
                link.innerHTML = text;
                link.href = '#' + element.id;
                link.addEventListener('click', onLinkClick);

                // attach link
                panel.querySelector('#toc_list').appendChild(link);
            }
        }

        // when panel is clicked
        function onPanelClick(event) {
            // stop click from propagating to window/document and closing panel
            event.stopPropagation();
        }

        // when header itself is clicked
        function onHeaderClick(event) {
            togglePanel();
        }

        // when button is clicked
        function onButtonClick(event) {
            togglePanel();
            // stop header underneath button from also being clicked
            event.stopPropagation();
        }

        // when link is clicked
        function onLinkClick() {
            openOrClosePanel();
        }

        // open panel if closed, close if opened
        function togglePanel() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                closePanel();
            else
                openPanel();
        }

        // open panel
        function openPanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'true';
        }

        // close panel
        function closePanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'false';
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- th list icon -->

<template class="icon_th_list">
    <!-- modified from: https://fontawesome.com/icons/th-list -->
    <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
        <path
            fill="currentColor"
            d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- lightbox plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user clicks on an
        // image, the image fills the screen and the user can pan/drag/zoom
        // the image and navigate between other images in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'lightbox';

        // default plugin options
        const options = {
            // list of possible zoom/scale factors
            zoomSteps:
                '0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1,' +
                '1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8',
            // whether to fit image to view ('fit'), display at 100% and shrink
            // if necessary ('shrink'), or always display at 100% ('100')
            defaultZoom: 'fit',
            // whether to zoom in/out toward center of view ('true') or mouse
            // ('false')
            centerZoom: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <img> element
            const imgs = document.querySelectorAll('figure > img');
            let count = 1;
            for (const img of imgs) {
                img.classList.add('lightbox_document_img');
                img.dataset.number = count;
                img.dataset.total = imgs.length;
                img.addEventListener('click', openLightbox);
                count++;
            }

            // attach mouse and key listeners to window
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('keyup', onKeyUp);
        }

        // when mouse is moved anywhere in window
        function onWindowMouseMove(event) {
            window.mouseX = event.clientX;
            window.mouseY = event.clientY;
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'lightbox_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'lightbox_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeLightbox();
                    break;
            }
        }

        // open lightbox
        function openLightbox() {
            const lightbox = makeLightbox(this);
            if (!lightbox)
                return;

            blurBody(lightbox);
            document.body.appendChild(lightbox);
        }

        // make lightbox
        function makeLightbox(img) {
            // delete lightbox if it exists, start fresh
            closeLightbox();

            // create screen overlay containing lightbox
            const overlay = document.createElement('div');
            overlay.id = 'lightbox_overlay';

            // create image info boxes
            const numberInfo = document.createElement('div');
            const zoomInfo = document.createElement('div');
            numberInfo.id = 'lightbox_number_info';
            zoomInfo.id = 'lightbox_zoom_info';

            // create container for image
            const imageContainer = document.createElement('div');
            imageContainer.id = 'lightbox_image_container';
            const lightboxImg = makeLightboxImg(
                img,
                imageContainer,
                numberInfo,
                zoomInfo
            );
            imageContainer.appendChild(lightboxImg);

            // create bottom container for caption and navigation buttons
            const bottomContainer = document.createElement('div');
            bottomContainer.id = 'lightbox_bottom_container';
            const caption = makeCaption(img);
            const prevButton = makePrevButton(img);
            const nextButton = makeNextButton(img);
            bottomContainer.appendChild(prevButton);
            bottomContainer.appendChild(caption);
            bottomContainer.appendChild(nextButton);

            // attach top middle and bottom to overlay
            overlay.appendChild(numberInfo);
            overlay.appendChild(zoomInfo);
            overlay.appendChild(imageContainer);
            overlay.appendChild(bottomContainer);

            return overlay;
        }

        // make <img> object that is intuitively draggable and zoomable
        function makeLightboxImg(
            sourceImg,
            container,
            numberInfoBox,
            zoomInfoBox
        ) {
            // create copy of source <img>
            const img = sourceImg.cloneNode(true);
            img.classList.remove('lightbox_document_img');
            img.removeAttribute('id');
            img.removeAttribute('width');
            img.removeAttribute('height');
            img.style.position = 'unset';
            img.style.margin = '0';
            img.style.padding = '0';
            img.style.width = '';
            img.style.height = '';
            img.style.minWidth = '';
            img.style.minHeight = '';
            img.style.maxWidth = '';
            img.style.maxHeight = '';
            img.id = 'lightbox_img';

            // build sorted list of unique zoomSteps, always including a 100%
            let zoomSteps = [];
            const optionsZooms = options.zoomSteps.split(/[^0-9.]/);
            for (const optionZoom of optionsZooms) {
                const newZoom = parseFloat(optionZoom);
                if (newZoom && !zoomSteps.includes(newZoom))
                    zoomSteps.push(newZoom);
            }
            if (!zoomSteps.includes(1))
                zoomSteps.push(1);
            zoomSteps = zoomSteps.sort(function sortNumber(a, b) {
                return a - b;
            });

            // <img> object property variables
            let zoom = 1;
            let translateX = 0;
            let translateY = 0;
            let clickMouseX = undefined;
            let clickMouseY = undefined;
            let clickTranslateX = undefined;
            let clickTranslateY = undefined;

            updateNumberInfo();

            // update image numbers displayed in info box
            function updateNumberInfo() {
                numberInfoBox.innerHTML =
                    sourceImg.dataset.number + ' of ' + sourceImg.dataset.total;
            }

            // update zoom displayed in info box
            function updateZoomInfo() {
                let zoomInfo = zoom * 100;
                if (!Number.isInteger(zoomInfo))
                    zoomInfo = zoomInfo.toFixed(2);
                zoomInfoBox.innerHTML = zoomInfo + '%';
            }

            // move to closest zoom step above current zoom
            const zoomIn = function() {
                for (const zoomStep of zoomSteps) {
                    if (zoomStep > zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                updateTransform();
            };

            // move to closest zoom step above current zoom
            const zoomOut = function() {
                zoomSteps.reverse();
                for (const zoomStep of zoomSteps) {
                    if (zoomStep < zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                zoomSteps.reverse();

                updateTransform();
            };

            // update display of <img> based on scale/translate properties
            const updateTransform = function() {
                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                // get new width/height after scale
                const rect = img.getBoundingClientRect();
                // limit translate
                translateX = Math.max(translateX, -rect.width / 2);
                translateX = Math.min(translateX, rect.width / 2);
                translateY = Math.max(translateY, -rect.height / 2);
                translateY = Math.min(translateY, rect.height / 2);

                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                updateZoomInfo();
            };

            // fit <img> to container
            const fit = function() {
                // no x/y offset, 100% zoom by default
                translateX = 0;
                translateY = 0;
                zoom = 1;

                // widths of <img> and container
                const imgWidth = img.naturalWidth;
                const imgHeight = img.naturalHeight;
                const containerWidth = parseFloat(
                    window.getComputedStyle(container).width
                );
                const containerHeight = parseFloat(
                    window.getComputedStyle(container).height
                );

                // how much zooming is needed to fit <img> to container
                const xRatio = imgWidth / containerWidth;
                const yRatio = imgHeight / containerHeight;
                const maxRatio = Math.max(xRatio, yRatio);
                const newZoom = 1 / maxRatio;

                // fit <img> to container according to option
                if (options.defaultZoom === 'shrink') {
                    if (maxRatio > 1)
                        zoom = newZoom;
                } else if (options.defaultZoom === 'fit')
                    zoom = newZoom;

                updateTransform();
            };

            // when mouse wheel is rolled anywhere in container
            const onContainerWheel = function(event) {
                if (!event)
                    return;

                // let ctrl + mouse wheel to zoom behave as normal
                if (event.ctrlKey)
                    return;

                // prevent normal scroll behavior
                event.preventDefault();
                event.stopPropagation();

                // point around which to scale img
                const viewRect = container.getBoundingClientRect();
                const viewX = (viewRect.left + viewRect.right) / 2;
                const viewY = (viewRect.top + viewRect.bottom) / 2;
                const originX = options.centerZoom === 'true' ? viewX : mouseX;
                const originY = options.centerZoom === 'true' ? viewY : mouseY;

                // get point on image under origin
                const oldRect = img.getBoundingClientRect();
                const oldPercentX = (originX - oldRect.left) / oldRect.width;
                const oldPercentY = (originY - oldRect.top) / oldRect.height;

                // increment/decrement zoom
                if (event.deltaY < 0)
                    zoomIn();
                if (event.deltaY > 0)
                    zoomOut();

                // get offset between previous image point and origin
                const newRect = img.getBoundingClientRect();
                const offsetX =
                    originX - (newRect.left + newRect.width * oldPercentX);
                const offsetY =
                    originY - (newRect.top + newRect.height * oldPercentY);

                // translate image to keep image point under origin
                translateX += offsetX;
                translateY += offsetY;

                // perform translate
                updateTransform();
            };

            // when container is clicked
            function onContainerClick(event) {
                // if container itself is target of click, and not other
                // element above it
                if (event.target === this)
                    closeLightbox();
            }

            // when mouse button is pressed on image
            const onImageMouseDown = function(event) {
                // store original mouse position relative to image
                clickMouseX = window.mouseX;
                clickMouseY = window.mouseY;
                clickTranslateX = translateX;
                clickTranslateY = translateY;
                event.stopPropagation();
                event.preventDefault();
            };

            // when mouse button is released anywhere in window
            const onWindowMouseUp = function(event) {
                // reset original mouse position
                clickMouseX = undefined;
                clickMouseY = undefined;
                clickTranslateX = undefined;
                clickTranslateY = undefined;

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mouseup', onWindowMouseUp);
            };

            // when mouse is moved anywhere in window
            const onWindowMouseMove = function(event) {
                if (
                    clickMouseX === undefined ||
                    clickMouseY === undefined ||
                    clickTranslateX === undefined ||
                    clickTranslateY === undefined
                )
                    return;

                // offset image based on original and current mouse position
                translateX = clickTranslateX + window.mouseX - clickMouseX;
                translateY = clickTranslateY + window.mouseY - clickMouseY;
                updateTransform();
                event.preventDefault();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mousemove', onWindowMouseMove);
            };

            // when window is resized
            const onWindowResize = function(event) {
                fit();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('resize', onWindowResize);
            };

            // attach the necessary event listeners
            img.addEventListener('dblclick', fit);
            img.addEventListener('mousedown', onImageMouseDown);
            container.addEventListener('wheel', onContainerWheel);
            container.addEventListener('mousedown', onContainerClick);
            container.addEventListener('touchstart', onContainerClick);
            window.addEventListener('mouseup', onWindowMouseUp);
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('resize', onWindowResize);

            // run fit() after lightbox atttached to document and <img> Loaded
            // so needed container and img dimensions available
            img.addEventListener('load', fit);

            return img;
        }

        // make caption
        function makeCaption(img) {
            const caption = document.createElement('div');
            caption.id = 'lightbox_caption';
            const captionSource = img.nextElementSibling;
            if (captionSource.tagName.toLowerCase() === 'figcaption') {
                const captionCopy = makeCopy(captionSource);
                caption.innerHTML = captionCopy.innerHTML;
            }

            caption.addEventListener('touchstart', function(event) {
                event.stopPropagation();
            });

            return caption;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // make button to jump to previous image in document
        function makePrevButton(img) {
            const prevButton = document.createElement('button');
            prevButton.id = 'lightbox_prev_button';
            prevButton.title = 'Jump to the previous image in the document [←]';
            prevButton.classList.add('icon_button', 'lightbox_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;

            // attach click listeners to button
            prevButton.addEventListener('click', function() {
                getPrevImg(img).click();
            });

            return prevButton;
        }

        // make button to jump to next image in document
        function makeNextButton(img) {
            const nextButton = document.createElement('button');
            nextButton.id = 'lightbox_next_button';
            nextButton.title = 'Jump to the next image in the document [→]';
            nextButton.classList.add('icon_button', 'lightbox_button');
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;

            // attach click listeners to button
            nextButton.addEventListener('click', function() {
                getNextImg(img).click();
            });

            return nextButton;
        }

        // get previous image in document
        function getPrevImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if < 1
            if (index - 1 >= 0)
                index--;
            else
                index = imgs.length - 1;
            return imgs[index];
        }

        // get next image in document
        function getNextImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if > total
            if (index + 1 <= imgs.length - 1)
                index++;
            else
                index = 0;
            return imgs[index];
        }

        // close lightbox
        function closeLightbox() {
            focusBody();

            const lightbox = document.getElementById('lightbox_overlay');
            if (lightbox)
                lightbox.remove();
        }

        // make all elements behind lightbox non-focusable
        function blurBody(overlay) {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.tabIndex = -1;
            document.body.classList.add('body_no_scroll');
        }

        // make all elements focusable again
        function focusBody() {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.removeAttribute('tabIndex');
            document.body.classList.remove('body_no_scroll');
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- attributes plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows arbitrary HTML attributes to be attached
        // to (almost) any element. Place an HTML comment inside or next to the
        // desired element in the format <!-- $attribute="value" -->

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'attributes';

        // default plugin options
        const options = {
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // get list of comments in document
            const comments = findComments();

            for(const comment of comments)
                if (comment.parentElement)
                    addAttributes(
                        comment.parentElement,
                        comment.nodeValue.trim()
                    );
        }

        // add html attributes to specified element based on string of 
        // html attributes and values
        function addAttributes(element, text) {
            // regex's for finding attribute/value pairs in the format of
            // attribute="value" or attribute='value
            const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
            const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

            // loop through attribute/value pairs
            let match;
            while(match = text.match(regex2) || text.match(regex1)) {
                // get attribute and value from regex capture groups
                let attribute = match[1];
                let value = match[2];

                // remove from string
                text = text.substring(match.index + match[0].length);

                if (!attribute || !value)
                    break;

                // set attribute of parent element
                try {
                    element.setAttribute(attribute, value);
                } catch(error) {
                    console.log(error);
                }

                // special case for colspan
                if (attribute === 'colspan')
                    removeTableCells(element, value);
            }
        }

        // get list of comment elements in document
        function findComments() {
            const comments = [];

            // iterate over comment nodes in document
            function acceptNode(node) {
                return NodeFilter.FILTER_ACCEPT;
            }
            const iterator = document.createNodeIterator(
                document.body,
                NodeFilter.SHOW_COMMENT,
                acceptNode
            );
            let node;
            while(node = iterator.nextNode())
                comments.push(node);

            return comments;
        }

        // remove certain number of cells after specified cell
        function removeTableCells(cell, number) {
            number = parseInt(number);
            if (!number)
                return;

            // remove elements
            for(; number > 1; number--) {
                if (cell.nextElementSibling)
                    cell.nextElementSibling.remove();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- math plugin configuration -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "CommonHTML": { linebreaks: { automatic: true } },
        "HTML-CSS": { linebreaks: { automatic: true } },
        "SVG": { linebreaks: { automatic: true } },
        "fast-preview": { disabled: true }
    });
</script>

<!-- math plugin -->

<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML'>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'MathJax' allows the proper rendering of
    // math/equations written in LaTeX.

    // https://www.mathjax.org/
</script>
<!-- annotations plugin -->

<script>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'Hypothesis' allows public annotation of the
    // manuscript.

    // https://web.hypothes.is/

    // plugin configuration
    window.hypothesisConfig = function() {
        return {
            branding: {
                accentColor: '#2196f3',
                appBackgroundColor: '#f8f8f8',
                ctaBackgroundColor: '#f8f8f8',
                ctaTextColor: '#000000',
                selectionFontFamily: 'Open Sans, Helvetica, sans serif',
                annotationFontFamily: 'Open Sans, Helvetica, sans serif'
            }
        };
    };

    // hypothesis client script
    const embed = 'https://hypothes.is/embed.js';
    // hypothesis annotation count query url
    const query = 'https://api.hypothes.is/api/search?limit=0&url='

    
    // start script
    function start() {
        const button = makeButton();
        document.body.insertBefore(button, document.body.firstChild);
        insertCount(button);
    }

    // make button
    function makeButton() {
        // create button
        const button = document.createElement('button');
        button.id = 'hypothesis_button';
        button.innerHTML = document.querySelector('.icon_hypothesis').innerHTML;
        button.title = 'Hypothesis annotations';
        button.classList.add('icon_button');

        function onClick(event) {
            onButtonClick(event, button);
        }

        // attach click listeners
        button.addEventListener('click', onClick);

        return button;
    }

    // insert annotations count
    async function insertCount(button) {
        // get annotation count from Hypothesis based on url
        let count = '-';
        try {
            const canonical = document.querySelector('link[rel="canonical"]');
            const location = window.location;
            const url = encodeURIComponent((canonical || location).href);
            const response = await fetch(query + url);
            const json = await response.json();
            count = json.total || '-';
        } catch(error) {
            console.log(error);
        }
        
        // put count into button
        const counter = document.createElement('span');
        counter.id = 'hypothesis_count';
        counter.innerHTML = count;
        button.title = 'View ' + count + ' Hypothesis annotations';
        button.append(counter);
    }

    // when button is clicked
    function onButtonClick(event, button) {
        const script = document.createElement('script');
        script.src = embed;
        document.body.append(script);
        button.remove();
    }

    window.addEventListener('load', start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
    <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
    <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
        <path
            fill="currentColor"
            d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- analytics plugin -->

<!-- copy and paste code from Google Analytics or similar service here -->
</body>
</html>
